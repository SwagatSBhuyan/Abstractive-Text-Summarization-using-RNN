{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JN1CXyeuleNS",
    "outputId": "4b4e48fa-c708-482c-eef6-ad4be8bd4265"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WpMYh00ik9qm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\swaga\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import re\n",
    "import torch\n",
    "import json\n",
    "# import torch_xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from preprocess import *\n",
    "from vocabulary import *\n",
    "from model import *\n",
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import seaborn as sns\n",
    "from string import punctuation\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SVaFT9sBnKVi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549361\n",
      "9842\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../../../evaluation/snli/snli_/snli_1.0_train.csv')\n",
    "val_df   = pd.read_csv('../../../evaluation/snli/snli_/snli_1.0_dev.csv')\n",
    "# train_df = pd.read_csv('../datasets/snli/snli_/snli_1.0_train.csv')\n",
    "# val_df   = pd.read_csv('../datasets/snli/snli_/snli_1.0_dev.csv')\n",
    "train_df, val_df = preprocess_text(train_df, val_df)\n",
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['sentence2'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "l2TMjBJDF1uT",
    "outputId": "8b9cda3b-9519-4504-e8ee-c527011f783d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence1  \\\n",
      "0   saudi stock exchange appointed sarah al ceo in...   \n",
      "1   hollywood actor morgan freeman said would like...   \n",
      "2   uk india business council chairperson said 60 ...   \n",
      "3   indian railways wednesday increased lower bert...   \n",
      "4   two pilots arrested saturday glasgow scotland ...   \n",
      "..                                                ...   \n",
      "95  researchers mit developed continuous high reso...   \n",
      "96  former indian captain rahul dravid former sri ...   \n",
      "97  appointment kalyan krishnamurthy flipkart 39 c...   \n",
      "98  national investigation agency friday framed ch...   \n",
      "99  australian motorcycle stunt performer robbie p...   \n",
      "\n",
      "                                            sentence2      bleu  \\\n",
      "0    saudi stock exchange appointed sarah al ceo i...  0.696471   \n",
      "1    hollywood actor morgan freeman said would lik...  0.673274   \n",
      "2    india business council chairperson said 60 br...  0.670611   \n",
      "3    indian railways wednesday increased lower ber...  0.635658   \n",
      "4    two pilots arrested saturday glasgow scotland...  0.644035   \n",
      "..                                                ...       ...   \n",
      "95   Researchers mit developed continuous high res...  0.602511   \n",
      "96   icc cricket committee represents players umpi...  0.570855   \n",
      "97   Flipkart CEO kalyan krishnamurthy is the CEO ...  0.732862   \n",
      "98   national investigation agency friday framed c...  0.652124   \n",
      "99   Australian motorcycle stunt performer robbie ...  0.667157   \n",
      "\n",
      "    Semantic_similarity  rouge_1_f  rouge_2_f  rouge_l_f  \n",
      "0              0.758483   0.476190   0.315789   0.476190  \n",
      "1              0.011786   0.000000   0.000000   0.000000  \n",
      "2              0.871521   0.631579   0.333333   0.526316  \n",
      "3              0.584623   0.285714   0.000000   0.190476  \n",
      "4              0.759435   0.300000   0.111111   0.300000  \n",
      "..                  ...        ...        ...        ...  \n",
      "95             0.455625   0.240000   0.000000   0.240000  \n",
      "96             0.331183   0.250000   0.000000   0.250000  \n",
      "97             0.519452   0.100000   0.000000   0.100000  \n",
      "98             0.411771   0.105263   0.000000   0.105263  \n",
      "99             0.815118   0.434783   0.285714   0.434783  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>saudi stock exchange appointed sarah al ceo in...</td>\n",
       "      <td>saudi stock exchange appointed sarah al ceo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>hollywood actor morgan freeman said would like...</td>\n",
       "      <td>hollywood actor morgan freeman said would lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>uk india business council chairperson said 60 ...</td>\n",
       "      <td>india business council chairperson said 60 br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>indian railways wednesday increased lower bert...</td>\n",
       "      <td>indian railways wednesday increased lower ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>two pilots arrested saturday glasgow scotland ...</td>\n",
       "      <td>two pilots arrested saturday glasgow scotland...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gold_label                                          sentence1  \\\n",
       "0          -1  saudi stock exchange appointed sarah al ceo in...   \n",
       "1          -1  hollywood actor morgan freeman said would like...   \n",
       "2          -1  uk india business council chairperson said 60 ...   \n",
       "3          -1  indian railways wednesday increased lower bert...   \n",
       "4          -1  two pilots arrested saturday glasgow scotland ...   \n",
       "\n",
       "                                           sentence2  \n",
       "0   saudi stock exchange appointed sarah al ceo i...  \n",
       "1   hollywood actor morgan freeman said would lik...  \n",
       "2   india business council chairperson said 60 br...  \n",
       "3   indian railways wednesday increased lower ber...  \n",
       "4   two pilots arrested saturday glasgow scotland...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rw = pd.read_csv('../datasets/Transformer_generated_summaries.csv', encoding='utf-8')\n",
    "# rw = pd.read_csv('ins.csv', encoding='utf-8')\n",
    "rw = pd.read_csv('test_sets/ins.csv', encoding='utf-8')\n",
    "# rw = pd.read_csv('../datasets/test_data/Transformer_generated_summaries.csv', encoding='utf-8')\n",
    "\n",
    "rw.drop(['original_summary'], axis = 1, inplace=True)\n",
    "rw.rename(columns = {'text':'sentence1'}, inplace = True)\n",
    "rw.rename(columns = {'Predicted_summary':'sentence2'}, inplace = True)\n",
    "\n",
    "# print(rw)\n",
    "gold = [-1] * 100\n",
    "rw.insert(loc=0, column='gold_label', value=gold)\n",
    "rw = rw[['gold_label', 'sentence1', 'sentence2']]\n",
    "# rw = rw[['sentence1', 'sentence2']]\n",
    "rw = rw.dropna()\n",
    "rw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>saudi stock exchange appoints its first female...</td>\n",
       "      <td>saudi stock exchange appointed sarah al ceo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>what makes fireworks explode</td>\n",
       "      <td>hollywood actor morgan freeman said would lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>60 british firms to increase investment in india</td>\n",
       "      <td>india business council chairperson said 60 br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>railways increase senior citizen women quota</td>\n",
       "      <td>indian railways wednesday increased lower ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>pilots arrested in scotland for drinking befor...</td>\n",
       "      <td>two pilots arrested saturday glasgow scotland...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gold_label                                          sentence1  \\\n",
       "0          -1  saudi stock exchange appoints its first female...   \n",
       "1          -1                      what makes fireworks explode    \n",
       "2          -1  60 british firms to increase investment in india    \n",
       "3          -1      railways increase senior citizen women quota    \n",
       "4          -1  pilots arrested in scotland for drinking befor...   \n",
       "\n",
       "                                           sentence2  \n",
       "0   saudi stock exchange appointed sarah al ceo i...  \n",
       "1   hollywood actor morgan freeman said would lik...  \n",
       "2   india business council chairperson said 60 br...  \n",
       "3   indian railways wednesday increased lower ber...  \n",
       "4   two pilots arrested saturday glasgow scotland...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rw = pd.read_csv('../datasets/Transformer_generated_summaries.csv', encoding='utf-8')\n",
    "# rw = pd.read_csv('ins.csv', encoding='utf-8')\n",
    "rw_ = pd.read_csv('test_sets/ins.csv', encoding='utf-8')\n",
    "# rw = pd.read_csv('../datasets/test_data/Transformer_generated_summaries.csv', encoding='utf-8')\n",
    "\n",
    "rw_.drop(['text'], axis = 1, inplace=True)\n",
    "rw_.rename(columns = {'original_summary':'sentence1'}, inplace = True)\n",
    "rw_.rename(columns = {'Predicted_summary':'sentence2'}, inplace = True)\n",
    "\n",
    "gold = [-1] * 100\n",
    "rw_.insert(loc=0, column='gold_label', value=gold)\n",
    "rw_ = rw_[['gold_label', 'sentence1', 'sentence2']]\n",
    "# rw = rw[['sentence1', 'sentence2']]\n",
    "rw_ = rw_.dropna()\n",
    "rw_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>saudi stock exchange appoints its first female...</td>\n",
       "      <td>saudi stock exchange appointed sarah al ceo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>what makes fireworks explode</td>\n",
       "      <td>hollywood actor morgan freeman said would lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>60 british firms to increase investment in india</td>\n",
       "      <td>india business council chairperson said 60 br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>railways increase senior citizen women quota</td>\n",
       "      <td>indian railways wednesday increased lower ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>pilots arrested in scotland for drinking befor...</td>\n",
       "      <td>two pilots arrested saturday glasgow scotland...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gold_label                                          sentence1  \\\n",
       "0          -1  saudi stock exchange appoints its first female...   \n",
       "1          -1                      what makes fireworks explode    \n",
       "2          -1  60 british firms to increase investment in india    \n",
       "3          -1      railways increase senior citizen women quota    \n",
       "4          -1  pilots arrested in scotland for drinking befor...   \n",
       "\n",
       "                                           sentence2  \n",
       "0   saudi stock exchange appointed sarah al ceo i...  \n",
       "1   hollywood actor morgan freeman said would lik...  \n",
       "2   india business council chairperson said 60 br...  \n",
       "3   indian railways wednesday increased lower ber...  \n",
       "4   two pilots arrested saturday glasgow scotland...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saudi stock exchange appointed sarah al ceo investment bank ncb capital first female head first woman chair major government financial institution kingdom chair arab world 39 largest stock exchange time preparing offer shares public '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw['sentence1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saudi stock exchange appointed sarah al ceo investment bank ncb capital first female'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_['sentence2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rw['sentence2'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "nlhVFSEXntjC"
   },
   "outputs": [],
   "source": [
    "train_df['sentence1'] = train_df['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "train_df['sentence2'] = train_df['sentence2'].astype(str).apply(lambda text: clean_text(text))\n",
    "val_df['sentence1'] = val_df['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "val_df['sentence2'] = val_df['sentence2'].astype(str).apply(lambda text: clean_text(text))\n",
    "rw['sentence1'] = rw['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "rw['sentence2'] = rw['sentence2'].astype(str).apply(lambda text: clean_text(text))\n",
    "rw_['sentence1'] = rw_['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "rw_['sentence2'] = rw_['sentence2'].astype(str).apply(lambda text: clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [gold_label, sentence1, sentence2]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [gold_label, sentence1, sentence2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[(train_df['sentence1'].str.split().str.len() > 0) & (train_df['sentence2'].str.split().str.len() > 0)]\n",
    "val_df = val_df[(val_df['sentence1'].str.split().str.len() > 0) & (val_df['sentence2'].str.split().str.len() > 0)]\n",
    "print(train_df[(train_df['sentence1'].str.split().str.len() == 0) | (train_df['sentence2'].str.split().str.len() == 0)])\n",
    "print(val_df[(val_df['sentence1'].str.split().str.len() == 0) | (val_df['sentence2'].str.split().str.len() == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "HDGOe_fln-hK",
    "outputId": "b7b3299e-c3ab-4c24-a277-07e42e904efb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>a person on a horse jumps over a broken down a...</td>\n",
       "      <td>a person is training his horse for a competition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>a person on a horse jumps over a broken down a...</td>\n",
       "      <td>a person is at a diner ordering an omelette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entailment</td>\n",
       "      <td>a person on a horse jumps over a broken down a...</td>\n",
       "      <td>a person is outdoors on a horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>children smiling and waving at camera</td>\n",
       "      <td>they are smiling at their parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>children smiling and waving at camera</td>\n",
       "      <td>there are children present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                          sentence1  \\\n",
       "0        neutral  a person on a horse jumps over a broken down a...   \n",
       "1  contradiction  a person on a horse jumps over a broken down a...   \n",
       "2     entailment  a person on a horse jumps over a broken down a...   \n",
       "3        neutral              children smiling and waving at camera   \n",
       "4     entailment              children smiling and waving at camera   \n",
       "\n",
       "                                          sentence2  \n",
       "0  a person is training his horse for a competition  \n",
       "1       a person is at a diner ordering an omelette  \n",
       "2                   a person is outdoors on a horse  \n",
       "3                 they are smiling at their parents  \n",
       "4                        there are children present  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "C1W3s5Ojn_mX",
    "outputId": "a7b88a51-54b3-4fed-d2ff-52ba129a56d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>two women are embracing while holding to go pa...</td>\n",
       "      <td>the sisters are hugging goodbye while holding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>two women are embracing while holding to go pa...</td>\n",
       "      <td>two woman are holding packages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>two women are embracing while holding to go pa...</td>\n",
       "      <td>the men are fighting outside a deli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entailment</td>\n",
       "      <td>two young children in blue jerseys one with th...</td>\n",
       "      <td>two kids in numbered jerseys wash their hands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>two young children in blue jerseys one with th...</td>\n",
       "      <td>two kids at a ballgame wash their hands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                          sentence1  \\\n",
       "0        neutral  two women are embracing while holding to go pa...   \n",
       "1     entailment  two women are embracing while holding to go pa...   \n",
       "2  contradiction  two women are embracing while holding to go pa...   \n",
       "3     entailment  two young children in blue jerseys one with th...   \n",
       "4        neutral  two young children in blue jerseys one with th...   \n",
       "\n",
       "                                           sentence2  \n",
       "0  the sisters are hugging goodbye while holding ...  \n",
       "1                     two woman are holding packages  \n",
       "2                the men are fighting outside a deli  \n",
       "3      two kids in numbered jerseys wash their hands  \n",
       "4            two kids at a ballgame wash their hands  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "d1g-SvVOoAfP"
   },
   "outputs": [],
   "source": [
    "train_val_df = pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "eihUwlHHoDZm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment', 'neutral', 'contradiction'}\n",
      "{'entailment': 0, 'neutral': 1, 'contradiction': 2}\n"
     ]
    }
   ],
   "source": [
    "sentence_pairs, _ = pair_generator(train_val_df)\n",
    "rw_sentence_pairs, __ = pair_generator(rw)\n",
    "rw_sentence_pairs_, __ = pair_generator(rw_)\n",
    "train_sentence_pairs, train_sentence_labels = pair_generator(train_df)\n",
    "val_sentence_pairs, val_sentence_labels = pair_generator(val_df)\n",
    "\n",
    "labels = set(train_sentence_labels)\n",
    "print(labels)\n",
    "\n",
    "# tag2idx = {word: i for i, word in enumerate(labels)}\n",
    "# print(tag2idx)\n",
    "tag2idx = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "print(tag2idx)\n",
    "\n",
    "train_labels = [tag2idx[t] for t in train_sentence_labels]\n",
    "val_labels = [tag2idx[t] for t in val_sentence_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saudi stock exchange appointed sarah al ceo investment bank ncb capital first female head first woman chair major government financial institution kingdom chair arab world largest stock exchange time preparing offer shares public',\n",
       " 'saudi stock exchange appointed sarah al ceo investment bank ncb capital first female')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_sentence_pairs_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPSLm_XnoPKk",
    "outputId": "a79ec791-7bb5-4060-e26f-f0b08d5f7be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 33820\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary()\n",
    "\n",
    "for data in [rw_sentence_pairs]:\n",
    "  for sen in data:\n",
    "    premise    = sen[0]\n",
    "    hypothesis = sen[1]\n",
    "    vocab.addSentence(premise)\n",
    "    vocab.addSentence(hypothesis)\n",
    "    \n",
    "for data in [rw_sentence_pairs_]:\n",
    "  for sen in data:\n",
    "    premise    = sen[0]\n",
    "    hypothesis = sen[1]\n",
    "    vocab.addSentence(premise)\n",
    "    vocab.addSentence(hypothesis)\n",
    "\n",
    "for data in [sentence_pairs]:\n",
    "  for sentence_pair in data:\n",
    "    premise    = sentence_pair[0]\n",
    "    hypothesis = sentence_pair[1]\n",
    "    vocab.addSentence(premise)\n",
    "    vocab.addSentence(hypothesis)\n",
    "\n",
    "print(\"Vocab size:\", len(vocab.word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cAAchk1oQb2",
    "outputId": "cbf7f5af-b59c-4b50-83ca-607cecc5efd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 33820\n"
     ]
    }
   ],
   "source": [
    "# vocab = Vocabulary()\n",
    "print(\"Vocab size:\", len(vocab.word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "neSP5WajoSat"
   },
   "outputs": [],
   "source": [
    "index2word = {}\n",
    "for wrd, idx in vocab.word2index.items():\n",
    "    # print(wrd, idx)\n",
    "    index2word[idx] = wrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8t7_OJcozF0"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 300\n",
    "VOCAB_SIZE = len(vocab.word2index)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE = 128\n",
    "LEARNING_RATE = 0.005\n",
    "STACKED_LAYERS = 2\n",
    "EMBEDDING_PATH = '../../../../embeddings/google_news/GoogleNews-vectors-negative300.bin'\n",
    "GLOVE_EMBEDDING = '../../../../embeddings/glove/glove.6B.300d.txt'\n",
    "# EMBEDDING_PATH = '../embeddings/google_news/GoogleNews-vectors-negative300.bin'\n",
    "# GLOVE_EMBEDDING = '../embeddings/glove/glove.6B.300d.txt'\n",
    "\n",
    "initiate_model_vocab(vocab, tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZKtFMQ6oTVk"
   },
   "outputs": [],
   "source": [
    "train_data = DataSetLoader(get_pair_indices(vocab, train_sentence_pairs), train_labels)\n",
    "val_data   = DataSetLoader(get_pair_indices(vocab, val_sentence_pairs), val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UoB3xqDyRLG",
    "outputId": "505953f5-3b5c-48e5-a52c-ea0980e577a2"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE, collate_fn=lambda x:x)\n",
    "val_loader   = torch.utils.data.DataLoader(val_data, batch_size = BATCH_SIZE, collate_fn=lambda x:x)\n",
    "\n",
    "print(len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8m4Riv3kzvGI"
   },
   "outputs": [],
   "source": [
    "embeddings_index = load_embeddings(GLOVE_EMBEDDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvnD6Q6yzwbJ",
    "outputId": "17464d30-1cb3-422d-8598-bdc1d177ae81"
   },
   "outputs": [],
   "source": [
    "weights = 1 * np.random.randn(VOCAB_SIZE + 1, EMBEDDING_SIZE)\n",
    "embedded_count = 0\n",
    "for word, lang_word_index in vocab.word2index.items():\n",
    "  if embeddings_index.get(word) is not None:\n",
    "    weights[lang_word_index] = embeddings_index.get(word)\n",
    "    embedded_count += 1\n",
    "\n",
    "print(\"Embedded count:\", embedded_count)\n",
    "del embeddings_index\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9fEl77ezx5X",
    "outputId": "5f001020-d2de-4d7a-c74c-ba3a00b50010"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM(VOCAB_SIZE, HIDDEN_SIZE, TARGET_SIZE, STACKED_LAYERS, weights, True)\n",
    "lstm_model.to(device)\n",
    "print(lstm_model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lstm_model, train_loader, val_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in lstm_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", lstm_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model, 'sm_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsH495dMz4Xu",
    "outputId": "0632ab0c-b244-4bab-bd1d-e24426d6b445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(33589, 300)\n",
       "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (FC_concat1): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (FC_concat2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (FC_concat3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=3, bias=True)\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=32, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = torch.load('sm_2')\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkfY79IF0Eav",
    "outputId": "d0797bd8-350e-4e8d-a8cd-bb39afe9d168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=32, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vufrSKr90mt0",
    "outputId": "ba80614c-2cb8-4d80-c941-c770f779b7c4"
   },
   "outputs": [],
   "source": [
    "sentence_o = [''] * len(rw)\n",
    "sentence_p = [''] * len(rw)\n",
    "# sentence_o = [''] * 2\n",
    "# sentence_p = [''] * 2\n",
    "\n",
    "# sentence_o[0] = \"rock music is very good for public\"\n",
    "# sentence_p[0] = \"people dont like rock and roll\"\n",
    "sentence_o[0] = \"uk india business council chairperson said 60 british firms likely increase investment india next years firms positive reforms fdi introduced last two years added india even important britain said\"\n",
    "sentence_p[0] = \"60 british firms to increase investment in india\"\n",
    "sentence_o[1] = \"india 39 first cosmetics brand lakmé founded 1952 jrd tata subsidiary tata oil mills business tycoon born july 29 1904 requested prime minister manufacture beauty products country brand named french opera lakmé french form indian goddess\"\n",
    "sentence_p[1] = \"jrd tata founded india 39 s first cosmetics brand\"\n",
    "\n",
    "sentence_o[0] = clean_text(sentence_o[0])\n",
    "sentence_p[0] = clean_text(sentence_p[0])\n",
    "sentence_o[1] = clean_text(sentence_o[1])\n",
    "sentence_p[1] = clean_text(sentence_p[1])\n",
    "\n",
    "sen_p1 = []\n",
    "sen_p2 = []\n",
    "for i in range(2):\n",
    "  sen1 = sentence_o[i]\n",
    "  sen2 = sentence_p[i]\n",
    "  sen_p1.append((sen1, sen2))\n",
    "for i in range(2):\n",
    "  sen2 = sentence_o[i]\n",
    "  sen1 = sentence_p[i]\n",
    "  sen_p2.append((sen1, sen2))\n",
    "\n",
    "# sen_p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5QABAtRQynp",
    "outputId": "d2b0fd48-e128-482f-fff4-005d59b99896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rw[0]:  ('saudi stock exchange appointed sarah al ceo investment bank ncb capital first female head first woman chair major government financial institution kingdom chair arab world largest stock exchange time preparing offer shares public', 'saudi stock exchange appointed sarah al ceo investment bank ncb capital first female')\n",
      "rrw[0]:  ('saudi stock exchange appointed sarah al ceo investment bank ncb capital first female', 'saudi stock exchange appointed sarah al ceo investment bank ncb capital first female head first woman chair major government financial institution kingdom chair arab world largest stock exchange time preparing offer shares public')\n"
     ]
    }
   ],
   "source": [
    "rrw_sentence_pairs_ = []\n",
    "for i in range(len(rw_sentence_pairs_)):\n",
    "    rrw_sentence_pairs_.append((rw_sentence_pairs_[i][1], rw_sentence_pairs_[i][0]))\n",
    "print('rw[0]: ', rw_sentence_pairs_[0])\n",
    "print('rrw[0]: ', rrw_sentence_pairs_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rw_sentence_pairs, __ = pair_generator(rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKnftM-cSWiC",
    "outputId": "9d57aebc-60f6-4348-cef1-bd37278456ac"
   },
   "outputs": [],
   "source": [
    "id_pairs = get_pair_indices(vocab, rw_sentence_pairs)\n",
    "id_pairs_1 = get_pair_indices(vocab, rw_sentence_pairs_)\n",
    "id_pairs_2 = get_pair_indices(vocab, rrw_sentence_pairs_)\n",
    "# id_pairs = get_pair_indices(vocab, sen_p1)\n",
    "# id_pairs = get_pair_indices(vocab, sen_p2)\n",
    "# id_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzurbdbC0pe9",
    "outputId": "e65643f5-9519-47e0-87b7-bd03ce07a9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "premise_seq    = [torch.tensor(seq[0]).long().to(device) for seq in id_pairs]\n",
    "hypothesis_seq = [torch.tensor(seq[1]).long().to(device) for seq in id_pairs]\n",
    "\n",
    "premise_len    = list(map(len, premise_seq))\n",
    "hypothesis_len = list(map(len, hypothesis_seq))\n",
    "\n",
    "batch = len(premise_seq)\n",
    "temp = pad_sequence(premise_seq + hypothesis_seq, batch_first=True)\n",
    "premise_seq    = temp[:batch, :]\n",
    "hypothesis_seq = temp[batch:, :]\n",
    "\n",
    "prediction = lstm_model([premise_seq, hypothesis_seq], premise_len, hypothesis_len)\n",
    "# prediction = prediction[prediction!=prediction[0,3]]\n",
    "\n",
    "prediction_list = prediction.to('cpu')\n",
    "prediction_list = prediction_list.tolist()\n",
    "print(len(prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "premise_seq    = [torch.tensor(seq[0]).long().to(device) for seq in id_pairs_1]\n",
    "hypothesis_seq = [torch.tensor(seq[1]).long().to(device) for seq in id_pairs_1]\n",
    "\n",
    "premise_len    = list(map(len, premise_seq))\n",
    "hypothesis_len = list(map(len, hypothesis_seq))\n",
    "\n",
    "batch = len(premise_seq)\n",
    "temp = pad_sequence(premise_seq + hypothesis_seq, batch_first=True)\n",
    "premise_seq    = temp[:batch, :]\n",
    "hypothesis_seq = temp[batch:, :]\n",
    "\n",
    "prediction_1 = lstm_model([premise_seq, hypothesis_seq], premise_len, hypothesis_len)\n",
    "# prediction = prediction[prediction!=prediction[0,3]]\n",
    "\n",
    "prediction_list = prediction_1.to('cpu')\n",
    "prediction_list = prediction_list.tolist()\n",
    "print(len(prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "premise_seq    = [torch.tensor(seq[0]).long().to(device) for seq in id_pairs_2]\n",
    "hypothesis_seq = [torch.tensor(seq[1]).long().to(device) for seq in id_pairs_2]\n",
    "\n",
    "premise_len    = list(map(len, premise_seq))\n",
    "hypothesis_len = list(map(len, hypothesis_seq))\n",
    "\n",
    "batch = len(premise_seq)\n",
    "temp = pad_sequence(premise_seq + hypothesis_seq, batch_first=True)\n",
    "premise_seq    = temp[:batch, :]\n",
    "hypothesis_seq = temp[batch:, :]\n",
    "\n",
    "prediction_2 = lstm_model([premise_seq, hypothesis_seq], premise_len, hypothesis_len)\n",
    "# prediction = prediction[prediction!=prediction[0,3]]\n",
    "\n",
    "prediction_list = prediction_2.to('cpu')\n",
    "prediction_list = prediction_list.tolist()\n",
    "print(len(prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "soft.tolist()\n",
    "soft_1 = torch.log_softmax(prediction_1, dim=1).argmax(dim=1)\n",
    "soft_1.tolist()\n",
    "soft_2 = torch.log_softmax(prediction_2, dim=1).argmax(dim=1)\n",
    "soft_2.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0], device='cuda:0') tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0], device='cuda:0') tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1,\n",
      "        1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1,\n",
      "        1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2,\n",
      "        2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "        1, 1, 2, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(soft, soft_1, soft_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bjp led opposition friday slammed nitish kumar led state government bihar assembly alleged increase crimes state including recent killing opposition leaders opposition also brought alleged rape minor girl rjd mla raised anti government slogans following houses adjourned', 'opposition also brought alleged rape minor girl rjd mla raised anti government slogans following')\n",
      "('chinese president xi jinping told ukrainian counterpart petro poroshenko china willing play constructive role seeking political resolution ukraine crisis also discussed opportunities economic development bilateral meeting sidelines world economic forum eastern ukraine facing civil war since russia annexed crimea', 'chinese president xi jinping told ukrainian counterpart petro por')\n",
      "('part cricketer ravindra jadeja restaurant jaddu food field rajkot demolished rajkot municipal corporation drive illegal construction city thursday store room kitchen constructed illegally part restaurant pulled corporation earlier issued notices illegal constructions', 'rajkot municipal corporation earlier issued notices illegal constructions part cricketer')\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for i in range(len(soft)):\n",
    "    if soft[i] == 2:\n",
    "        print(rw_sentence_pairs[i])\n",
    "        ctr = ctr + 1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bjp led opposition friday slammed nitish kumar led state government bihar assembly alleged increase crimes state including recent killing opposition leaders opposition also brought alleged rape minor girl rjd mla raised anti government slogans following houses adjourned', 'opposition also brought alleged rape minor girl rjd mla raised anti government slogans following')\n",
      "('chinese president xi jinping told ukrainian counterpart petro poroshenko china willing play constructive role seeking political resolution ukraine crisis also discussed opportunities economic development bilateral meeting sidelines world economic forum eastern ukraine facing civil war since russia annexed crimea', 'chinese president xi jinping told ukrainian counterpart petro por')\n",
      "('part cricketer ravindra jadeja restaurant jaddu food field rajkot demolished rajkot municipal corporation drive illegal construction city thursday store room kitchen constructed illegally part restaurant pulled corporation earlier issued notices illegal constructions', 'rajkot municipal corporation earlier issued notices illegal constructions part cricketer')\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "ctr_1 = 0\n",
    "for i in range(len(soft_1)):\n",
    "    if soft_1[i] == 2:\n",
    "        print(rw_sentence_pairs_[i])\n",
    "        ctr_1 = ctr_1 + 1\n",
    "print(ctr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chinese president xi jinping told ukrainian counterpart petro por', 'chinese president xi jinping told ukrainian counterpart petro poroshenko china willing play constructive role seeking political resolution ukraine crisis also discussed opportunities economic development bilateral meeting sidelines world economic forum eastern ukraine facing civil war since russia annexed crimea')\n",
      "('south africa defeated afghanistan runs second group match super stage super', 'south africa defeated afghanistan runs second group match super stage sunday batting first proteas scored ab de villiers starring ball response mohammad shahzad ball got afghans good start christopher morris helped south africa dismiss')\n",
      "('billionaires list richest person in the world richest person billionaires list', 'microsoft co founder bill gates ranked first forbes billionaires list fortune billion world richest person past years warren buffett reclaimed second slot two years amazon jeff bezos ranked third mark zuckerberg ranked fifth first time')\n",
      "('laws first issued since come force starting october umpires eject cr', 'umpires eject cricketers temporarily permanently match misbehaviour new laws approved marylebone cricket club certain limitations bat sizes also announced maximum dimensions width depth edges new laws first issued since come force starting october')\n",
      "('australian men eight rowing failed qualify qualify for the olympic games for', 'australian men eight rowing failed qualify olympics games first time years finished fourth rio olympics qualifier event country six medals event history women team also failed qualify rio')\n",
      "('bahujan samaj party bsp chief mayawati said muslims', 'bahujan samaj party bsp chief mayawati saturday said muslims waste vote samajwadi party sp must vote bsp bharatiya janata party bjp defeated said people suffering due bad policies central government state government')\n",
      "('general motors hourly workers receive bonuses lakh company registered record year including', 'american vehicle manufacturer general motors hourly workers receive bonuses lakh company registered record year including around crore profit north america general motors profit sharing bonuses biggest given company date general motors trucks suv sales drove profits home market')\n",
      "('affordable housing market estimated touch billion lakh crore per annum next', 'india affordable housing market estimated touch billion lakh crore per annum next years amid rising demand segment study professional services major pwc stated policies innovation technology financing help attract private sector participation well meeting housing demand study added')\n",
      "('pakistan high alert monday authorities executed qadri assassination governor taseer', 'pakistan high alert monday authorities executed qadri assassination governor taseer lawyers capital islamabad declared one day strike protests erupted across nation qadri reportedly considered hero killing taseer defend honour islam governor taseer advocated reforms pakistan rigid blasphemy laws')\n",
      "('rajkot municipal corporation earlier issued notices illegal constructions part cricketer', 'part cricketer ravindra jadeja restaurant jaddu food field rajkot demolished rajkot municipal corporation drive illegal construction city thursday store room kitchen constructed illegally part restaurant pulled corporation earlier issued notices illegal constructions')\n",
      "('german football club bayern players staff celebrated beginning oktoberfest festival wed wednesday', 'german football club bayern players staff celebrated beginning oktoberfest festival wednesday players staff dressed traditional drank glass beer bayern boss carlo ancelotti first oktoberfest appearance alongside new renato sanches mats')\n",
      "('bjp president amit shah elected full three year term met veteran leader lk', 'bjp president amit shah elected full three year term met veteran leader lk advani residence sunday sought blessings advani reportedly criticised shah post bihar polls skipped election meeting along senior leader mm joshi shah meet joshi former pm atal bihari vajpayee tuesday')\n",
      "('severe cyclonic storm vardah expected cross bay bengal coast s', 'severe cyclonic storm vardah expected cross bay bengal coast sriharikota andhra pradesh pm monday authorities sounded high alert andhra pradesh tamil nadu cyclone reportedly turned severe however storm may weaken making landfall officials said')\n",
      "('according tracxn report indian startups raised billion first six months', 'according tracxn report indian startups raised billion first six months half pumped delhi ncr deals bengaluru mumbai ranked second third pune hyderabad ranked fourth fifth funded startup cities country')\n",
      "('colombias president set to sign new peace deal with rebels ending years conflict despite objections', 'colombia president juan manuel santos set sign new peace deal farc rebels ending years conflict despite objections people rejected original accord october opponents peace deal said several key issues including eligibility convicted war crimes appointed public office')\n",
      "('national investigation agency friday framed charges lashkar e taiba operative ansari alias ab', 'national investigation agency friday framed charges lashkar e taiba operative ansari alias abu conspiring terror attacks india also part terrorist control room karachi mumbai attacks framed ipc section sections unlawful activities prevention act')\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "ctr_2 = 0\n",
    "for i in range(len(soft_2)):\n",
    "    if soft_2[i] == 2:\n",
    "        print(rrw_sentence_pairs_[i])\n",
    "        ctr_2 = ctr_2 + 1\n",
    "print(ctr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pairs = get_pair_indices(vocab, rrw_sentence_pairs)\n",
    "# id_pairs = get_pair_indices(vocab, sen_p2)\n",
    "id_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_seq    = [torch.tensor(seq[0]).long().to(device) for seq in id_pairs]\n",
    "hypothesis_seq = [torch.tensor(seq[1]).long().to(device) for seq in id_pairs]\n",
    "\n",
    "premise_len    = list(map(len, premise_seq))\n",
    "hypothesis_len = list(map(len, hypothesis_seq))\n",
    "\n",
    "batch = len(premise_seq)\n",
    "temp = pad_sequence(premise_seq + hypothesis_seq, batch_first=True)\n",
    "premise_seq    = temp[:batch, :]\n",
    "hypothesis_seq = temp[batch:, :]\n",
    "\n",
    "prediction = lstm_model([premise_seq, hypothesis_seq], premise_len, hypothesis_len)\n",
    "# prediction = prediction[prediction!=prediction[0,3]]\n",
    "\n",
    "prediction_list = prediction.to('cpu')\n",
    "prediction_list = prediction_list.tolist()\n",
    "print(len(prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft2 = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "soft2.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr2 = 0\n",
    "for i in range(len(soft)):\n",
    "    if soft2[i] == 0:\n",
    "        print(rrw_sentence_pairs[i])\n",
    "        ctr2 = ctr2 + 1\n",
    "print(ctr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_100 = 0\n",
    "e_50 = 0\n",
    "n_100 = 0\n",
    "n_50 = 0\n",
    "cc = 0\n",
    "for i in range(len(soft1)):\n",
    "    if soft1[i] == soft2[i] == 0:\n",
    "        e_100 = e_100 + 1\n",
    "    elif (soft1[i] == 0 and soft2[i] == 1) or (soft1[i] == 1 and soft2[i] == 0):\n",
    "        e_50 = e_50 + 1\n",
    "    elif soft1[i] == soft2[i] == 1:\n",
    "        n_100 = n_100 + 1\n",
    "    elif (soft1[i] == 1 and soft2[i] == 2) or (soft1[i] == 2 and soft2[i] == 1):\n",
    "        n_50 = n_50 + 1\n",
    "    else: \n",
    "        cc = cc + 1\n",
    "print('e100: ', e_100)\n",
    "print('e50: ', e_50)\n",
    "print('n100: ', n_100)\n",
    "print('n50: ', n_50)\n",
    "print('c100: ', cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_sentence_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_sentence_pairs[1]\n",
    "# 0: entailment\n",
    "# 1: neutral\n",
    "# 2: contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = torch.max(prediction, dim=0)\n",
    "mini = torch.min(prediction, dim=0)\n",
    "# print(maxi[0][0])\n",
    "denom1 = float(maxi[0][0].to('cpu')) - float(mini[0][0].to('cpu'))\n",
    "denom2 = float(maxi[0][1].to('cpu')) - float(mini[0][1].to('cpu'))\n",
    "denom3 = float(maxi[0][2].to('cpu')) - float(mini[0][2].to('cpu'))\n",
    "denom = ( denom1 + denom2 + denom3 ) / 3\n",
    "print(maxi, mini)\n",
    "print(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = []\n",
    "for i in prediction:\n",
    "    a = []\n",
    "    for j in i:\n",
    "        a.append(float(j.to('cpu'))/denom)\n",
    "    aa.append(a)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_scores = []\n",
    "for i in aa:\n",
    "    e_scores.append(i[0] + i[1]*0.5 + i[2]*0.1)\n",
    "print(e_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_labels = []\n",
    "for i in e_scores:\n",
    "    if i < 0:\n",
    "        E_labels.append('NEGATIVE ENTAILMENT')\n",
    "    elif i > 0.2:\n",
    "        E_labels.append('PERFECT ENTAILMENT')\n",
    "    else:\n",
    "        E_labels.append('NEUTRAL ENTAILMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_E = pd.DataFrame(list(zip(rw_sentence_pairs, aa, e_scores, E_labels)), columns =['sentence pairs', 'entailment scores (raw: e, n, c)', 'entailment_metric [-1:1]', 'entailment_labels'])\n",
    "# df_final_E.to_csv('entailment_scores_of_test_pairs.csv')\n",
    "df_final_E.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testcases_df = pd.read_csv('ins.csv')\n",
    "# testcases_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "for i in range(len(soft)):\n",
    "    if soft[i] == 2:\n",
    "        print(rw_sentence_pairs[i])\n",
    "        ctr = ctr + 1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores = {'sentence1': [], 'sentence2': []}\n",
    "for i in testcases_df['original_summary']:\n",
    "    new_scores['sentence2'].append(i)\n",
    "for i in testcases_df['Predicted_summary']:\n",
    "    new_scores['sentence1'].append(i)\n",
    "for i in testcases_df['Predicted_summary']:\n",
    "    new_scores['sentence1'].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores['sentence1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_o = [''] * len(testcases_df)\n",
    "sentence_p = [''] * len(testcases_df)\n",
    "# sentence_o = [''] * 2\n",
    "# sentence_p = [''] * 2\n",
    "\n",
    "# sentence_o[0] = \"rock music is very good for public\"\n",
    "# sentence_p[0] = \"people like rock and roll\"\n",
    "# sentence_o[1] = \"a girl is dancing on the stage\"\n",
    "# sentence_p[1] = \"hello world\"\n",
    "\n",
    "# sentence_o[0] = clean_text(sentence_o[0])\n",
    "# sentence_p[0] = clean_text(sentence_p[0])\n",
    "# sentence_o[1] = clean_text(sentence_o[1])\n",
    "# sentence_p[1] = clean_text(sentence_p[1])\n",
    "\n",
    "new_sen_p = []\n",
    "for i in range(len(testcases_df)):\n",
    "  sen1 = new_scores['sentence1'][i]\n",
    "  sen2 = new_scores['sentence2'][i]\n",
    "  new_sen_p.append((sen1, sen2))\n",
    "\n",
    "new_sen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [new_sen_p]:\n",
    "  for sentence_pair in data:\n",
    "    premise    = sentence_pair[0]\n",
    "    hypothesis = sentence_pair[1]\n",
    "    vocab.addSentence(premise)\n",
    "    vocab.addSentence(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_pairs = get_pair_indices(vocab, new_sen_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_seq    = [torch.tensor(seq[0]).long().to(device) for seq in new_id_pairs]\n",
    "hypothesis_seq = [torch.tensor(seq[1]).long().to(device) for seq in new_id_pairs]\n",
    "\n",
    "premise_len    = list(map(len, premise_seq))\n",
    "hypothesis_len = list(map(len, hypothesis_seq))\n",
    "\n",
    "batch = len(premise_seq)\n",
    "temp = pad_sequence(premise_seq + hypothesis_seq, batch_first=True)\n",
    "premise_seq    = temp[:batch, :]\n",
    "hypothesis_seq = temp[batch:, :]\n",
    "\n",
    "prediction = lstm_model([premise_seq, hypothesis_seq], premise_len, hypothesis_len)\n",
    "# prediction = prediction[prediction!=prediction[0,3]]\n",
    "\n",
    "prediction_list = prediction.to('cpu')\n",
    "prediction_list = prediction_list.tolist()\n",
    "print(len(prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "# soft.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctr = 0\n",
    "# for i in range(len(soft)):\n",
    "#     if soft[i] == 1:\n",
    "#         print(rw_sentence_pairs[i])\n",
    "#         ctr = ctr + 1\n",
    "# print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "entail_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
