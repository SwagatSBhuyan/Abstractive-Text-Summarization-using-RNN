{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JN1CXyeuleNS",
    "outputId": "4b4e48fa-c708-482c-eef6-ad4be8bd4265"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WpMYh00ik9qm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\swaga\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import re\n",
    "import torch\n",
    "import json\n",
    "# import torch_xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from preprocess import *\n",
    "from vocabulary import *\n",
    "from model import *\n",
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import seaborn as sns\n",
    "from string import punctuation\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SVaFT9sBnKVi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549361\n",
      "9842\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('snli/snli_/snli_1.0_train.csv')\n",
    "val_df   = pd.read_csv('snli/snli_/snli_1.0_dev.csv')\n",
    "train_df, val_df = preprocess_text(train_df, val_df)\n",
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "l2TMjBJDF1uT",
    "outputId": "8b9cda3b-9519-4504-e8ee-c527011f783d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
       "      <td>The CBI booked four former officials of Syndi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
       "      <td>Chief Justice JS Khehar said the Supreme Cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
       "      <td>Explosions targetted at people and police off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Why has Reliance been barred from trading in f...</td>\n",
       "      <td>Mukesh Ambani-led Reliance Industries barred ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Was stopped from entering my own studio at Tim...</td>\n",
       "      <td>Arnab Goswami said he was told he could not d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gold_label                                          sentence1  \\\n",
       "0           0  4 ex-bank officials booked for cheating bank o...   \n",
       "1           0     Supreme Court to go paperless in 6 months: CJI   \n",
       "2           0  At least 3 killed, 30 injured in blast in Sylh...   \n",
       "3           0  Why has Reliance been barred from trading in f...   \n",
       "4           0  Was stopped from entering my own studio at Tim...   \n",
       "\n",
       "                                           sentence2  \n",
       "0   The CBI booked four former officials of Syndi...  \n",
       "1   Chief Justice JS Khehar said the Supreme Cour...  \n",
       "2   Explosions targetted at people and police off...  \n",
       "3   Mukesh Ambani-led Reliance Industries barred ...  \n",
       "4   Arnab Goswami said he was told he could not d...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw = pd.read_csv('test_data/Transformer_generated_summaries.csv', encoding='utf-8')\n",
    "rw.drop(['Text'], axis = 1, inplace=True)\n",
    "rw.rename(columns = {'Original_summary':'sentence1'}, inplace = True)\n",
    "rw.rename(columns = {'Predicted_summary':'sentence2'}, inplace = True)\n",
    "gold = [0] * 1000\n",
    "rw.insert(loc=0, column='gold_label', value=gold)\n",
    "rw = rw[['gold_label', 'sentence1', 'sentence2']]\n",
    "rw = rw.dropna()\n",
    "rw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nlhVFSEXntjC"
   },
   "outputs": [],
   "source": [
    "train_df['sentence1'] = train_df['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "train_df['sentence2'] = train_df['sentence2'].astype(str).apply(lambda text: clean_text(text))\n",
    "val_df['sentence1'] = val_df['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "val_df['sentence2'] = val_df['sentence2'].astype(str).apply(lambda text: clean_text(text))\n",
    "rw['sentence1'] = rw['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "rw['sentence2'] = rw['sentence2'].astype(str).apply(lambda text: clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [gold_label, sentence1, sentence2]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [gold_label, sentence1, sentence2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[(train_df['sentence1'].str.split().str.len() > 0) & (train_df['sentence2'].str.split().str.len() > 0)]\n",
    "val_df = val_df[(val_df['sentence1'].str.split().str.len() > 0) & (val_df['sentence2'].str.split().str.len() > 0)]\n",
    "print(train_df[(train_df['sentence1'].str.split().str.len() == 0) | (train_df['sentence2'].str.split().str.len() == 0)])\n",
    "print(val_df[(val_df['sentence1'].str.split().str.len() == 0) | (val_df['sentence2'].str.split().str.len() == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "HDGOe_fln-hK",
    "outputId": "b7b3299e-c3ab-4c24-a277-07e42e904efb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>a person on a horse jumps over a broken down a...</td>\n",
       "      <td>a person is training his horse for a competition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>a person on a horse jumps over a broken down a...</td>\n",
       "      <td>a person is at a diner ordering an omelette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entailment</td>\n",
       "      <td>a person on a horse jumps over a broken down a...</td>\n",
       "      <td>a person is outdoors on a horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>children smiling and waving at camera</td>\n",
       "      <td>they are smiling at their parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>children smiling and waving at camera</td>\n",
       "      <td>there are children present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                          sentence1  \\\n",
       "0        neutral  a person on a horse jumps over a broken down a...   \n",
       "1  contradiction  a person on a horse jumps over a broken down a...   \n",
       "2     entailment  a person on a horse jumps over a broken down a...   \n",
       "3        neutral              children smiling and waving at camera   \n",
       "4     entailment              children smiling and waving at camera   \n",
       "\n",
       "                                          sentence2  \n",
       "0  a person is training his horse for a competition  \n",
       "1       a person is at a diner ordering an omelette  \n",
       "2                   a person is outdoors on a horse  \n",
       "3                 they are smiling at their parents  \n",
       "4                        there are children present  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "C1W3s5Ojn_mX",
    "outputId": "a7b88a51-54b3-4fed-d2ff-52ba129a56d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>two women are embracing while holding to go pa...</td>\n",
       "      <td>the sisters are hugging goodbye while holding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>two women are embracing while holding to go pa...</td>\n",
       "      <td>two woman are holding packages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>two women are embracing while holding to go pa...</td>\n",
       "      <td>the men are fighting outside a deli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entailment</td>\n",
       "      <td>two young children in blue jerseys one with th...</td>\n",
       "      <td>two kids in numbered jerseys wash their hands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>two young children in blue jerseys one with th...</td>\n",
       "      <td>two kids at a ballgame wash their hands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                          sentence1  \\\n",
       "0        neutral  two women are embracing while holding to go pa...   \n",
       "1     entailment  two women are embracing while holding to go pa...   \n",
       "2  contradiction  two women are embracing while holding to go pa...   \n",
       "3     entailment  two young children in blue jerseys one with th...   \n",
       "4        neutral  two young children in blue jerseys one with th...   \n",
       "\n",
       "                                           sentence2  \n",
       "0  the sisters are hugging goodbye while holding ...  \n",
       "1                     two woman are holding packages  \n",
       "2                the men are fighting outside a deli  \n",
       "3      two kids in numbered jerseys wash their hands  \n",
       "4            two kids at a ballgame wash their hands  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "d1g-SvVOoAfP"
   },
   "outputs": [],
   "source": [
    "train_val_df = pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eihUwlHHoDZm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contradiction', 'neutral', 'entailment'}\n",
      "{'contradiction': 0, 'neutral': 1, 'entailment': 2}\n"
     ]
    }
   ],
   "source": [
    "sentence_pairs, _ = pair_generator(train_val_df)\n",
    "rw_sentence_pairs, __ = pair_generator(rw)\n",
    "train_sentence_pairs, train_sentence_labels = pair_generator(train_df)\n",
    "val_sentence_pairs, val_sentence_labels = pair_generator(val_df)\n",
    "\n",
    "labels = set(train_sentence_labels)\n",
    "print(labels)\n",
    "\n",
    "tag2idx = {word: i for i, word in enumerate(labels)}\n",
    "print(tag2idx)\n",
    "\n",
    "train_labels = [tag2idx[t] for t in train_sentence_labels]\n",
    "val_labels = [tag2idx[t] for t in val_sentence_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPSLm_XnoPKk",
    "outputId": "a79ec791-7bb5-4060-e26f-f0b08d5f7be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 35119\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary()\n",
    "\n",
    "for data in [rw_sentence_pairs]:\n",
    "  for sen in data:\n",
    "    premise    = sen[0]\n",
    "    hypothesis = sen[1]\n",
    "    vocab.addSentence(premise)\n",
    "    vocab.addSentence(hypothesis)\n",
    "\n",
    "for data in [sentence_pairs]:\n",
    "  for sentence_pair in data:\n",
    "    premise    = sentence_pair[0]\n",
    "    hypothesis = sentence_pair[1]\n",
    "    vocab.addSentence(premise)\n",
    "    vocab.addSentence(hypothesis)\n",
    "\n",
    "print(\"Vocab size:\", len(vocab.word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cAAchk1oQb2",
    "outputId": "cbf7f5af-b59c-4b50-83ca-607cecc5efd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 35119\n"
     ]
    }
   ],
   "source": [
    "# vocab = Vocabulary()\n",
    "print(\"Vocab size:\", len(vocab.word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "neSP5WajoSat"
   },
   "outputs": [],
   "source": [
    "index2word = {}\n",
    "for wrd, idx in vocab.word2index.items():\n",
    "    # print(wrd, idx)\n",
    "    index2word[idx] = wrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T8t7_OJcozF0"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 300\n",
    "VOCAB_SIZE = len(vocab.word2index)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE = 64\n",
    "LEARNING_RATE = 0.006\n",
    "STACKED_LAYERS = 2\n",
    "EMBEDDING_PATH = '../../dataset/google_news/GoogleNews-vectors-negative300.bin'\n",
    "GLOVE_EMBEDDING = '../../embeddings/glove.6B.300d.txt'\n",
    "\n",
    "initiate_model_vocab(vocab, tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1ZKtFMQ6oTVk"
   },
   "outputs": [],
   "source": [
    "train_data = DataSetLoader(get_pair_indices(vocab, train_sentence_pairs), train_labels)\n",
    "val_data   = DataSetLoader(get_pair_indices(vocab, val_sentence_pairs), val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UoB3xqDyRLG",
    "outputId": "505953f5-3b5c-48e5-a52c-ea0980e577a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17168 308\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE, collate_fn=lambda x:x)\n",
    "val_loader   = torch.utils.data.DataLoader(val_data, batch_size = BATCH_SIZE, collate_fn=lambda x:x)\n",
    "\n",
    "print(len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8m4Riv3kzvGI"
   },
   "outputs": [],
   "source": [
    "embeddings_index = load_embeddings(GLOVE_EMBEDDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvnD6Q6yzwbJ",
    "outputId": "17464d30-1cb3-422d-8598-bdc1d177ae81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded count: 28742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35120, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 1 * np.random.randn(VOCAB_SIZE + 1, EMBEDDING_SIZE)\n",
    "embedded_count = 0\n",
    "for word, lang_word_index in vocab.word2index.items():\n",
    "  if embeddings_index.get(word) is not None:\n",
    "    weights[lang_word_index] = embeddings_index.get(word)\n",
    "    embedded_count += 1\n",
    "\n",
    "print(\"Embedded count:\", embedded_count)\n",
    "del embeddings_index\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9fEl77ezx5X",
    "outputId": "5f001020-d2de-4d7a-c74c-ba3a00b50010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embedding): Embedding(35120, 300)\n",
      "  (lstm): LSTM(300, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (FC_concat1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (FC_concat2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (FC_concat3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (output): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTM(VOCAB_SIZE, HIDDEN_SIZE, TARGET_SIZE, STACKED_LAYERS, weights, True)\n",
    "lstm_model.to(device)\n",
    "print(lstm_model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lstm_model, train_loader, val_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in lstm_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", lstm_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model, 'saved_model_final_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsH495dMz4Xu",
    "outputId": "0632ab0c-b244-4bab-bd1d-e24426d6b445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(35120, 300)\n",
       "  (lstm): LSTM(300, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (FC_concat1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (FC_concat2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (FC_concat3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=3, bias=True)\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=32, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = torch.load('saved_models/saved_model_final_')\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkfY79IF0Eav",
    "outputId": "d0797bd8-350e-4e8d-a8cd-bb39afe9d168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=32, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vufrSKr90mt0",
    "outputId": "ba80614c-2cb8-4d80-c941-c770f779b7c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('many people like to dance to the music of rock and pop',\n",
       "  'people like rock and roll'),\n",
       " ('a girl is dancing on the floor', 'dancing girl')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_o = [''] * len(rw)\n",
    "sentence_p = [''] * len(rw)\n",
    "\n",
    "sentence_o[0] = \"many people like to dance to the music of rock and pop\"\n",
    "sentence_p[0] = \"people like rock and roll\"\n",
    "sentence_o[1] = \"a girl is dancing on the floor\"\n",
    "sentence_p[1] = \"dancing girl\"\n",
    "\n",
    "sentence_o[0] = clean_text(sentence_o[0])\n",
    "sentence_p[0] = clean_text(sentence_p[0])\n",
    "sentence_o[1] = clean_text(sentence_o[1])\n",
    "sentence_p[1] = clean_text(sentence_p[1])\n",
    "\n",
    "sen_p = []\n",
    "for i in range(2):\n",
    "  sen1 = sentence_o[i]\n",
    "  sen2 = sentence_p[i]\n",
    "  sen_p.append((sen1, sen2))\n",
    "\n",
    "sen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5QABAtRQynp",
    "outputId": "d2b0fd48-e128-482f-fff4-005d59b99896"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ex bank officials booked for cheating bank of crore',\n",
       " 'the cbi booked four former officials of syndicate bank and six others for cheating forgery')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_sentence_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKnftM-cSWiC",
    "outputId": "9d57aebc-60f6-4348-cef1-bd37278456ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4, 5, 6, 2, 7, 8],\n",
       " [9, 10, 4, 11, 12, 3, 7, 13, 2, 14, 15, 16, 5, 6, 17])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_pairs = get_pair_indices(vocab, rw_sentence_pairs)\n",
    "# id_pairs = get_pair_indices(vocab, sen_p)\n",
    "id_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzurbdbC0pe9",
    "outputId": "e65643f5-9519-47e0-87b7-bd03ce07a9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "premise_seq    = [torch.tensor(seq[0]).long().to(device) for seq in id_pairs]\n",
    "hypothesis_seq = [torch.tensor(seq[1]).long().to(device) for seq in id_pairs]\n",
    "\n",
    "premise_len    = list(map(len, premise_seq))\n",
    "hypothesis_len = list(map(len, hypothesis_seq))\n",
    "\n",
    "batch = len(premise_seq)\n",
    "temp = pad_sequence(premise_seq + hypothesis_seq, batch_first=True)\n",
    "premise_seq    = temp[:batch, :]\n",
    "hypothesis_seq = temp[batch:, :]\n",
    "\n",
    "prediction = lstm_model([premise_seq, hypothesis_seq], premise_len, hypothesis_len)\n",
    "# prediction = prediction[prediction!=prediction[0,3]]\n",
    "\n",
    "prediction_list = prediction.to('cpu')\n",
    "prediction_list = prediction_list.tolist()\n",
    "print(len(prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1308,  0.9463, -0.3197],\n",
       "        [-0.4200,  1.0235, -0.1301],\n",
       "        [-0.5133,  1.2159, -0.1641],\n",
       "        ...,\n",
       "        [ 0.3282,  0.4428, -0.4151],\n",
       "        [ 0.2177,  0.6922, -0.4887],\n",
       "        [-0.0440,  0.7216, -0.2341]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1308,  0.9463, -0.3197], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('thousands march in london to protest against brexit',\n",
       " 'thousands of people took to the streets in london to protest against the decision to leave the')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_sentence_pairs[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "soft.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('us brewer millercoors sues hcl technologies for crore', 'millercoors sued hcl tech for million over')\n",
      "('kangana gifts herself bedroom bungalow on birthday report', 'kangana ranaut gifted herself a three bedroom bungalow on the occasion')\n",
      "('bsf gets first woman field officer after years', 'tanushree pareek is the first woman field officer in the year')\n",
      "('will give lakh grant to kailash mansarovar pilgrims yogi', 'yogi adityanath has announced a lakh grant to those')\n",
      "('want to reshoot the song gerua with ice cream tweets srk', 'shah rukh khan wants to reshoot the song gerua')\n",
      "('censor board demands removal of phrase mann ki baat in film', 'censor board has demanded removal of phrase mann ki baat')\n",
      "('sp will choose its next party chief before sept akhilesh', 'akhilesh yadav says samajwadi party will choose its next national')\n",
      "('russia has no plans to meddle in french election putin', 'russian president vladimir putin said that russia has no intention of meddling in french elections putin')\n",
      "('varun likens idiots balatkar speech to badri s molestation', 'varun dhawan likens molestation scene in badrinath ki dulhania')\n",
      "('pic shows deepika with ex boyfriend ranbir s mother at event', 'deepika padukone was spotted with her ex boyfriend ranbir kap')\n",
      "('tax dept summons govinda for not paying dues worth lakh', 'govinda appeared before the tax department on friday following a summons to him for not paying')\n",
      "('scientists develop most efficient laser microscope', 'nano laser microscope uses nanoparticles to shine light on sub cellular structures')\n",
      "('amitabh bachchan sings song that pays tribute to brahmaputra', 'amitabh bachchan arijit singh sonu nigam shre')\n",
      "('donald trump asked me out on a date once emma thompson', 'trump had offered emma thompson accommodation in one of his trump towers in while she was')\n",
      "('la lakers honour shaquille o neal with kg dunking statue', 'the bronze statue is suspended from a building hanging feet from the ground and')\n",
      "('houseboat owners should not pollute dal lake j amp k govt', 'the state government has asked houseboat owners to ensure that they do not pollute the')\n",
      "('ashwin breaks record for most wickets in a test season', 'ravichandran ashwin breaks record for most wickets in a test season')\n",
      "('yogi adityanath needs to do a gas releasing asana twinkle', 'twinkle khanna says yogi adityanath needs to do an asana')\n",
      "('up cm is yr older to me but far behind in work akhilesh', 'up cm yogi adityanath is one year older to him in age')\n",
      "('bihar dy cm tejashwi dares adityanath to ban liquor in up', 'bihar deputy cm tejashwi yadav says adityanath should ban liquor')\n",
      "('steve smith nd captain to score tons in a series in india', 'steve smith equalled alastair cook s record for most centuries')\n",
      "('hotel to refund couples who get divorced within year of stay', 'countryside hotels will refund couples who get divorced within a year of their stay')\n",
      "('bank mistakenly transfers crore to other banks', 'kfw mistakenly transferred over billion over')\n",
      "('kohli ruled out of dharamsala test rahane to lead india', 'virat kohli ruled out of final test against australia at dharamsala')\n",
      "('umesh s inswinger knocks off renshaw s off stump', 'umesh yadav bowled an inswinger to dismiss matt renshaw for')\n",
      "('kuldeep yadav first men s chinaman bowler to play for india', 'kuldeep yadav has become the first chinaman bowler to represent india')\n",
      "('lay clear guidelines for anti romeo squads cm adityanath', 'up cm yogi adityanath orders clear guidelines for anti romeo')\n",
      "('year old kerala boy said to be india s youngest father', 'a year old boy from kerala is being called as india')\n",
      "('mukesh ambani s reliance barred from futures trading for yr', 'sebi has imposed a one year ban on mukesh ambani led rel')\n",
      "('no question of supplying cauvery water to tamil nadu k taka', 'karnataka government says there is no question of releasing cauvery water to tamil nadu')\n",
      "('raj hc bans former mps from staying in govt accommodation', 'former alwar mp jitendra singh and mahesh joshi banned from staying')\n",
      "('india pakistan armies exchange sweets on pakistan day', 'the day commemorates the passage of lahore resolution in and the adoption of pakistan')\n",
      "('pakistan hosting anti india terrorists us lawmaker', 'us lawmaker tulsi gabbard says pakistan is allowing anti india terrorists to use')\n",
      "('can t guarantee ad won t show near offensive content google', 'eric schmidt says google can get close to ensuring that an ad doesn')\n",
      "('rs uproar over naming chandigarh airport after bhagat singh', 'opposition alleges that bjp government in haryana refused to name airport after bhagat')\n",
      "('coal india slapped with crore fine for unfair business', 'competition commission of india has slapped a crore penalty on coal india')\n",
      "('beer festival to be held in delhi in april', 'tropical beer festival organised by neonrings will be held in delhi on april')\n",
      "('no plans to introduce and notes says govt', 'the government on friday said it has no plans to come out with')\n",
      "('credit suisse ceo s pay rises to crore for a year', 'credit suisse ceo tidjane thiams pay for his first full year on')\n",
      "('i have no equation or relationship with irrfan nawazuddin', 'nawazuddin siddiqui said he has no relationship with irrfan khan')\n",
      "('virender sehwag to anchor tv show umeed olympic', 'virender sehwag has been roped in by a mumbai based entertainment')\n",
      "('pune sign top ranked t i bowler imran tahir for ipl', 'imran tahir is the number one ranked t i and odi bowler in')\n",
      "('aus media compared kohli with wrong donald tweets kaif', 'former cricketer mohammad kaif tweets that they have compared the batsman with the')\n",
      "('shashank manohar defers resignation to remain icc chairman', 'icc chairman shashank manohar has deferred his resignation and will continue to remain')\n",
      "('apple files patent to use iphone as trackpad for laptops', 'patent filed by apple shows how an iphone can be used in place of a trackpad')\n",
      "('nasa ai captures changes in active volcano s lava lake', 'earth observing spacecraft autonomously started capturing images of a volcano with a rare lava')\n",
      "('i am not replacing anyone on the kapil sharma show raju', 'raju srivastava says he is not replacing anyone on the kapil sharma')\n",
      "('had issues as a teenager because i m dark skinned priyanka', 'actress priyanka chopra had issues as a teenager because she is dark skinned')\n",
      "('netflix s iron fist now among top rated imdb series', 'iron fist rated by users on imdb imdb users')\n",
      "('swara bhaskar s anaarkali of aarah hits the theatres', 'swara bhaskars anaarkali of aarah was rated')\n",
      "('mulayam s younger son daughter in law meet cm adityanath', 'prateek yadav along with his wife aparna yadav met yogi ad')\n",
      "('flipkart to acquire ebay s india operations reports', 'flipkart is acquiring ebay india in a deal that is part of a')\n",
      "('indian led mit team makes d printed colour changing skin', 'a flexible electronic circuitry was printed on a t shaped plastic substrate it responds to')\n",
      "('pakistan has to vacate pok gilgit baltistan india', 'pakistan has to vacate illegal occupation of pakistan occupied kashmir pok and')\n",
      "('censorship pointless in the age of internet anurag kashyap', 'anurag kashyap has said that he finds censorship pointless in the age of')\n",
      "('mohammed shami out of the final test against australia', 'mohammed shami ruled out of final test against australia in dharamsala indian')\n",
      "('bhupathi named india s non playing captain paes in squad', 'mahesh bhupathi named indian davis cup team s non')\n",
      "('raina is a reluctant cricketer after marriage former coach', 'suresh raina has become a reluctant cricketer after marriage says former')\n",
      "('told a man to stop touching me at a temple once vidya balan', 'vidya balan told a man to stop touching her at a temple in mumbai')\n",
      "('cops rescue woman daughter locked up in house for years', 'delhi police has rescued a woman and her daughter who had been locked up in their house')\n",
      "('firm urgently recalls kids cat leggings over choking hazard', 'primark has recalled a pair of children s cat print le')\n",
      "('asked action crew to actually beat me up for a scene rao', 'rajkummar rao reveals he asked the action crew to beat him up for a')\n",
      "('doctors attacked on duty will be given medical aid fadnavis', 'maharashtra chief minister devendra fadnavis said if a doctor is attacked on duty')\n",
      "('neem beer tree in delhi university gives out free liquor', 'a tree dubbed the neem beer tree located in')\n",
      "('up cops suspended over indiscipline since yogi became cm', 'uttar pradesh police has suspended more than policemen over discipline related issues most of')\n",
      "('f champion hamilton calls for more ladies in the paddock', 'lewis hamilton wants more ladies in the formula one paddock daniel ricciardo and')\n",
      "('up cm yogi makes surprise visit to hazratganj police station', 'uttar pradesh chief minister yogi adityanath visited hazratganj police station')\n",
      "('jio decision to charge users helping industry recover idea', 'idea says reliance jios announcement to make subscribers pay for services from april has')\n",
      "('i wish kangana gets along with co stars in future shahid', 'shahid kapoor hopes kangana ranaut gets along with co stars in')\n",
      "('a wife not in the same profession is beneficial shahid', 'shahid kapoor says its beneficial having a wife not in the same profession as')\n",
      "('killed injured in terror attack on uk parliament', 'four people were killed and at least civilians were injured after a terrorist ploughed')\n",
      "('shah rukh khan wins income tax case over earnings from kbc', 'i t department had alleged shah rukh hadn t been paying')\n",
      "('bhagat singh rajguru sukhdev were hanged on this day', 'bhagat singh sukhdev thapar and shivaram rajguru')\n",
      "('chinese company files trademark complaint against mercedes', 'chery claims to have used the name eq')\n",
      "('ready to resume work if govt assures security maha doctors', 'the protesting doctors on wednesday filed an affidavit in the bombay high court the court had')\n",
      "('i can have a flop and not worry about my next meal akshay', 'akshay kumar said today he can have a flop and not worry about where')\n",
      "('kapil sunil are good friends and friends fight krushna', 'krushna abhishek says kapil sharma and sunil grover are')\n",
      "('forum engagement on startup india s online learning program', 'startup india s online learning and development module has an interactive and vibrant community with')\n",
      "('kapil calls kiku sharda per day artiste report', 'kapil sharma insulted kiku sharda who plays bumper')\n",
      "('cannibalism existed in spain years ago study', 'spain based archaeologists have found evidence of cannibalism existing around years ago')\n",
      "('amazon river was formed million years ago study', 'netherlands and brazil based researchers have determined the amazon river was formed more than million')\n",
      "('madhya pradesh govt spent l per nilgai for relocation', 'madhya pradesh spent an average of lakh on each nil')\n",
      "('hair dye shortage in puerto rico as fans go blonde for team', 'puerto rico is facing a shortage of hair dye as fans are dying their hair blonde')\n",
      "('world s first cannabis gym opens in us', 'the power plant fitness gym will open in california us in may members can consume')\n",
      "('actors didn t want me as i m not an a list actress taapsee', 'taapsee pannu said she is not an a list')\n",
      "('ec freezes aiadmk s poll symbol after panneerselvam s claim', 'election commission blocks use of aiadmks name and twin leaves poll symbol o')\n",
      "('smart calendar that syncs with phone to show schedule made', 'japanese designer kosho tsuboi has made a magic calendar that syncs with')\n",
      "('delhi s civic body polls postponed by a day over board exams', 'mcd polls have been postponed by a day to april due to the ongoing cbs')\n",
      "('village boycotts muslims after man elopes with hindu lady', 'a mahapanchayat in rajasthan s hanumangar')\n",
      "('may change sidhu s ministry if he continues tv work singh', 'punjab cm amarinder singh says navjot singh sidhus ministry might have to')\n",
      "('un asks uk to suspend work at hinkley point nuclear plant', 'un has asked the uk to suspend work at the hinkley point nuclear plant')\n",
      "('video young girl steals pope francis s skullcap', 'a video of a young girl stealing pope francis skullcap has emerged in which she')\n",
      "('time lapse videos show growth of chinese cities in years', 'in the population of shenzhen was which rose')\n",
      "('bihar starts free wi fi facility for colleges universities', 'bihar government launches programme to provide free wifi facilities in colleges and universities chief minister nit')\n",
      "('govt asks mps to attend dangal screening with spouses', 'lok sabha speaker sumitra mahajan has organised a screening of aamir')\n",
      "('rocket lab becomes a unicorn with million funding round', 'rocket lab has raised million in series d funding round at a valuation of over')\n",
      "('pak ceasefire violations lower after surgical strike govt', 'there were ceasefire violations at loc and at the international border in')\n",
      "('centre approves building of lakh houses for urban poor', 'the centre has approved the construction of over lakh houses for urban poor in')\n",
      "('centre spent over crore on ads in fiscal year', 'the centre has spent over crore on advertisements in the')\n",
      "('pak singer ghulam ali to perform at varanasi temple', 'ghulam ali is scheduled to perform at the sankatmochan temple in')\n",
      "('india register first away win in an int l friendly in yrs', 'sunil chhetri jeje lalpekhlua and sandesh jhing')\n",
      "('bcci doubles salaries of indian cricket team', 'ravindra jadeja cheteshwar pujara and murali')\n",
      "('bcci upgrades jadeja pujara to grade a contracts', 'ravindra jadeja cheteshwar pujara and murali')\n",
      "('dating app slammed for promoting itself with racist post', 'singapore based dating app highblood has been facing flak for sharing a racist post')\n",
      "('cops blame rats for missing marijuana haul at nagpur station', 'police blame rats for disappearance of haul of drugs from a warehouse at nagpur railway station')\n",
      "('rajinikanth s crew beat us up claim photo journalists', 'rajinikanth and akshay kumar starrer')\n",
      "('gif decided to be deadly weapon by us jury', 'a jury has agreed to count a gif as a deadly weapon in a case against a')\n",
      "('villagers lynch cow thief in uttar pradesh', 'several villagers lynched a cow thief in bijnor district of uttar pradesh three')\n",
      "('indian sisters run a spa for babies in australia', 'indian sisters kavita kumar and anita yap run a spa for babies in perth')\n",
      "('clothing brand creates clothes that grow with kids', 'a clothing brand has created a fashion line called metamorphosis')\n",
      "('up cm orders ban on gutkha paan masala in govt offices', 'yogi adityanath banned gutkha paan and paan')\n",
      "('sunil grover to quit the kapil sharma show reports', 'chandan prabhakar and ali asgar have also boycotted the show')\n",
      "('why no action against bjp congress over foreign funding hc', 'delhi high court asks why no action was taken against bjp and congress over alleged foreign funding')\n",
      "('up police orders to constitute anti romeo squad in lucknow', 'uttar pradesh police to constitute anti romeo squad in districts of lucknow')\n",
      "('chhattisgarh police jawan shot dead by naxals in bijapur', 'tarun sodhi was shot dead by naxals in farsegarh village')\n",
      "('day left for sotc s super holiday sale to end', 'travel company sotc s super holiday sale')\n",
      "('sc declines to interfere with hc order in narada sting case', 'the supreme court refused to interfere with the calcutta high court order that directed the')\n",
      "('mathematician wins crore prize for work on wavelets', 'yves meyer has been awarded the abel prize for his work on wavelets')\n",
      "('colgate celebrates india s water heroes on world water day', 'colgate is celebrating world water day on march by honouring india')\n",
      "('i would love it if my daughter son became actors says juhi', 'juhi chawla would love to see her daughter jhanvi and son ar')\n",
      "('settlement on ram temple best way to maintain harmony cong', 'congress said a mutual out of court settlement by both communities was the best way')\n",
      "('cpi m tmc clash in rs over strip search of student leaders', 'cpi m and tmc mps hit out at each other in rajya sabha')\n",
      "('cisf jawan restores japanese flier s bag with l cash', 'a cisf jawan helped restore a japanese nationals forgotten bag containing')\n",
      "('nba player lebron james lauds man for stopping fist fight', 'the boys were engaged in a fist fight in the middle of a street in the us')\n",
      "('phogat sisters to campaign for bjp in delhi civic polls', 'the bharatiya janata party has roped in wrestlers geeta and babita')\n",
      "('jadeja has started to come out of ashwin s shadow ganguly', 'ravindra jadeja has started to come out of the shadow of ravichand')\n",
      "('three us troops wounded after afghan soldier opens fire', 'three us soldiers were wounded after an afghan soldier opened fire at a base in helmand')\n",
      "('hc gets medical report of no birthmark on dhanush s body', 'the madras high court has examined the medical report where no birthmark or scar has')\n",
      "('i have wanted to slap people when i was eve teased taapsee', 'taapsee pannu has revealed that she has wanted to slap people when she')\n",
      "('india include mohammed shami in the squad for final test', 'mohammed shami last played for india in november and had been out since due to')\n",
      "('never faced any camp system in bollywood diljit dosanjh', 'diljit dosanjh said he has never faced any camp system in bollywood')\n",
      "('more custodial deaths in maha than other states centre', 'there were such instances in the state in in and in')\n",
      "('dean jones trolls user after he calls him cry baby', 'commentator dean jones trolled a user after he called jones a')\n",
      "('beauty and the beast earns crore in opening weekend', 'emma watson and dan stevens starrer beauty and the beast has')\n",
      "('punjab cm to seek legal opinion over sidhu s tv commitments', 'punjab cm captain amarinder singh will seek legal opinion on navjot singh sidhu')\n",
      "('up will witness no communal riots on my watch yogi', 'yogi adityanath says state will witness no corruption or communal riots under his')\n",
      "('smith attains fifth highest batting rating in test cricket', 'steve smith has reached a career high rating points in the latest icc test')\n",
      "('i might take ashwin s advice and hit him on head says starc', 'mitchell starc was given a send off by ravichandran ashwin during')\n",
      "('militant behind attack on lankan cricket team in pak killed', 'qari mohammad yasin also known as ustad aslam was killed in')\n",
      "('alia s sister slams media for taking pics of aish at funeral', 'shaheen bhatt slams media for taking pictures of aishwarya rai bach')\n",
      "('rani mukerji made acting debut in her father s bengali film', 'rani mukerji made her acting debut in bengali film')\n",
      "('cafe in japan lets guests take a nap on beds worth lakh', 'a limited time nap cafe has opened up in tokyo japan featuring ten beds')\n",
      "('i don t post adira s pic as aditya is a private person rani', 'aditya chopra is a very private person and rani mukerji respects')\n",
      "('the rules of the censor board need to be revisited anupam', 'anupam kher has said that the rules of the censor board need to')\n",
      "('iit kanpur to host techkriti from march to', 'techkriti themed factualising fictions will be')\n",
      "('yogi left free to do religious duties sena on deputy cms', 'shiv sena said it was aimed at keeping adityanath free to perform religious')\n",
      "('kapil sharma apologises to sunil grover on twitter', 'kapil sharma has apologised to sunil grover on twitter the two had an')\n",
      "('st look poster of farhan akhtar s the fakir of venice out', 'farhan akhtar and annu kapoor starrer the fakir of venice')\n",
      "('neil armstrong s spacesuit was made by a bra manufacturer', 'the spacesuit was made by seamstresses who usually worked on bras and gird')\n",
      "('rahul must make way if he can t lead kerala cong leader', 'kerala youth congress leader cr mahesh says rahul gandhi must make way for others')\n",
      "('fir against bengal poet for hurting religious sentiments', 'a police complaint has been filed against srijato bandopadhyay')\n",
      "('pujara s double ton helps him become nd best test batsman', 'cheteshwar pujara has moved up to second place in icc test rankings')\n",
      "('bindra sushil kumar named by govt to monitor olympic prep', 'abhinav bindra and sushil kumar are among the olympians appointed')\n",
      "('ex k taka cm invests in taxi app aimed to take on ola uber', 'former chief minister hd kumaraswamy has committed initial investment in a taxi aggregation app')\n",
      "('microsoft allowed to keep crore mistakenly paid to it', 'in the dutch police accidentally ordered licenses for a special edition of')\n",
      "('wakf board rules out amicable solution to ram temple issue', 'wakf board has ruled out a settlement on the ram temple issue as suggested by the')\n",
      "('mexico s richest man became crore richer in a year', 'mexico s richest man carlos slim added billion')\n",
      "('swaraj requests safety of indian woman ill treated in pak', 'mohammadia begum was being mistreated by her in laws in pakistan foreign')\n",
      "('british banks handled mn of laundered russian money', 'british banks handled nearly million over crore')\n",
      "('this baby looks more ed sheeran than ed sheeran tweets user', 'isla walton is being called a doppelganger of singer ed sheeran')\n",
      "('india ranks nd among world s happiest nations', 'india has been ranked nd in the world s happiest countries category pakistan')\n",
      "('softbank puts e comm veteran kabir misra on snapdeal board', 'kabir misra has been closely involved in managing softbank s')\n",
      "('ed attaches zakir naik led foundation s assets worth cr', 'enforcement directorate has attached zakir naik led islamic research foundation irf')\n",
      "('payments startup airpay raises cr led by kalaari capital', 'mumbai based payments startup airpay raises crore in series a round of funding')\n",
      "('tech billionaires own trillion of the world s wealth', 'there are tech billionaires with a combined net worth of trillion three of')\n",
      "('nawazuddin stars as manto in short film by nandita das', 'nawazuddin siddiqui stars as saadat hasan manto in the short')\n",
      "('one can only speak their minds in bathrooms today jokes srk', 'shah rukh khan jokingly said that one can only speak their minds in bathrooms')\n",
      "('teaser of de niro s hbo tv series the wizard of lies out', 'robert de niro and michelle pfeiffer starrer television series')\n",
      "('year old woman is world s youngest billionaire forbes', 'alexandra andresen is the world s youngest billionaire with a net')\n",
      "('no evidence of trump s wiretapping claim fbi director', 'fbi director james comey says there is no evidence to support president donald trumps claim that')\n",
      "('nearly one lakh dropped out of school in meghalaya in yrs', 'nearly one lakh students have dropped out of schools in meghalaya in the past')\n",
      "('bezos biggest gainer on forbes list as wealth jumps bn', 'amazon ceo jeff bezos has emerged as the biggest gainer on forbes')\n",
      "('l or al s liliane bettencourt named world s richest woman', 'l or al heiress liliane bettencourt is')\n",
      "('what was in the koffee hamper on koffee with karan season', 'karan johar has revealed the contents of the koffee')\n",
      "('i would marry shah rukh as i love his bungalow karan johar', 'karan johar says he would marry shah rukh khan if he was given the')\n",
      "('bjp s up win validates modi s policies chinese state media', 'uttar pradesh election results were a validation for prime minister narendra modi and his decisions like demon')\n",
      "('chinese maths textbooks to be translated for uk schools', 'harpercollins has signed an agreement with china s publishers to translate chinese')\n",
      "('deutsche bank seeks cr by selling shares at discount', 'deutsche bank said it will raise billion over')\n",
      "('bihar university cancels ex delhi law minister s llb degree', 'bihar university cancels jitender singh tomars bachelor of laws llb')\n",
      "('norway replaces denmark as world s happiest country', 'norway has replaced denmark as the world s happiest country iceland')\n",
      "('it firm cognizant to lay off employees reports', 'cognizant technology solutions is expected to lay off at least employees')\n",
      "('us told us there s no significant change in h b visas govt', 'commerce minister nirmala sitharaman said there is no significant change in the h')\n",
      "('shouted at sunil for the first time in years kapil sharma', 'kapil sharma admits he shouted at sunil grover for the first time in five')\n",
      "('india s vidya pillai wins silver at women s world snooker', 'vidya pillai won a silver medal at the women world snooker championship in')\n",
      "('i carry four devices including an iphone oppo vivo founder', 'oppo and vivos co founder duan yongping has said')\n",
      "('lakh in demonetised notes seized from muzaffarnagar', 'police seized demonetised banknotes of and')\n",
      "('wireless tech based on infrared rays offers gbps speed', 'netherlands based researchers have developed a wireless network based on harmless infrared rays a download')\n",
      "('manipur s st bjp cm biren singh wins floor test', 'bjp chief minister nongthombam biren singh won the floor test in the')\n",
      "('new glass bridge opens in china', 'a new glass bridge has opened on mount langya in hebei china')\n",
      "('roger federer wins record tying th indian wells title', 'roger federer defeated compatriot stan wawrinka')\n",
      "('bcci rejects states unjustified demand of l for ipl', 'bcci ceo rahul johri has rejected demand of lakh by')\n",
      "('wade tries dhoni like no look runout gives away extra run', 'aussie wicketkeeper matthew wade attempted a no look runout during the ranch')\n",
      "('panel seeks probe into kingfisher dues worth crore', 'a parliamentary panel has sought a probe into kingfisher airlines accumulation of high levels')\n",
      "('cong asks attorney general to resign over liquor ban issue', 'congress leader vm sudheeran asks attorney general mukul rohatgi to resign')\n",
      "('footballer thanks wife and girlfriend in post game interview', 'mohammed anas accidentally thanked both his wife and girlfriend during a post match interview')\n",
      "('us prez trump calls russia prez putin a tough cookie', 'us president donald trump has described russian president vladimir putin as a tough cookie')\n",
      "('man utd become first club to win premier league matches', 'manchester united beat middlesbrough on sunday to become first club to win')\n",
      "('twitter compares yogi adityanath to actor vin diesel', 'up chief minister yogi adityanath and hollywood actor vin diesel are seen as')\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for i in range(len(soft)):\n",
    "    if soft[i] == 0:\n",
    "        print(rw_sentence_pairs[i])\n",
    "        ctr = ctr + 1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "entail_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
