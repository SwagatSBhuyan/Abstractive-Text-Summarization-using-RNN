{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JN1CXyeuleNS",
    "outputId": "4b4e48fa-c708-482c-eef6-ad4be8bd4265"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WpMYh00ik9qm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\swaga\\Anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import re\n",
    "import torch\n",
    "import json\n",
    "# import torch_xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from preprocess import *\n",
    "from vocabulary import *\n",
    "from model import *\n",
    "from model_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\swaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import seaborn as sns\n",
    "from string import punctuation\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SVaFT9sBnKVi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549361\n",
      "9842\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../../../evaluation/snli/snli_/snli_1.0_train.csv')\n",
    "val_df   = pd.read_csv('../../../evaluation/snli/snli_/snli_1.0_dev.csv')\n",
    "# train_df = pd.read_csv('../datasets/snli/snli_/snli_1.0_train.csv')\n",
    "# val_df   = pd.read_csv('../datasets/snli/snli_/snli_1.0_dev.csv')\n",
    "train_df, val_df = preprocess_text(train_df, val_df)\n",
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['sentence2'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "l2TMjBJDF1uT",
    "outputId": "8b9cda3b-9519-4504-e8ee-c527011f783d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>saudi stock exchange appoints its first female...</td>\n",
       "      <td>saudi stock exchange appointed sarah al ceo i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>what makes fireworks explode</td>\n",
       "      <td>hollywood actor morgan freeman said would lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>60 british firms to increase investment in india</td>\n",
       "      <td>india business council chairperson said 60 br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>railways increase senior citizen women quota</td>\n",
       "      <td>indian railways wednesday increased lower ber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pilots arrested in scotland for drinking befor...</td>\n",
       "      <td>two pilots arrested saturday glasgow scotland...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gold_label                                          sentence1  \\\n",
       "0           0  saudi stock exchange appoints its first female...   \n",
       "1           0                      what makes fireworks explode    \n",
       "2           0  60 british firms to increase investment in india    \n",
       "3           0      railways increase senior citizen women quota    \n",
       "4           0  pilots arrested in scotland for drinking befor...   \n",
       "\n",
       "                                           sentence2  \n",
       "0   saudi stock exchange appointed sarah al ceo i...  \n",
       "1   hollywood actor morgan freeman said would lik...  \n",
       "2   india business council chairperson said 60 br...  \n",
       "3   indian railways wednesday increased lower ber...  \n",
       "4   two pilots arrested saturday glasgow scotland...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rw = pd.read_csv('../datasets/Transformer_generated_summaries.csv', encoding='utf-8')\n",
    "# rw = pd.read_csv('ins.csv', encoding='utf-8')\n",
    "rw = pd.read_csv('test_sets/ins.csv', encoding='utf-8')\n",
    "# rw = pd.read_csv('../datasets/test_data/Transformer_generated_summaries.csv', encoding='utf-8')\n",
    "rw.drop(['text'], axis = 1, inplace=True)\n",
    "rw.rename(columns = {'original_summary':'sentence1'}, inplace = True)\n",
    "rw.rename(columns = {'Predicted_summary':'sentence2'}, inplace = True)\n",
    "gold = [0] * 100\n",
    "rw.insert(loc=0, column='gold_label', value=gold)\n",
    "rw = rw[['gold_label', 'sentence1', 'sentence2']]\n",
    "rw = rw.dropna()\n",
    "rw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rw['sentence2'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nlhVFSEXntjC"
   },
   "outputs": [],
   "source": [
    "train_df['sentence1'] = train_df['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "train_df['sentence2'] = train_df['sentence2'].astype(str).apply(lambda text: clean_text(text))\n",
    "val_df['sentence1'] = val_df['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "val_df['sentence2'] = val_df['sentence2'].astype(str).apply(lambda text: clean_text(text))\n",
    "rw['sentence1'] = rw['sentence1'].astype(str).apply(lambda text: clean_text(text))\n",
    "rw['sentence2'] = rw['sentence2'].astype(str).apply(lambda text: clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [gold_label, sentence1, sentence2]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [gold_label, sentence1, sentence2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[(train_df['sentence1'].str.split().str.len() > 0) & (train_df['sentence2'].str.split().str.len() > 0)]\n",
    "val_df = val_df[(val_df['sentence1'].str.split().str.len() > 0) & (val_df['sentence2'].str.split().str.len() > 0)]\n",
    "print(train_df[(train_df['sentence1'].str.split().str.len() == 0) | (train_df['sentence2'].str.split().str.len() == 0)])\n",
    "print(val_df[(val_df['sentence1'].str.split().str.len() == 0) | (val_df['sentence2'].str.split().str.len() == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "HDGOe_fln-hK",
    "outputId": "b7b3299e-c3ab-4c24-a277-07e42e904efb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>a person on a horse jumps over a broken down a...</td>\n",
       "      <td>a person is training his horse for a competition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>a person on a horse jumps over a broken down a...</td>\n",
       "      <td>a person is at a diner ordering an omelette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entailment</td>\n",
       "      <td>a person on a horse jumps over a broken down a...</td>\n",
       "      <td>a person is outdoors on a horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>children smiling and waving at camera</td>\n",
       "      <td>they are smiling at their parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>children smiling and waving at camera</td>\n",
       "      <td>there are children present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                          sentence1  \\\n",
       "0        neutral  a person on a horse jumps over a broken down a...   \n",
       "1  contradiction  a person on a horse jumps over a broken down a...   \n",
       "2     entailment  a person on a horse jumps over a broken down a...   \n",
       "3        neutral              children smiling and waving at camera   \n",
       "4     entailment              children smiling and waving at camera   \n",
       "\n",
       "                                          sentence2  \n",
       "0  a person is training his horse for a competition  \n",
       "1       a person is at a diner ordering an omelette  \n",
       "2                   a person is outdoors on a horse  \n",
       "3                 they are smiling at their parents  \n",
       "4                        there are children present  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "C1W3s5Ojn_mX",
    "outputId": "a7b88a51-54b3-4fed-d2ff-52ba129a56d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>two women are embracing while holding to go pa...</td>\n",
       "      <td>the sisters are hugging goodbye while holding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>two women are embracing while holding to go pa...</td>\n",
       "      <td>two woman are holding packages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>two women are embracing while holding to go pa...</td>\n",
       "      <td>the men are fighting outside a deli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entailment</td>\n",
       "      <td>two young children in blue jerseys one with th...</td>\n",
       "      <td>two kids in numbered jerseys wash their hands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>two young children in blue jerseys one with th...</td>\n",
       "      <td>two kids at a ballgame wash their hands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label                                          sentence1  \\\n",
       "0        neutral  two women are embracing while holding to go pa...   \n",
       "1     entailment  two women are embracing while holding to go pa...   \n",
       "2  contradiction  two women are embracing while holding to go pa...   \n",
       "3     entailment  two young children in blue jerseys one with th...   \n",
       "4        neutral  two young children in blue jerseys one with th...   \n",
       "\n",
       "                                           sentence2  \n",
       "0  the sisters are hugging goodbye while holding ...  \n",
       "1                     two woman are holding packages  \n",
       "2                the men are fighting outside a deli  \n",
       "3      two kids in numbered jerseys wash their hands  \n",
       "4            two kids at a ballgame wash their hands  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "d1g-SvVOoAfP"
   },
   "outputs": [],
   "source": [
    "train_val_df = pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eihUwlHHoDZm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entailment', 'neutral', 'contradiction'}\n",
      "{'entailment': 0, 'neutral': 1, 'contradiction': 2}\n"
     ]
    }
   ],
   "source": [
    "sentence_pairs, _ = pair_generator(train_val_df)\n",
    "rw_sentence_pairs, __ = pair_generator(rw)\n",
    "train_sentence_pairs, train_sentence_labels = pair_generator(train_df)\n",
    "val_sentence_pairs, val_sentence_labels = pair_generator(val_df)\n",
    "\n",
    "labels = set(train_sentence_labels)\n",
    "print(labels)\n",
    "\n",
    "tag2idx = {word: i for i, word in enumerate(labels)}\n",
    "print(tag2idx)\n",
    "\n",
    "train_labels = [tag2idx[t] for t in train_sentence_labels]\n",
    "val_labels = [tag2idx[t] for t in val_sentence_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPSLm_XnoPKk",
    "outputId": "a79ec791-7bb5-4060-e26f-f0b08d5f7be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 33588\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary()\n",
    "\n",
    "for data in [rw_sentence_pairs]:\n",
    "  for sen in data:\n",
    "    premise    = sen[0]\n",
    "    hypothesis = sen[1]\n",
    "    vocab.addSentence(premise)\n",
    "    vocab.addSentence(hypothesis)\n",
    "\n",
    "for data in [sentence_pairs]:\n",
    "  for sentence_pair in data:\n",
    "    premise    = sentence_pair[0]\n",
    "    hypothesis = sentence_pair[1]\n",
    "    vocab.addSentence(premise)\n",
    "    vocab.addSentence(hypothesis)\n",
    "\n",
    "print(\"Vocab size:\", len(vocab.word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cAAchk1oQb2",
    "outputId": "cbf7f5af-b59c-4b50-83ca-607cecc5efd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 33588\n"
     ]
    }
   ],
   "source": [
    "# vocab = Vocabulary()\n",
    "print(\"Vocab size:\", len(vocab.word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "neSP5WajoSat"
   },
   "outputs": [],
   "source": [
    "index2word = {}\n",
    "for wrd, idx in vocab.word2index.items():\n",
    "    # print(wrd, idx)\n",
    "    index2word[idx] = wrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "T8t7_OJcozF0"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_SIZE = 200\n",
    "VOCAB_SIZE = len(vocab.word2index)\n",
    "TARGET_SIZE = len(tag2idx)\n",
    "HIDDEN_SIZE = 64\n",
    "LEARNING_RATE = 0.005\n",
    "STACKED_LAYERS = 2\n",
    "EMBEDDING_PATH = '../../../../embeddings/google_news/GoogleNews-vectors-negative300.bin'\n",
    "GLOVE_EMBEDDING = '../../../../embeddings/glove/glove.6B.200d.txt'\n",
    "# EMBEDDING_PATH = '../embeddings/google_news/GoogleNews-vectors-negative300.bin'\n",
    "# GLOVE_EMBEDDING = '../embeddings/glove/glove.6B.300d.txt'\n",
    "\n",
    "initiate_model_vocab(vocab, tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1ZKtFMQ6oTVk"
   },
   "outputs": [],
   "source": [
    "train_data = DataSetLoader(get_pair_indices(vocab, train_sentence_pairs), train_labels)\n",
    "val_data   = DataSetLoader(get_pair_indices(vocab, val_sentence_pairs), val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UoB3xqDyRLG",
    "outputId": "505953f5-3b5c-48e5-a52c-ea0980e577a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17168 308\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE, collate_fn=lambda x:x)\n",
    "val_loader   = torch.utils.data.DataLoader(val_data, batch_size = BATCH_SIZE, collate_fn=lambda x:x)\n",
    "\n",
    "print(len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8m4Riv3kzvGI"
   },
   "outputs": [],
   "source": [
    "embeddings_index = load_embeddings(GLOVE_EMBEDDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvnD6Q6yzwbJ",
    "outputId": "17464d30-1cb3-422d-8598-bdc1d177ae81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded count: 27414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33589, 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 1 * np.random.randn(VOCAB_SIZE + 1, EMBEDDING_SIZE)\n",
    "embedded_count = 0\n",
    "for word, lang_word_index in vocab.word2index.items():\n",
    "  if embeddings_index.get(word) is not None:\n",
    "    weights[lang_word_index] = embeddings_index.get(word)\n",
    "    embedded_count += 1\n",
    "\n",
    "print(\"Embedded count:\", embedded_count)\n",
    "del embeddings_index\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9fEl77ezx5X",
    "outputId": "5f001020-d2de-4d7a-c74c-ba3a00b50010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embedding): Embedding(33589, 200)\n",
      "  (lstm): LSTM(200, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (FC_concat1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (FC_concat2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (FC_concat3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (output): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTM(VOCAB_SIZE, HIDDEN_SIZE, TARGET_SIZE, STACKED_LAYERS, weights, True)\n",
    "lstm_model.to(device)\n",
    "print(lstm_model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▎                                                                          | 1/15 [13:04<3:03:00, 784.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:13:04.35\n",
      "Epoch 1: train_loss: 0.7954 train_acc: 0.6569 | val_loss: 0.7022 val_acc: 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▋                                                                     | 2/15 [26:29<2:52:38, 796.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:13:25.56\n",
      "Epoch 2: train_loss: 0.7266 train_acc: 0.6969 | val_loss: 0.6649 val_acc: 0.7278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████                                                                | 3/15 [40:03<2:40:56, 804.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:13:34.02\n",
      "Epoch 3: train_loss: 0.7103 train_acc: 0.7065 | val_loss: 0.6584 val_acc: 0.7292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▎                                                          | 4/15 [52:14<2:22:09, 775.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:12:10.47\n",
      "Epoch 4: train_loss: 0.6997 train_acc: 0.7113 | val_loss: 0.6488 val_acc: 0.7368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████                                                    | 5/15 [1:04:12<2:05:47, 754.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:11:58.15\n",
      "Epoch 5: train_loss: 0.6946 train_acc: 0.7137 | val_loss: 0.6549 val_acc: 0.7323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▏                                              | 6/15 [1:16:14<1:51:33, 743.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:12:02.24\n",
      "Epoch 6: train_loss: 0.6917 train_acc: 0.7144 | val_loss: 0.6483 val_acc: 0.7389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████████▍                                         | 7/15 [1:30:53<1:45:03, 787.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:14:38.89\n",
      "Epoch 7: train_loss: 0.6912 train_acc: 0.7151 | val_loss: 0.6538 val_acc: 0.7313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████████▌                                    | 8/15 [1:45:05<1:34:17, 808.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:14:11.63\n",
      "Epoch 8: train_loss: 0.6875 train_acc: 0.7171 | val_loss: 0.6471 val_acc: 0.7331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████▊                               | 9/15 [1:58:48<1:21:16, 812.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:13:42.87\n",
      "Epoch 9: train_loss: 0.6848 train_acc: 0.7178 | val_loss: 0.6380 val_acc: 0.7399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|███████████████████████████████████████████████████▎                         | 10/15 [2:13:23<1:09:19, 831.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:14:34.83\n",
      "Epoch 10: train_loss: 0.6849 train_acc: 0.7176 | val_loss: 0.6402 val_acc: 0.7341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|█████████████████████████████████████████████████████████▉                     | 11/15 [2:27:17<55:30, 832.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:13:54.37\n",
      "Epoch 11: train_loss: 0.6838 train_acc: 0.7171 | val_loss: 0.6437 val_acc: 0.7347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▏               | 12/15 [2:40:44<41:14, 824.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:13:26.85\n",
      "Epoch 12: train_loss: 0.6816 train_acc: 0.7188 | val_loss: 0.6385 val_acc: 0.7388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████████████████████████████████████████████████████████████████▍          | 13/15 [2:52:59<26:35, 797.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:12:15.39\n",
      "Epoch 13: train_loss: 0.6826 train_acc: 0.7182 | val_loss: 0.6429 val_acc: 0.7399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████████████████████████████████████████████████████████████████████▋     | 14/15 [3:05:25<13:02, 782.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:12:26.17\n",
      "Epoch 14: train_loss: 0.6867 train_acc: 0.7169 | val_loss: 0.6357 val_acc: 0.7399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 15/15 [3:17:30<00:00, 790.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:12:04.81\n",
      "Epoch 15: train_loss: 0.6803 train_acc: 0.7197 | val_loss: 0.6382 val_acc: 0.7412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(lstm_model, train_loader, val_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "embedding.weight \t torch.Size([33589, 200])\n",
      "lstm.weight_ih_l0 \t torch.Size([256, 200])\n",
      "lstm.weight_hh_l0 \t torch.Size([256, 64])\n",
      "lstm.bias_ih_l0 \t torch.Size([256])\n",
      "lstm.bias_hh_l0 \t torch.Size([256])\n",
      "lstm.weight_ih_l0_reverse \t torch.Size([256, 200])\n",
      "lstm.weight_hh_l0_reverse \t torch.Size([256, 64])\n",
      "lstm.bias_ih_l0_reverse \t torch.Size([256])\n",
      "lstm.bias_hh_l0_reverse \t torch.Size([256])\n",
      "lstm.weight_ih_l1 \t torch.Size([256, 128])\n",
      "lstm.weight_hh_l1 \t torch.Size([256, 64])\n",
      "lstm.bias_ih_l1 \t torch.Size([256])\n",
      "lstm.bias_hh_l1 \t torch.Size([256])\n",
      "lstm.weight_ih_l1_reverse \t torch.Size([256, 128])\n",
      "lstm.weight_hh_l1_reverse \t torch.Size([256, 64])\n",
      "lstm.bias_ih_l1_reverse \t torch.Size([256])\n",
      "lstm.bias_hh_l1_reverse \t torch.Size([256])\n",
      "FC_concat1.weight \t torch.Size([128, 256])\n",
      "FC_concat1.bias \t torch.Size([128])\n",
      "FC_concat2.weight \t torch.Size([64, 128])\n",
      "FC_concat2.bias \t torch.Size([64])\n",
      "FC_concat3.weight \t torch.Size([32, 64])\n",
      "FC_concat3.bias \t torch.Size([32])\n",
      "output.weight \t torch.Size([3, 32])\n",
      "output.bias \t torch.Size([3])\n",
      "out.0.weight \t torch.Size([128, 256])\n",
      "out.0.bias \t torch.Size([128])\n",
      "out.3.weight \t torch.Size([64, 128])\n",
      "out.3.bias \t torch.Size([64])\n",
      "out.5.weight \t torch.Size([32, 64])\n",
      "out.5.bias \t torch.Size([32])\n",
      "out.8.weight \t torch.Size([3, 32])\n",
      "out.8.bias \t torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in lstm_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", lstm_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': 257520, 'exp_avg': tensor([[-2.8026e-45, -0.0000e+00, -1.4013e-45,  ..., -2.8026e-45,\n",
      "         -1.4013e-45, -4.2039e-45],\n",
      "        [-4.2039e-45,  4.2039e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -2.9888e-37],\n",
      "        [ 4.3737e-05,  7.0158e-05, -2.9655e-06,  ..., -1.8895e-05,\n",
      "          1.8283e-06, -1.1721e-05],\n",
      "        ...,\n",
      "        [-2.8026e-45,  1.4013e-45, -1.4013e-45,  ...,  1.4013e-45,\n",
      "         -5.6052e-45,  1.4013e-45],\n",
      "        [-2.8026e-45,  1.4013e-45, -4.2039e-45,  ...,  1.4013e-45,\n",
      "         -1.4013e-45,  2.8026e-45],\n",
      "        [ 0.0000e+00, -1.4013e-45,  5.6052e-45,  ..., -2.8026e-45,\n",
      "         -4.2039e-45,  1.4013e-45]], device='cuda:0'), 'exp_avg_sq': tensor([[7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [2.0277e-13, 3.8496e-13, 5.1157e-16,  ..., 2.2916e-13, 3.7312e-14,\n",
      "         2.8334e-12],\n",
      "        [9.0722e-10, 1.7469e-09, 5.8166e-10,  ..., 3.7395e-10, 2.5311e-10,\n",
      "         8.0425e-10],\n",
      "        ...,\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43]], device='cuda:0')}, 1: {'step': 257520, 'exp_avg': tensor([[-2.3674e-05, -8.1681e-05,  6.9038e-06,  ...,  7.3191e-05,\n",
      "         -6.9111e-06,  6.6034e-06],\n",
      "        [ 2.0451e-06,  4.7220e-06, -8.0735e-06,  ..., -4.5431e-06,\n",
      "         -1.1340e-05, -4.8693e-06],\n",
      "        [ 2.8261e-05, -5.0594e-05,  2.4037e-05,  ...,  4.3959e-05,\n",
      "         -2.1318e-05,  2.7229e-05],\n",
      "        ...,\n",
      "        [-1.3770e-05,  1.7382e-05,  6.9943e-05,  ..., -6.6216e-05,\n",
      "         -9.0889e-05, -3.6382e-05],\n",
      "        [-6.7770e-06,  3.1327e-05, -7.8987e-05,  ...,  2.4771e-05,\n",
      "          6.7073e-05, -6.0719e-05],\n",
      "        [-1.1744e-05, -5.6470e-06, -1.2790e-05,  ...,  1.3247e-05,\n",
      "          3.1866e-05, -3.3970e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[2.5501e-08, 4.4183e-08, 3.1578e-08,  ..., 2.4676e-08, 2.8395e-08,\n",
      "         2.4471e-08],\n",
      "        [6.9741e-10, 7.3452e-10, 5.5193e-10,  ..., 4.1733e-10, 5.4289e-10,\n",
      "         7.1876e-10],\n",
      "        [2.1373e-08, 3.7250e-08, 2.4654e-08,  ..., 2.2045e-08, 2.1516e-08,\n",
      "         1.9797e-08],\n",
      "        ...,\n",
      "        [9.2343e-08, 1.0028e-07, 8.8484e-08,  ..., 9.1213e-08, 8.7133e-08,\n",
      "         8.4212e-08],\n",
      "        [6.8170e-08, 7.2096e-08, 7.1891e-08,  ..., 6.9246e-08, 8.7193e-08,\n",
      "         5.7780e-08],\n",
      "        [2.3605e-08, 2.9139e-08, 2.3822e-08,  ..., 2.4836e-08, 2.1168e-08,\n",
      "         2.2325e-08]], device='cuda:0')}, 2: {'step': 257520, 'exp_avg': tensor([[ 3.0625e-05,  1.1707e-05,  1.8202e-05,  ..., -1.3905e-05,\n",
      "         -5.4904e-06, -1.1501e-05],\n",
      "        [-1.1613e-05,  2.9509e-07, -2.5262e-06,  ...,  1.6341e-06,\n",
      "          4.5262e-06, -2.7665e-06],\n",
      "        [ 1.9514e-05, -1.0300e-06,  8.4767e-06,  ...,  1.0577e-05,\n",
      "         -3.0180e-06,  1.4761e-06],\n",
      "        ...,\n",
      "        [ 1.0552e-04, -6.2847e-06,  1.6384e-04,  ..., -1.0308e-04,\n",
      "         -1.2630e-04,  1.2628e-05],\n",
      "        [ 1.7647e-05,  2.3188e-05, -7.4961e-06,  ..., -2.7077e-05,\n",
      "         -1.1368e-05,  9.3016e-06],\n",
      "        [-1.9011e-05, -1.1591e-06, -2.9944e-05,  ...,  3.5728e-05,\n",
      "          1.4130e-05, -1.7538e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[5.6385e-08, 2.9373e-10, 2.1142e-08,  ..., 2.3252e-08, 1.9969e-08,\n",
      "         5.1021e-09],\n",
      "        [7.2080e-10, 8.2796e-12, 3.8158e-10,  ..., 3.1796e-10, 2.0371e-10,\n",
      "         6.2395e-11],\n",
      "        [3.8369e-08, 1.8754e-10, 1.3704e-08,  ..., 1.7680e-08, 1.2352e-08,\n",
      "         5.3037e-09],\n",
      "        ...,\n",
      "        [1.8917e-07, 1.2097e-09, 7.5811e-08,  ..., 1.2652e-07, 9.2437e-08,\n",
      "         2.5931e-08],\n",
      "        [1.2140e-07, 7.7234e-10, 5.6616e-08,  ..., 7.8308e-08, 1.2083e-07,\n",
      "         9.4620e-09],\n",
      "        [2.8347e-08, 2.2296e-10, 1.1274e-08,  ..., 2.2612e-08, 1.8106e-08,\n",
      "         9.3965e-09]], device='cuda:0')}, 3: {'step': 257520, 'exp_avg': tensor([-5.5500e-04, -4.9543e-06, -6.3235e-05, -1.8968e-04, -2.2324e-05,\n",
      "        -2.4299e-06,  4.8082e-05,  5.9718e-05,  1.7752e-05, -2.9947e-04,\n",
      "         2.6780e-04,  3.1206e-04, -7.5104e-04,  2.5766e-05,  4.8502e-04,\n",
      "         8.4771e-05,  1.1339e-05,  2.5511e-05,  1.0760e-04,  4.3680e-04,\n",
      "         1.5861e-04,  2.1900e-04, -1.8406e-04, -5.1015e-06, -3.5688e-05,\n",
      "         1.0756e-04, -3.4928e-05,  4.2924e-05, -5.1854e-04, -1.5897e-05,\n",
      "         1.0373e-04,  3.2614e-05,  1.4917e-04, -1.0700e-04, -9.7122e-05,\n",
      "         1.1988e-04,  5.7347e-05,  1.2537e-04,  3.3967e-04, -1.3541e-04,\n",
      "        -5.9271e-04, -4.5597e-05,  1.7371e-04,  3.2916e-05, -1.6883e-05,\n",
      "         4.2473e-05,  3.4827e-04, -2.1451e-05,  3.9585e-05,  4.6393e-04,\n",
      "         2.4820e-04,  6.9481e-05, -4.1312e-04,  6.0458e-05, -1.2331e-05,\n",
      "        -5.9497e-05, -6.5079e-04, -3.7475e-05, -2.2726e-04,  3.3536e-05,\n",
      "        -1.6756e-04,  7.1754e-04,  4.5602e-05, -4.3969e-05, -1.9031e-05,\n",
      "        -1.1956e-05, -8.2442e-05,  3.6704e-06, -2.2287e-05,  1.0003e-05,\n",
      "         1.7456e-05,  3.1105e-06, -2.6157e-05,  1.5181e-04,  1.7085e-04,\n",
      "        -3.0840e-05,  6.2865e-04,  1.2331e-05,  6.5840e-05, -7.0510e-05,\n",
      "        -9.9703e-06,  3.8199e-05,  5.5129e-05, -1.1353e-04,  1.5034e-05,\n",
      "         2.7550e-04, -5.6990e-05, -2.7152e-04,  1.9771e-04, -1.3895e-04,\n",
      "        -2.8586e-05, -3.6607e-05, -3.3506e-04, -2.3466e-04, -3.9979e-06,\n",
      "        -1.1225e-04,  2.6443e-05, -5.6249e-05,  1.5434e-04,  4.0334e-05,\n",
      "        -1.2968e-04,  1.2120e-04, -6.0276e-05, -4.6688e-04, -2.7940e-04,\n",
      "         3.2411e-06,  1.4254e-04,  7.9007e-07, -1.5003e-05,  2.7684e-06,\n",
      "         5.8568e-04, -3.3868e-05,  3.2765e-05, -2.7621e-04,  2.8384e-04,\n",
      "         2.1478e-05, -2.2237e-04, -3.0515e-05,  2.6596e-05, -3.1579e-05,\n",
      "        -2.8453e-04, -2.2762e-05,  1.6578e-04, -5.3038e-04,  2.0738e-04,\n",
      "        -1.2505e-05,  1.7562e-04, -1.2182e-05, -3.9086e-04, -2.0555e-05,\n",
      "        -8.1538e-04, -3.5018e-04, -1.2542e-05, -3.3371e-04,  3.4357e-05,\n",
      "         3.2325e-06, -7.7389e-05,  3.2691e-04, -4.8253e-05, -7.4598e-05,\n",
      "        -8.1505e-04,  2.8148e-04, -5.7540e-04, -2.5709e-04, -3.5044e-04,\n",
      "        -9.0673e-05, -6.1951e-05,  4.6812e-04,  1.5879e-04,  1.4981e-03,\n",
      "         1.4903e-04,  6.2402e-04,  2.1499e-04,  2.2645e-04, -8.0235e-04,\n",
      "        -2.6656e-04,  6.1379e-04,  3.1553e-04,  1.7330e-04,  7.8209e-05,\n",
      "         8.2866e-04,  6.2119e-04, -1.9451e-04,  1.6089e-04,  5.4403e-05,\n",
      "         2.0855e-04, -1.6839e-04,  3.9724e-04,  2.4919e-04,  1.1834e-04,\n",
      "         1.1317e-04, -5.0238e-05,  5.4959e-05,  1.6325e-05,  2.0171e-04,\n",
      "        -4.7327e-05, -3.6821e-07, -7.9525e-04,  6.7139e-04, -6.0943e-05,\n",
      "        -4.5821e-04, -6.1052e-05,  3.7103e-04, -1.1379e-04, -1.1814e-03,\n",
      "        -1.2097e-04, -4.9933e-05,  1.2916e-03,  2.3713e-04,  1.4192e-04,\n",
      "         7.1871e-04,  2.7524e-05, -2.0521e-03, -1.4798e-05,  1.6974e-04,\n",
      "        -2.5777e-04, -2.4749e-05, -1.7218e-04,  2.3111e-04,  7.2696e-05,\n",
      "         2.6077e-05,  1.4577e-04, -1.8484e-04,  1.0964e-03,  2.4719e-04,\n",
      "         7.6331e-04,  2.9262e-04,  2.7171e-04, -1.9250e-04,  1.9652e-05,\n",
      "         2.5766e-04,  6.8189e-04,  2.9696e-04, -4.5406e-04, -3.3103e-04,\n",
      "         5.0311e-04, -2.5164e-04,  1.4428e-04,  1.4517e-04,  7.6580e-05,\n",
      "        -8.6707e-04,  4.3810e-05,  1.2641e-04, -8.3087e-05,  3.3062e-04,\n",
      "        -2.7948e-04,  4.9048e-04,  1.2859e-04, -4.6135e-04,  3.3933e-04,\n",
      "         6.9530e-04, -4.8756e-04, -9.8563e-04, -7.8196e-05,  1.7903e-04,\n",
      "         3.8104e-05, -1.3771e-04,  5.2559e-04,  5.5452e-04, -1.7298e-05,\n",
      "         3.9429e-05,  6.1605e-04,  1.6598e-03,  8.9069e-05, -6.9949e-04,\n",
      "         8.3583e-05,  3.9292e-05, -9.6283e-05, -7.5214e-04, -5.8433e-05,\n",
      "        -1.1547e-04,  2.7871e-04, -4.6520e-04,  6.3212e-04,  5.3293e-04,\n",
      "         2.9341e-05], device='cuda:0'), 'exp_avg_sq': tensor([9.0385e-07, 1.7596e-08, 6.6354e-07, 3.2614e-07, 2.2964e-08, 2.4055e-07,\n",
      "        8.8069e-07, 5.0560e-07, 2.2042e-07, 1.8986e-06, 1.1137e-06, 7.7149e-07,\n",
      "        5.8898e-06, 6.0915e-07, 2.3605e-06, 2.7706e-07, 2.3176e-07, 8.9715e-08,\n",
      "        4.0445e-07, 9.7731e-07, 4.2902e-07, 3.1318e-06, 2.4015e-07, 1.1800e-06,\n",
      "        2.3056e-06, 4.0914e-07, 7.1556e-07, 3.4993e-07, 2.6641e-06, 3.2864e-06,\n",
      "        3.1696e-07, 2.8076e-07, 8.0231e-07, 7.6776e-07, 3.8920e-06, 4.2441e-07,\n",
      "        2.4980e-07, 4.1866e-07, 1.1928e-06, 1.5448e-06, 2.9957e-06, 1.2521e-07,\n",
      "        5.4324e-07, 4.6709e-08, 4.1858e-07, 1.9520e-07, 3.0442e-06, 1.8258e-07,\n",
      "        3.0713e-07, 7.7375e-07, 6.8914e-07, 6.6316e-08, 2.0205e-07, 1.1001e-07,\n",
      "        7.3200e-07, 1.3194e-07, 1.0886e-06, 1.0763e-08, 1.3365e-06, 6.0089e-06,\n",
      "        9.3796e-07, 3.6655e-06, 1.0056e-06, 3.3818e-07, 3.4498e-07, 2.8778e-09,\n",
      "        2.1475e-07, 5.0168e-08, 2.6149e-09, 3.9951e-08, 3.6727e-07, 4.9605e-08,\n",
      "        5.9482e-08, 1.1534e-06, 4.7157e-07, 3.5179e-07, 4.8918e-06, 7.1971e-07,\n",
      "        1.2274e-07, 1.8326e-07, 4.4510e-08, 3.9010e-08, 1.0029e-07, 5.0365e-07,\n",
      "        6.5969e-08, 1.2527e-06, 1.2351e-07, 1.7283e-06, 1.0275e-06, 1.9013e-07,\n",
      "        1.8426e-07, 5.3993e-08, 1.5142e-06, 1.8797e-06, 3.4252e-08, 3.5117e-08,\n",
      "        1.9329e-07, 1.2379e-07, 2.5241e-06, 2.1409e-07, 3.4571e-07, 1.2224e-07,\n",
      "        5.6420e-07, 6.8404e-07, 1.2683e-06, 8.8862e-09, 2.3749e-07, 6.0051e-09,\n",
      "        2.6291e-07, 7.6217e-08, 1.8828e-06, 1.8492e-08, 5.0509e-08, 4.7104e-07,\n",
      "        2.0114e-06, 8.2712e-09, 8.6525e-08, 7.4960e-08, 7.9727e-08, 3.3730e-08,\n",
      "        4.9109e-07, 1.1450e-09, 2.3674e-07, 2.6634e-06, 1.3238e-06, 4.8984e-07,\n",
      "        5.5048e-07, 5.6418e-08, 1.1148e-05, 9.0352e-08, 2.8113e-06, 1.2819e-06,\n",
      "        1.0081e-07, 1.6843e-06, 2.3923e-06, 1.6399e-06, 1.2277e-06, 4.8724e-06,\n",
      "        3.5623e-06, 6.6864e-06, 1.0985e-05, 2.1747e-06, 7.3964e-06, 1.7562e-06,\n",
      "        9.7238e-07, 7.4633e-07, 1.9175e-06, 4.5662e-06, 1.4575e-06, 6.9593e-06,\n",
      "        1.2737e-06, 6.5767e-06, 9.5074e-06, 2.2935e-06, 1.1723e-06, 1.1351e-06,\n",
      "        5.3494e-06, 1.8660e-06, 1.6049e-06, 3.2422e-07, 2.0199e-06, 6.0716e-06,\n",
      "        1.4830e-05, 8.8982e-07, 1.1247e-06, 3.2677e-06, 7.0849e-06, 2.3207e-06,\n",
      "        8.3779e-07, 4.0469e-07, 1.4313e-06, 1.1865e-07, 1.3699e-06, 1.0469e-06,\n",
      "        1.4873e-06, 5.2230e-07, 1.3567e-06, 3.4399e-06, 7.9872e-06, 1.6979e-07,\n",
      "        1.0307e-06, 6.7787e-07, 1.0766e-06, 1.0708e-06, 3.8313e-06, 6.2746e-08,\n",
      "        3.3677e-06, 9.2477e-06, 2.3667e-06, 1.5370e-05, 3.8926e-06, 1.3172e-06,\n",
      "        7.0089e-06, 2.8210e-08, 2.4175e-06, 9.6689e-07, 3.2939e-08, 1.7484e-06,\n",
      "        1.7718e-06, 8.1018e-07, 1.0500e-06, 4.8200e-06, 2.2286e-06, 6.3001e-06,\n",
      "        7.1094e-06, 3.7235e-06, 2.1120e-06, 2.0552e-06, 8.8072e-07, 4.8572e-07,\n",
      "        1.8611e-06, 2.1559e-06, 1.8878e-06, 6.0656e-06, 1.1445e-06, 5.4557e-06,\n",
      "        5.5164e-06, 2.1691e-06, 1.7530e-06, 2.0490e-06, 5.1664e-06, 5.3420e-06,\n",
      "        1.6850e-06, 4.5080e-07, 1.4217e-06, 4.2989e-06, 9.2087e-06, 6.9528e-07,\n",
      "        3.5597e-06, 1.5214e-06, 5.1738e-06, 3.4024e-06, 6.6833e-06, 3.4365e-07,\n",
      "        1.0834e-06, 7.2278e-08, 9.8286e-07, 9.5935e-07, 3.3206e-06, 4.2134e-07,\n",
      "        1.2071e-06, 4.3289e-06, 6.8329e-06, 1.6027e-07, 9.9796e-07, 6.8201e-07,\n",
      "        1.1500e-06, 7.4196e-07, 3.5669e-06, 2.0477e-08, 4.3601e-06, 2.6752e-06,\n",
      "        4.3021e-06, 4.1492e-06, 2.6802e-06, 7.3463e-07], device='cuda:0')}, 4: {'step': 257520, 'exp_avg': tensor([-5.5500e-04, -4.9543e-06, -6.3235e-05, -1.8968e-04, -2.2324e-05,\n",
      "        -2.4299e-06,  4.8082e-05,  5.9718e-05,  1.7752e-05, -2.9947e-04,\n",
      "         2.6780e-04,  3.1206e-04, -7.5104e-04,  2.5766e-05,  4.8502e-04,\n",
      "         8.4771e-05,  1.1339e-05,  2.5511e-05,  1.0760e-04,  4.3680e-04,\n",
      "         1.5861e-04,  2.1900e-04, -1.8406e-04, -5.1015e-06, -3.5688e-05,\n",
      "         1.0756e-04, -3.4928e-05,  4.2924e-05, -5.1854e-04, -1.5897e-05,\n",
      "         1.0373e-04,  3.2614e-05,  1.4917e-04, -1.0700e-04, -9.7122e-05,\n",
      "         1.1988e-04,  5.7347e-05,  1.2537e-04,  3.3967e-04, -1.3541e-04,\n",
      "        -5.9271e-04, -4.5597e-05,  1.7371e-04,  3.2916e-05, -1.6883e-05,\n",
      "         4.2473e-05,  3.4827e-04, -2.1451e-05,  3.9585e-05,  4.6393e-04,\n",
      "         2.4820e-04,  6.9481e-05, -4.1312e-04,  6.0458e-05, -1.2331e-05,\n",
      "        -5.9497e-05, -6.5079e-04, -3.7475e-05, -2.2726e-04,  3.3536e-05,\n",
      "        -1.6756e-04,  7.1754e-04,  4.5602e-05, -4.3969e-05, -1.9031e-05,\n",
      "        -1.1956e-05, -8.2442e-05,  3.6704e-06, -2.2287e-05,  1.0003e-05,\n",
      "         1.7456e-05,  3.1105e-06, -2.6157e-05,  1.5181e-04,  1.7085e-04,\n",
      "        -3.0840e-05,  6.2865e-04,  1.2331e-05,  6.5840e-05, -7.0510e-05,\n",
      "        -9.9703e-06,  3.8199e-05,  5.5129e-05, -1.1353e-04,  1.5034e-05,\n",
      "         2.7550e-04, -5.6990e-05, -2.7152e-04,  1.9771e-04, -1.3895e-04,\n",
      "        -2.8586e-05, -3.6607e-05, -3.3506e-04, -2.3466e-04, -3.9979e-06,\n",
      "        -1.1225e-04,  2.6443e-05, -5.6249e-05,  1.5434e-04,  4.0334e-05,\n",
      "        -1.2968e-04,  1.2120e-04, -6.0276e-05, -4.6688e-04, -2.7940e-04,\n",
      "         3.2411e-06,  1.4254e-04,  7.9007e-07, -1.5003e-05,  2.7684e-06,\n",
      "         5.8568e-04, -3.3868e-05,  3.2765e-05, -2.7621e-04,  2.8384e-04,\n",
      "         2.1478e-05, -2.2237e-04, -3.0515e-05,  2.6596e-05, -3.1579e-05,\n",
      "        -2.8453e-04, -2.2762e-05,  1.6578e-04, -5.3038e-04,  2.0738e-04,\n",
      "        -1.2505e-05,  1.7562e-04, -1.2182e-05, -3.9086e-04, -2.0555e-05,\n",
      "        -8.1538e-04, -3.5018e-04, -1.2542e-05, -3.3371e-04,  3.4357e-05,\n",
      "         3.2325e-06, -7.7389e-05,  3.2691e-04, -4.8253e-05, -7.4598e-05,\n",
      "        -8.1504e-04,  2.8148e-04, -5.7539e-04, -2.5709e-04, -3.5044e-04,\n",
      "        -9.0673e-05, -6.1951e-05,  4.6812e-04,  1.5879e-04,  1.4981e-03,\n",
      "         1.4903e-04,  6.2403e-04,  2.1499e-04,  2.2645e-04, -8.0235e-04,\n",
      "        -2.6656e-04,  6.1375e-04,  3.1553e-04,  1.7330e-04,  7.8209e-05,\n",
      "         8.2867e-04,  6.2119e-04, -1.9450e-04,  1.6089e-04,  5.4404e-05,\n",
      "         2.0855e-04, -1.6839e-04,  3.9724e-04,  2.4919e-04,  1.1834e-04,\n",
      "         1.1317e-04, -5.0238e-05,  5.4958e-05,  1.6325e-05,  2.0171e-04,\n",
      "        -4.7327e-05, -3.6821e-07, -7.9525e-04,  6.7139e-04, -6.0943e-05,\n",
      "        -4.5821e-04, -6.1052e-05,  3.7103e-04, -1.1379e-04, -1.1814e-03,\n",
      "        -1.2097e-04, -4.9933e-05,  1.2916e-03,  2.3713e-04,  1.4192e-04,\n",
      "         7.1871e-04,  2.7524e-05, -2.0521e-03, -1.4798e-05,  1.6974e-04,\n",
      "        -2.5777e-04, -2.4749e-05, -1.7218e-04,  2.3111e-04,  7.2696e-05,\n",
      "         2.6077e-05,  1.4577e-04, -1.8484e-04,  1.0964e-03,  2.4720e-04,\n",
      "         7.6331e-04,  2.9261e-04,  2.7171e-04, -1.9250e-04,  1.9652e-05,\n",
      "         2.5766e-04,  6.8189e-04,  2.9696e-04, -4.5406e-04, -3.3103e-04,\n",
      "         5.0311e-04, -2.5164e-04,  1.4429e-04,  1.4517e-04,  7.6580e-05,\n",
      "        -8.6707e-04,  4.3808e-05,  1.2641e-04, -8.3087e-05,  3.3062e-04,\n",
      "        -2.7948e-04,  4.9048e-04,  1.2859e-04, -4.6135e-04,  3.3933e-04,\n",
      "         6.9530e-04, -4.8756e-04, -9.8563e-04, -7.8196e-05,  1.7903e-04,\n",
      "         3.8104e-05, -1.3771e-04,  5.2559e-04,  5.5452e-04, -1.7298e-05,\n",
      "         3.9429e-05,  6.1605e-04,  1.6598e-03,  8.9069e-05, -6.9949e-04,\n",
      "         8.3583e-05,  3.9292e-05, -9.6283e-05, -7.5214e-04, -5.8433e-05,\n",
      "        -1.1547e-04,  2.7871e-04, -4.6520e-04,  6.3212e-04,  5.3293e-04,\n",
      "         2.9341e-05], device='cuda:0'), 'exp_avg_sq': tensor([9.0385e-07, 1.7596e-08, 6.6354e-07, 3.2614e-07, 2.2964e-08, 2.4055e-07,\n",
      "        8.8069e-07, 5.0560e-07, 2.2042e-07, 1.8986e-06, 1.1137e-06, 7.7149e-07,\n",
      "        5.8898e-06, 6.0915e-07, 2.3605e-06, 2.7706e-07, 2.3176e-07, 8.9715e-08,\n",
      "        4.0445e-07, 9.7731e-07, 4.2902e-07, 3.1318e-06, 2.4015e-07, 1.1800e-06,\n",
      "        2.3056e-06, 4.0914e-07, 7.1556e-07, 3.4993e-07, 2.6641e-06, 3.2864e-06,\n",
      "        3.1696e-07, 2.8076e-07, 8.0231e-07, 7.6776e-07, 3.8920e-06, 4.2441e-07,\n",
      "        2.4980e-07, 4.1866e-07, 1.1928e-06, 1.5448e-06, 2.9957e-06, 1.2521e-07,\n",
      "        5.4324e-07, 4.6709e-08, 4.1858e-07, 1.9520e-07, 3.0442e-06, 1.8258e-07,\n",
      "        3.0713e-07, 7.7375e-07, 6.8914e-07, 6.6316e-08, 2.0205e-07, 1.1001e-07,\n",
      "        7.3200e-07, 1.3194e-07, 1.0886e-06, 1.0763e-08, 1.3365e-06, 6.0089e-06,\n",
      "        9.3796e-07, 3.6655e-06, 1.0056e-06, 3.3818e-07, 3.4498e-07, 2.8778e-09,\n",
      "        2.1475e-07, 5.0168e-08, 2.6149e-09, 3.9951e-08, 3.6727e-07, 4.9605e-08,\n",
      "        5.9482e-08, 1.1534e-06, 4.7157e-07, 3.5179e-07, 4.8918e-06, 7.1971e-07,\n",
      "        1.2274e-07, 1.8326e-07, 4.4510e-08, 3.9010e-08, 1.0029e-07, 5.0365e-07,\n",
      "        6.5969e-08, 1.2527e-06, 1.2351e-07, 1.7283e-06, 1.0275e-06, 1.9013e-07,\n",
      "        1.8426e-07, 5.3993e-08, 1.5142e-06, 1.8797e-06, 3.4252e-08, 3.5117e-08,\n",
      "        1.9329e-07, 1.2379e-07, 2.5241e-06, 2.1409e-07, 3.4571e-07, 1.2224e-07,\n",
      "        5.6420e-07, 6.8404e-07, 1.2683e-06, 8.8862e-09, 2.3749e-07, 6.0051e-09,\n",
      "        2.6291e-07, 7.6217e-08, 1.8828e-06, 1.8492e-08, 5.0509e-08, 4.7104e-07,\n",
      "        2.0114e-06, 8.2712e-09, 8.6525e-08, 7.4960e-08, 7.9727e-08, 3.3730e-08,\n",
      "        4.9109e-07, 1.1450e-09, 2.3674e-07, 2.6634e-06, 1.3238e-06, 4.8984e-07,\n",
      "        5.5048e-07, 5.6418e-08, 1.1148e-05, 9.0352e-08, 2.8113e-06, 1.2819e-06,\n",
      "        1.0081e-07, 1.6843e-06, 2.3923e-06, 1.6399e-06, 1.2277e-06, 4.8724e-06,\n",
      "        3.5623e-06, 6.6864e-06, 1.0985e-05, 2.1747e-06, 7.3964e-06, 1.7562e-06,\n",
      "        9.7238e-07, 7.4633e-07, 1.9175e-06, 4.5662e-06, 1.4575e-06, 6.9593e-06,\n",
      "        1.2737e-06, 6.5767e-06, 9.5074e-06, 2.2935e-06, 1.1723e-06, 1.1351e-06,\n",
      "        5.3494e-06, 1.8660e-06, 1.6049e-06, 3.2422e-07, 2.0199e-06, 6.0716e-06,\n",
      "        1.4830e-05, 8.8982e-07, 1.1247e-06, 3.2677e-06, 7.0849e-06, 2.3207e-06,\n",
      "        8.3779e-07, 4.0469e-07, 1.4313e-06, 1.1865e-07, 1.3699e-06, 1.0469e-06,\n",
      "        1.4873e-06, 5.2230e-07, 1.3567e-06, 3.4399e-06, 7.9872e-06, 1.6979e-07,\n",
      "        1.0307e-06, 6.7787e-07, 1.0766e-06, 1.0708e-06, 3.8313e-06, 6.2746e-08,\n",
      "        3.3677e-06, 9.2477e-06, 2.3667e-06, 1.5370e-05, 3.8926e-06, 1.3172e-06,\n",
      "        7.0089e-06, 2.8210e-08, 2.4175e-06, 9.6689e-07, 3.2939e-08, 1.7484e-06,\n",
      "        1.7718e-06, 8.1018e-07, 1.0500e-06, 4.8200e-06, 2.2286e-06, 6.3001e-06,\n",
      "        7.1094e-06, 3.7235e-06, 2.1120e-06, 2.0552e-06, 8.8072e-07, 4.8572e-07,\n",
      "        1.8611e-06, 2.1559e-06, 1.8878e-06, 6.0656e-06, 1.1445e-06, 5.4557e-06,\n",
      "        5.5164e-06, 2.1691e-06, 1.7530e-06, 2.0490e-06, 5.1664e-06, 5.3420e-06,\n",
      "        1.6850e-06, 4.5080e-07, 1.4217e-06, 4.2989e-06, 9.2087e-06, 6.9528e-07,\n",
      "        3.5597e-06, 1.5214e-06, 5.1738e-06, 3.4024e-06, 6.6833e-06, 3.4365e-07,\n",
      "        1.0834e-06, 7.2278e-08, 9.8286e-07, 9.5935e-07, 3.3206e-06, 4.2134e-07,\n",
      "        1.2071e-06, 4.3289e-06, 6.8329e-06, 1.6027e-07, 9.9796e-07, 6.8201e-07,\n",
      "        1.1500e-06, 7.4196e-07, 3.5669e-06, 2.0477e-08, 4.3601e-06, 2.6752e-06,\n",
      "        4.3021e-06, 4.1492e-06, 2.6802e-06, 7.3463e-07], device='cuda:0')}, 5: {'step': 257520, 'exp_avg': tensor([[-3.1510e-05,  1.3682e-05,  7.3839e-06,  ..., -9.2967e-05,\n",
      "          6.2774e-05, -4.1527e-05],\n",
      "        [-6.1137e-05, -2.3305e-05,  1.6191e-05,  ..., -1.9384e-05,\n",
      "         -3.9093e-05,  2.8207e-05],\n",
      "        [-3.5224e-05, -4.4720e-05,  4.3772e-05,  ...,  3.6949e-05,\n",
      "          2.1352e-05, -8.5786e-05],\n",
      "        ...,\n",
      "        [-9.7665e-05,  6.1195e-05, -3.1194e-05,  ..., -3.9559e-05,\n",
      "          2.1197e-05,  1.2394e-04],\n",
      "        [-7.5799e-05, -1.0406e-04,  2.1716e-04,  ...,  5.3719e-05,\n",
      "          8.1057e-05, -1.0981e-04],\n",
      "        [-1.3120e-04, -2.0846e-05, -9.4248e-05,  ...,  3.8180e-05,\n",
      "          1.0275e-04, -1.0973e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[2.7776e-08, 3.6343e-08, 3.1074e-08,  ..., 2.7478e-08, 3.8483e-08,\n",
      "         2.3536e-08],\n",
      "        [3.3306e-08, 2.7196e-08, 2.6790e-08,  ..., 1.6435e-08, 2.2021e-08,\n",
      "         2.4337e-08],\n",
      "        [1.6275e-07, 1.6023e-07, 1.6956e-07,  ..., 1.2156e-07, 1.4367e-07,\n",
      "         1.2820e-07],\n",
      "        ...,\n",
      "        [9.7588e-08, 9.5167e-08, 7.0668e-08,  ..., 6.8554e-08, 8.1781e-08,\n",
      "         6.8533e-08],\n",
      "        [2.9670e-07, 3.0636e-07, 2.9025e-07,  ..., 2.5027e-07, 3.7476e-07,\n",
      "         1.8303e-07],\n",
      "        [1.6268e-07, 1.6701e-07, 1.7319e-07,  ..., 1.1589e-07, 1.9999e-07,\n",
      "         1.4349e-07]], device='cuda:0')}, 6: {'step': 257520, 'exp_avg': tensor([[-1.3148e-06, -3.4305e-05,  4.6113e-06,  ...,  3.5748e-06,\n",
      "         -1.0938e-04,  1.2688e-05],\n",
      "        [-1.4559e-05,  2.8550e-06,  5.8145e-05,  ...,  5.5887e-05,\n",
      "         -1.7769e-04, -6.3964e-05],\n",
      "        [-2.0402e-05,  5.3962e-05,  3.5401e-05,  ...,  3.1589e-04,\n",
      "         -1.7019e-06,  3.0903e-05],\n",
      "        ...,\n",
      "        [ 6.5421e-06,  7.2116e-06, -2.3062e-05,  ...,  2.7557e-04,\n",
      "         -2.3071e-04, -1.3626e-04],\n",
      "        [-1.1804e-05, -7.8643e-05,  5.3076e-05,  ...,  3.3083e-04,\n",
      "          1.2971e-04,  6.1018e-04],\n",
      "        [ 6.5408e-05,  1.0647e-04, -4.3855e-06,  ...,  3.6515e-04,\n",
      "          4.5208e-04, -2.4340e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[8.2603e-09, 3.1564e-09, 1.9258e-08,  ..., 1.0974e-07, 5.2666e-08,\n",
      "         5.8105e-08],\n",
      "        [9.3958e-09, 3.6477e-09, 1.6407e-08,  ..., 9.1858e-08, 4.8996e-08,\n",
      "         4.2955e-08],\n",
      "        [7.0407e-08, 2.1622e-08, 1.7004e-07,  ..., 5.9595e-07, 5.0573e-07,\n",
      "         4.0006e-07],\n",
      "        ...,\n",
      "        [4.4576e-08, 1.5228e-08, 6.4568e-08,  ..., 6.3712e-07, 2.8165e-07,\n",
      "         2.1859e-07],\n",
      "        [1.7669e-07, 6.4199e-08, 4.3675e-07,  ..., 1.6792e-06, 2.2309e-06,\n",
      "         8.9160e-07],\n",
      "        [1.1192e-07, 3.6320e-08, 3.2054e-07,  ..., 1.3201e-06, 8.6280e-07,\n",
      "         1.1215e-06]], device='cuda:0')}, 7: {'step': 257520, 'exp_avg': tensor([ 4.3589e-04, -2.8081e-04,  3.5461e-05, -7.0766e-04,  7.4951e-05,\n",
      "        -6.4978e-05, -8.7203e-05,  2.3683e-05,  3.7365e-04,  1.9483e-04,\n",
      "        -1.2080e-05, -4.2174e-05,  3.7832e-04, -4.6442e-04, -1.9524e-04,\n",
      "        -7.6864e-04, -1.2952e-04, -5.7544e-04, -3.5239e-04,  2.2398e-04,\n",
      "         1.9057e-03,  3.6770e-04, -6.2262e-05, -5.8368e-05, -3.2405e-04,\n",
      "         1.4330e-04,  4.0433e-05, -7.8691e-05,  2.4954e-04, -2.7107e-04,\n",
      "         2.5259e-04,  1.8638e-04,  1.4354e-04, -3.1443e-04,  1.9483e-04,\n",
      "        -5.9575e-05, -2.3194e-04, -4.6562e-05,  5.1780e-06,  5.4482e-05,\n",
      "         4.8157e-05,  5.2123e-05,  9.1160e-04,  4.2128e-04, -6.3763e-04,\n",
      "         6.4345e-04, -1.3086e-05,  3.7056e-05, -7.4535e-06,  5.2291e-04,\n",
      "        -4.7301e-04, -5.3553e-05,  3.6088e-05,  2.7950e-05,  6.7054e-05,\n",
      "         2.6837e-04, -2.4332e-04,  8.5936e-05,  3.6247e-05, -1.2967e-04,\n",
      "         4.6141e-04, -6.7391e-04,  8.4376e-05, -3.0422e-04,  7.5311e-05,\n",
      "         1.4380e-04,  1.7775e-04,  1.0782e-04, -1.9720e-04,  8.2913e-05,\n",
      "        -2.3808e-05, -1.0047e-05,  9.7577e-04,  5.2408e-05, -8.8429e-05,\n",
      "        -1.8243e-05, -3.6676e-04,  3.2875e-04,  8.8910e-05,  3.1636e-04,\n",
      "         1.1270e-04,  2.0160e-05,  7.4191e-06, -4.3006e-04,  1.9666e-04,\n",
      "        -4.4604e-05,  2.1622e-05, -1.4623e-05,  1.0522e-05,  3.6551e-06,\n",
      "        -5.3968e-07,  1.3259e-05, -1.3778e-04, -3.9889e-05,  1.9795e-05,\n",
      "        -3.4662e-06,  2.1329e-04,  3.6257e-05, -5.5474e-05, -5.2616e-06,\n",
      "        -7.4013e-05,  2.9852e-04, -2.7418e-06,  5.1739e-05,  2.7462e-04,\n",
      "        -5.3204e-06,  4.4958e-05,  1.4695e-04, -9.6454e-05,  6.5257e-04,\n",
      "        -6.7583e-05, -1.6815e-05, -4.4614e-05,  7.7207e-05, -6.4861e-05,\n",
      "        -4.7937e-06,  3.6524e-05,  7.6267e-05,  5.0116e-05,  2.3235e-04,\n",
      "         5.6177e-06, -3.9394e-06, -2.3565e-05,  7.6034e-05,  1.8983e-04,\n",
      "         2.7087e-03,  4.2296e-04,  1.6876e-04,  2.2282e-04, -2.5502e-04,\n",
      "         5.8539e-04, -5.3142e-04,  5.1496e-04, -4.4335e-04, -8.2376e-05,\n",
      "        -4.9122e-05, -1.8013e-03,  6.2149e-04, -3.6889e-04,  2.9335e-04,\n",
      "        -2.1359e-04,  2.8003e-04, -7.2092e-05, -8.1961e-04,  8.9878e-05,\n",
      "         8.9766e-04, -6.9806e-04, -1.1946e-04, -1.0109e-04, -4.2190e-04,\n",
      "         2.2788e-04,  2.9038e-05, -4.6819e-04, -1.8973e-04,  1.2739e-04,\n",
      "         2.2039e-04,  2.3077e-04,  2.7846e-04, -1.7462e-04, -1.0369e-05,\n",
      "        -4.6678e-04,  1.7395e-04, -4.5044e-05,  1.3888e-04,  2.3132e-05,\n",
      "         3.4944e-05,  3.7631e-05, -7.0076e-06,  1.6557e-03,  1.1520e-04,\n",
      "        -5.6464e-05, -2.5621e-04,  7.3815e-05, -1.9449e-04, -8.8123e-05,\n",
      "        -3.8038e-04,  3.8277e-05, -1.5966e-04, -2.6980e-03, -1.9427e-04,\n",
      "         7.8717e-05,  1.0346e-04,  8.5463e-05,  1.5875e-05, -4.1888e-04,\n",
      "         5.8211e-04,  8.9711e-05,  3.7532e-04, -7.1291e-05, -1.4328e-03,\n",
      "        -3.4271e-04,  2.1459e-04,  3.3055e-04, -6.3007e-05,  3.6636e-04,\n",
      "        -5.7067e-04, -2.5574e-05, -2.1673e-04, -8.0357e-05,  3.0591e-05,\n",
      "         8.6852e-04,  7.0253e-04, -4.6771e-05,  2.2141e-04,  2.2007e-04,\n",
      "         2.0250e-04, -1.4596e-04, -5.2981e-04, -3.5563e-04, -1.9417e-04,\n",
      "        -7.6156e-04,  3.2487e-04,  7.0902e-04,  2.7174e-04, -9.0185e-05,\n",
      "        -1.3555e-04, -5.6487e-04,  1.6359e-04,  7.2355e-05, -7.9422e-04,\n",
      "         5.9285e-04, -1.0250e-04,  5.4645e-04,  2.7163e-04,  4.1193e-04,\n",
      "        -4.7364e-04,  3.3685e-04, -3.1774e-05, -1.1066e-04,  1.2108e-04,\n",
      "         2.0202e-05, -2.1757e-05,  4.2805e-04,  3.7616e-05,  7.5013e-04,\n",
      "         8.0766e-04, -4.8890e-04,  3.6551e-04, -4.5707e-05, -2.7683e-04,\n",
      "        -4.8074e-05,  3.9325e-04, -4.0148e-04, -6.4591e-05,  4.1306e-05,\n",
      "         6.7400e-06, -2.5592e-05,  8.9598e-04, -2.9908e-04, -1.2060e-04,\n",
      "         7.8840e-05, -1.3076e-04, -9.8606e-05,  5.5934e-04, -2.3922e-04,\n",
      "         1.5895e-03], device='cuda:0'), 'exp_avg_sq': tensor([9.1946e-07, 7.5467e-07, 5.4410e-06, 6.3954e-06, 5.0096e-06, 7.2183e-07,\n",
      "        4.4599e-07, 5.9587e-08, 8.5188e-06, 2.6753e-07, 1.8927e-07, 8.0211e-07,\n",
      "        7.1184e-06, 4.8723e-06, 3.8589e-07, 2.2289e-06, 7.0142e-07, 1.0095e-05,\n",
      "        1.0365e-06, 5.5958e-06, 1.0106e-05, 7.8963e-07, 5.6674e-07, 4.0895e-07,\n",
      "        6.9774e-07, 3.1083e-07, 1.3583e-07, 4.9236e-06, 2.2616e-06, 1.5413e-06,\n",
      "        2.7274e-07, 1.3446e-06, 1.0659e-06, 4.8058e-07, 7.2385e-07, 4.2632e-07,\n",
      "        8.0062e-07, 3.1725e-06, 1.9046e-07, 6.2128e-07, 1.5851e-06, 5.2362e-08,\n",
      "        8.8170e-06, 2.6370e-06, 2.8104e-06, 8.9128e-06, 4.8353e-07, 1.0566e-06,\n",
      "        2.0591e-07, 1.9955e-06, 3.7138e-06, 6.0352e-08, 9.3297e-08, 5.5846e-07,\n",
      "        4.6992e-07, 3.5002e-06, 4.1101e-07, 6.5455e-07, 6.6190e-07, 2.4546e-06,\n",
      "        2.6781e-06, 2.2431e-05, 4.1120e-06, 9.9949e-06, 2.5199e-07, 1.2125e-06,\n",
      "        3.9266e-06, 3.5047e-06, 8.4492e-07, 8.1069e-08, 6.3327e-08, 6.8100e-09,\n",
      "        5.3709e-06, 4.3001e-08, 2.8737e-07, 9.9968e-07, 4.1101e-06, 2.2838e-06,\n",
      "        1.3381e-07, 9.1095e-07, 5.4424e-07, 8.7280e-06, 2.2535e-07, 3.2562e-06,\n",
      "        1.1167e-06, 2.7738e-07, 9.8842e-08, 1.8451e-07, 1.6922e-07, 5.1542e-08,\n",
      "        1.2888e-08, 2.7766e-06, 1.2292e-07, 5.0525e-07, 1.9329e-08, 8.9190e-07,\n",
      "        2.6106e-06, 4.2990e-08, 2.1262e-07, 6.1189e-08, 8.0295e-08, 3.1909e-07,\n",
      "        1.2586e-08, 3.3543e-08, 1.7531e-06, 4.4600e-09, 9.9024e-07, 1.8994e-06,\n",
      "        4.6503e-07, 4.8656e-06, 1.7109e-07, 9.9534e-08, 2.3968e-07, 7.9829e-07,\n",
      "        6.0834e-07, 5.3234e-09, 9.6430e-09, 7.6782e-08, 1.2844e-07, 9.3096e-07,\n",
      "        4.0772e-08, 1.6247e-07, 1.3520e-07, 6.7722e-07, 1.2333e-06, 1.6467e-05,\n",
      "        4.7825e-06, 2.9199e-06, 3.8762e-06, 8.6348e-07, 4.1030e-06, 1.0164e-05,\n",
      "        1.1495e-05, 1.8064e-06, 1.1637e-06, 1.5949e-07, 2.5597e-05, 1.1063e-06,\n",
      "        1.8015e-06, 3.3479e-06, 9.9923e-06, 1.1674e-05, 2.3495e-06, 4.3984e-06,\n",
      "        3.6667e-06, 2.0015e-05, 3.9644e-06, 1.1109e-05, 1.1935e-07, 3.6114e-06,\n",
      "        8.1105e-07, 1.4077e-06, 5.0628e-06, 8.3355e-07, 2.4919e-07, 7.5914e-06,\n",
      "        3.0855e-06, 1.8311e-06, 6.8790e-07, 1.1461e-06, 8.1130e-06, 9.3012e-07,\n",
      "        3.5041e-06, 6.5032e-07, 4.9124e-07, 5.0330e-06, 5.5004e-07, 1.1368e-06,\n",
      "        9.6583e-06, 1.7231e-07, 7.4357e-06, 5.9736e-06, 2.7429e-06, 8.0913e-06,\n",
      "        1.0523e-06, 3.1263e-06, 1.1802e-06, 5.9426e-06, 9.6998e-06, 2.5692e-07,\n",
      "        3.1621e-07, 1.1092e-06, 6.4343e-07, 6.5667e-07, 7.5269e-07, 3.1415e-06,\n",
      "        1.1248e-06, 1.0175e-05, 7.6809e-06, 2.5773e-05, 9.9165e-06, 7.9559e-06,\n",
      "        2.2025e-06, 1.0262e-06, 2.1486e-06, 5.0410e-06, 6.1150e-06, 1.7604e-06,\n",
      "        1.2863e-06, 9.2976e-08, 1.2076e-05, 1.4632e-06, 2.0718e-06, 3.6041e-06,\n",
      "        6.3250e-06, 4.8322e-06, 1.9710e-06, 3.7168e-06, 2.7135e-06, 6.7428e-06,\n",
      "        2.2792e-06, 5.7620e-06, 5.2124e-06, 1.8978e-06, 5.6001e-07, 1.3301e-06,\n",
      "        3.5175e-06, 5.1082e-07, 3.7622e-07, 4.9742e-06, 1.7999e-06, 8.4104e-07,\n",
      "        1.4140e-06, 2.2704e-06, 7.5867e-06, 6.0315e-07, 3.6451e-06, 6.6265e-07,\n",
      "        2.2985e-06, 2.3229e-06, 4.0839e-07, 1.0466e-06, 8.9516e-06, 7.7856e-08,\n",
      "        1.0871e-05, 5.6647e-06, 3.3517e-06, 6.0497e-06, 8.8731e-07, 1.7252e-06,\n",
      "        2.1280e-06, 4.9896e-06, 4.2120e-06, 1.9574e-07, 1.2457e-07, 1.5080e-06,\n",
      "        1.0241e-06, 3.2618e-06, 5.9476e-07, 3.7796e-06, 1.2187e-06, 4.6531e-06,\n",
      "        4.9035e-06, 3.5919e-06, 1.9740e-05, 1.1249e-05], device='cuda:0')}, 8: {'step': 257520, 'exp_avg': tensor([ 4.3589e-04, -2.8081e-04,  3.5461e-05, -7.0765e-04,  7.4951e-05,\n",
      "        -6.4978e-05, -8.7203e-05,  2.3683e-05,  3.7365e-04,  1.9483e-04,\n",
      "        -1.2080e-05, -4.2174e-05,  3.7832e-04, -4.6442e-04, -1.9524e-04,\n",
      "        -7.6864e-04, -1.2952e-04, -5.7544e-04, -3.5239e-04,  2.2398e-04,\n",
      "         1.9057e-03,  3.6770e-04, -6.2262e-05, -5.8368e-05, -3.2405e-04,\n",
      "         1.4330e-04,  4.0433e-05, -7.8690e-05,  2.4954e-04, -2.7107e-04,\n",
      "         2.5259e-04,  1.8638e-04,  1.4354e-04, -3.1443e-04,  1.9483e-04,\n",
      "        -5.9575e-05, -2.3194e-04, -4.6562e-05,  5.1780e-06,  5.4482e-05,\n",
      "         4.8157e-05,  5.2123e-05,  9.1160e-04,  4.2128e-04, -6.3762e-04,\n",
      "         6.4346e-04, -1.3086e-05,  3.7056e-05, -7.4535e-06,  5.2291e-04,\n",
      "        -4.7301e-04, -5.3553e-05,  3.6088e-05,  2.7950e-05,  6.7054e-05,\n",
      "         2.6837e-04, -2.4332e-04,  8.5936e-05,  3.6247e-05, -1.2967e-04,\n",
      "         4.6141e-04, -6.7389e-04,  8.4376e-05, -3.0422e-04,  7.5311e-05,\n",
      "         1.4380e-04,  1.7775e-04,  1.0782e-04, -1.9720e-04,  8.2913e-05,\n",
      "        -2.3808e-05, -1.0047e-05,  9.7577e-04,  5.2408e-05, -8.8429e-05,\n",
      "        -1.8243e-05, -3.6676e-04,  3.2875e-04,  8.8910e-05,  3.1636e-04,\n",
      "         1.1270e-04,  2.0160e-05,  7.4191e-06, -4.3006e-04,  1.9666e-04,\n",
      "        -4.4604e-05,  2.1622e-05, -1.4623e-05,  1.0522e-05,  3.6551e-06,\n",
      "        -5.3968e-07,  1.3259e-05, -1.3778e-04, -3.9889e-05,  1.9795e-05,\n",
      "        -3.4662e-06,  2.1329e-04,  3.6257e-05, -5.5474e-05, -5.2616e-06,\n",
      "        -7.4013e-05,  2.9852e-04, -2.7418e-06,  5.1739e-05,  2.7462e-04,\n",
      "        -5.3204e-06,  4.4958e-05,  1.4695e-04, -9.6454e-05,  6.5257e-04,\n",
      "        -6.7583e-05, -1.6815e-05, -4.4614e-05,  7.7207e-05, -6.4861e-05,\n",
      "        -4.7937e-06,  3.6524e-05,  7.6267e-05,  5.0116e-05,  2.3235e-04,\n",
      "         5.6177e-06, -3.9394e-06, -2.3565e-05,  7.6034e-05,  1.8983e-04,\n",
      "         2.7087e-03,  4.2296e-04,  1.6876e-04,  2.2282e-04, -2.5502e-04,\n",
      "         5.8539e-04, -5.3142e-04,  5.1497e-04, -4.4335e-04, -8.2376e-05,\n",
      "        -4.9122e-05, -1.8013e-03,  6.2149e-04, -3.6889e-04,  2.9335e-04,\n",
      "        -2.1359e-04,  2.8003e-04, -7.2092e-05, -8.1960e-04,  8.9878e-05,\n",
      "         8.9765e-04, -6.9806e-04, -1.1945e-04, -1.0109e-04, -4.2190e-04,\n",
      "         2.2788e-04,  2.9038e-05, -4.6819e-04, -1.8973e-04,  1.2739e-04,\n",
      "         2.2038e-04,  2.3077e-04,  2.7846e-04, -1.7462e-04, -1.0369e-05,\n",
      "        -4.6678e-04,  1.7395e-04, -4.5044e-05,  1.3888e-04,  2.3132e-05,\n",
      "         3.4944e-05,  3.7630e-05, -7.0077e-06,  1.6557e-03,  1.1520e-04,\n",
      "        -5.6464e-05, -2.5621e-04,  7.3846e-05, -1.9448e-04, -8.8123e-05,\n",
      "        -3.8038e-04,  3.8277e-05, -1.5966e-04, -2.6980e-03, -1.9427e-04,\n",
      "         7.8717e-05,  1.0346e-04,  8.5463e-05,  1.5875e-05, -4.1888e-04,\n",
      "         5.8212e-04,  8.9712e-05,  3.7532e-04, -7.1289e-05, -1.4328e-03,\n",
      "        -3.4271e-04,  2.1459e-04,  3.3055e-04, -6.3007e-05,  3.6636e-04,\n",
      "        -5.7067e-04, -2.5575e-05, -2.1673e-04, -8.0357e-05,  3.0591e-05,\n",
      "         8.6852e-04,  7.0253e-04, -4.6771e-05,  2.2141e-04,  2.2007e-04,\n",
      "         2.0250e-04, -1.4596e-04, -5.2980e-04, -3.5563e-04, -1.9417e-04,\n",
      "        -7.6156e-04,  3.2487e-04,  7.0901e-04,  2.7174e-04, -9.0185e-05,\n",
      "        -1.3555e-04, -5.6487e-04,  1.6359e-04,  7.2355e-05, -7.9422e-04,\n",
      "         5.9285e-04, -1.0250e-04,  5.4645e-04,  2.7163e-04,  4.1194e-04,\n",
      "        -4.7364e-04,  3.3685e-04, -3.1774e-05, -1.1066e-04,  1.2108e-04,\n",
      "         2.0202e-05, -2.1757e-05,  4.2804e-04,  3.7616e-05,  7.5013e-04,\n",
      "         8.0766e-04, -4.8890e-04,  3.6549e-04, -4.5707e-05, -2.7683e-04,\n",
      "        -4.8075e-05,  3.9325e-04, -4.0148e-04, -6.4591e-05,  4.1306e-05,\n",
      "         6.7400e-06, -2.5592e-05,  8.9597e-04, -2.9908e-04, -1.2060e-04,\n",
      "         7.8840e-05, -1.3076e-04, -9.8607e-05,  5.5934e-04, -2.3922e-04,\n",
      "         1.5894e-03], device='cuda:0'), 'exp_avg_sq': tensor([9.1946e-07, 7.5467e-07, 5.4410e-06, 6.3954e-06, 5.0096e-06, 7.2183e-07,\n",
      "        4.4599e-07, 5.9587e-08, 8.5188e-06, 2.6753e-07, 1.8927e-07, 8.0211e-07,\n",
      "        7.1184e-06, 4.8723e-06, 3.8589e-07, 2.2289e-06, 7.0142e-07, 1.0095e-05,\n",
      "        1.0365e-06, 5.5958e-06, 1.0106e-05, 7.8963e-07, 5.6674e-07, 4.0895e-07,\n",
      "        6.9774e-07, 3.1083e-07, 1.3583e-07, 4.9236e-06, 2.2616e-06, 1.5413e-06,\n",
      "        2.7274e-07, 1.3446e-06, 1.0659e-06, 4.8058e-07, 7.2385e-07, 4.2632e-07,\n",
      "        8.0062e-07, 3.1725e-06, 1.9046e-07, 6.2128e-07, 1.5851e-06, 5.2362e-08,\n",
      "        8.8170e-06, 2.6370e-06, 2.8104e-06, 8.9128e-06, 4.8353e-07, 1.0566e-06,\n",
      "        2.0591e-07, 1.9955e-06, 3.7138e-06, 6.0352e-08, 9.3297e-08, 5.5846e-07,\n",
      "        4.6992e-07, 3.5002e-06, 4.1101e-07, 6.5455e-07, 6.6190e-07, 2.4546e-06,\n",
      "        2.6781e-06, 2.2431e-05, 4.1120e-06, 9.9949e-06, 2.5199e-07, 1.2125e-06,\n",
      "        3.9266e-06, 3.5047e-06, 8.4492e-07, 8.1069e-08, 6.3327e-08, 6.8100e-09,\n",
      "        5.3709e-06, 4.3001e-08, 2.8737e-07, 9.9968e-07, 4.1101e-06, 2.2838e-06,\n",
      "        1.3381e-07, 9.1095e-07, 5.4424e-07, 8.7280e-06, 2.2535e-07, 3.2562e-06,\n",
      "        1.1167e-06, 2.7738e-07, 9.8842e-08, 1.8451e-07, 1.6922e-07, 5.1542e-08,\n",
      "        1.2888e-08, 2.7766e-06, 1.2292e-07, 5.0525e-07, 1.9329e-08, 8.9190e-07,\n",
      "        2.6106e-06, 4.2990e-08, 2.1262e-07, 6.1189e-08, 8.0295e-08, 3.1909e-07,\n",
      "        1.2586e-08, 3.3543e-08, 1.7531e-06, 4.4600e-09, 9.9024e-07, 1.8994e-06,\n",
      "        4.6503e-07, 4.8656e-06, 1.7109e-07, 9.9534e-08, 2.3968e-07, 7.9829e-07,\n",
      "        6.0834e-07, 5.3234e-09, 9.6430e-09, 7.6782e-08, 1.2844e-07, 9.3096e-07,\n",
      "        4.0772e-08, 1.6247e-07, 1.3520e-07, 6.7722e-07, 1.2333e-06, 1.6467e-05,\n",
      "        4.7825e-06, 2.9199e-06, 3.8762e-06, 8.6348e-07, 4.1030e-06, 1.0164e-05,\n",
      "        1.1495e-05, 1.8064e-06, 1.1637e-06, 1.5949e-07, 2.5597e-05, 1.1063e-06,\n",
      "        1.8015e-06, 3.3479e-06, 9.9923e-06, 1.1674e-05, 2.3495e-06, 4.3984e-06,\n",
      "        3.6667e-06, 2.0015e-05, 3.9644e-06, 1.1109e-05, 1.1935e-07, 3.6114e-06,\n",
      "        8.1105e-07, 1.4077e-06, 5.0628e-06, 8.3355e-07, 2.4919e-07, 7.5914e-06,\n",
      "        3.0855e-06, 1.8311e-06, 6.8790e-07, 1.1461e-06, 8.1130e-06, 9.3012e-07,\n",
      "        3.5041e-06, 6.5032e-07, 4.9124e-07, 5.0330e-06, 5.5004e-07, 1.1368e-06,\n",
      "        9.6583e-06, 1.7231e-07, 7.4357e-06, 5.9736e-06, 2.7429e-06, 8.0913e-06,\n",
      "        1.0523e-06, 3.1263e-06, 1.1802e-06, 5.9426e-06, 9.6998e-06, 2.5692e-07,\n",
      "        3.1621e-07, 1.1092e-06, 6.4343e-07, 6.5667e-07, 7.5269e-07, 3.1415e-06,\n",
      "        1.1248e-06, 1.0175e-05, 7.6809e-06, 2.5773e-05, 9.9165e-06, 7.9559e-06,\n",
      "        2.2025e-06, 1.0262e-06, 2.1486e-06, 5.0410e-06, 6.1150e-06, 1.7604e-06,\n",
      "        1.2863e-06, 9.2976e-08, 1.2076e-05, 1.4632e-06, 2.0718e-06, 3.6041e-06,\n",
      "        6.3250e-06, 4.8322e-06, 1.9710e-06, 3.7168e-06, 2.7135e-06, 6.7428e-06,\n",
      "        2.2792e-06, 5.7620e-06, 5.2124e-06, 1.8978e-06, 5.6001e-07, 1.3301e-06,\n",
      "        3.5175e-06, 5.1082e-07, 3.7622e-07, 4.9742e-06, 1.7999e-06, 8.4104e-07,\n",
      "        1.4140e-06, 2.2704e-06, 7.5867e-06, 6.0315e-07, 3.6451e-06, 6.6265e-07,\n",
      "        2.2985e-06, 2.3229e-06, 4.0839e-07, 1.0466e-06, 8.9516e-06, 7.7856e-08,\n",
      "        1.0871e-05, 5.6647e-06, 3.3517e-06, 6.0497e-06, 8.8732e-07, 1.7252e-06,\n",
      "        2.1280e-06, 4.9896e-06, 4.2120e-06, 1.9574e-07, 1.2457e-07, 1.5080e-06,\n",
      "        1.0241e-06, 3.2618e-06, 5.9476e-07, 3.7796e-06, 1.2187e-06, 4.6531e-06,\n",
      "        4.9035e-06, 3.5919e-06, 1.9740e-05, 1.1249e-05], device='cuda:0')}, 9: {'step': 257520, 'exp_avg': tensor([[ 1.4013e-45, -1.4013e-45,  4.2039e-45,  ...,  1.4013e-45,\n",
      "          2.8026e-45,  0.0000e+00],\n",
      "        [-1.4013e-45, -1.4013e-45, -5.6052e-45,  ..., -2.8026e-45,\n",
      "          5.6052e-45,  0.0000e+00],\n",
      "        [ 5.6052e-45,  5.6052e-45,  1.4013e-45,  ..., -4.2039e-45,\n",
      "          5.6052e-45, -2.8026e-45],\n",
      "        ...,\n",
      "        [ 2.8026e-45,  2.8026e-45, -5.6052e-45,  ...,  0.0000e+00,\n",
      "          7.0065e-45, -1.4013e-45],\n",
      "        [ 0.0000e+00,  4.2039e-45,  4.2039e-45,  ..., -1.4013e-45,\n",
      "          0.0000e+00, -5.6052e-45],\n",
      "        [ 2.8026e-45, -0.0000e+00,  5.6052e-45,  ...,  4.2039e-45,\n",
      "          1.4013e-45, -4.2039e-45]], device='cuda:0'), 'exp_avg_sq': tensor([[7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        ...,\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43]], device='cuda:0')}, 10: {'step': 257520, 'exp_avg': tensor([[-0.0000e+00,  2.8026e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "          2.8026e-45,  4.2039e-45],\n",
      "        [ 1.4013e-45, -2.8026e-45,  0.0000e+00,  ...,  4.2039e-45,\n",
      "         -1.4013e-45, -2.8026e-45],\n",
      "        [ 2.8026e-45, -4.2039e-45,  2.8026e-45,  ...,  0.0000e+00,\n",
      "          2.8026e-45,  4.2039e-45],\n",
      "        ...,\n",
      "        [ 1.4013e-45, -1.4013e-45, -4.2039e-45,  ..., -2.8026e-45,\n",
      "          4.2039e-45,  7.0065e-45],\n",
      "        [-2.8026e-45,  0.0000e+00,  4.2039e-45,  ..., -4.2039e-45,\n",
      "          4.2039e-45, -1.4013e-45],\n",
      "        [ 7.0065e-45, -1.4013e-45,  1.4013e-45,  ...,  1.4013e-45,\n",
      "         -2.8026e-45, -1.4013e-45]], device='cuda:0'), 'exp_avg_sq': tensor([[7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        ...,\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43],\n",
      "        [7.0065e-43, 7.0065e-43, 7.0065e-43,  ..., 7.0065e-43, 7.0065e-43,\n",
      "         7.0065e-43]], device='cuda:0')}, 11: {'step': 257520, 'exp_avg': tensor([ 2.8026e-45, -2.8026e-45,  0.0000e+00,  1.4013e-45,  1.4013e-45,\n",
      "         2.8026e-45, -1.4013e-45,  4.2039e-45, -5.6052e-45,  2.8026e-45,\n",
      "        -4.2039e-45,  0.0000e+00, -0.0000e+00, -4.2039e-45,  4.2039e-45,\n",
      "         0.0000e+00, -5.6052e-45,  4.2039e-45, -2.8026e-45, -0.0000e+00,\n",
      "         1.4013e-45,  4.2039e-45, -2.8026e-45, -5.6052e-45, -1.4013e-45,\n",
      "         2.8026e-45, -4.2039e-45, -5.6052e-45, -4.2039e-45, -5.6052e-45,\n",
      "         2.8026e-45,  2.8026e-45,  4.2039e-45, -1.4013e-45,  2.8026e-45,\n",
      "         7.0065e-45,  5.6052e-45, -1.4013e-45,  4.2039e-45, -4.2039e-45,\n",
      "        -2.8026e-45,  1.4013e-45, -2.8026e-45, -2.8026e-45,  4.2039e-45,\n",
      "         1.4013e-45,  1.4013e-45,  4.2039e-45,  4.2039e-45, -2.8026e-45,\n",
      "         4.2039e-45, -0.0000e+00, -4.2039e-45,  0.0000e+00,  2.8026e-45,\n",
      "         2.8026e-45, -1.4013e-45,  0.0000e+00, -2.8026e-45,  4.2039e-45,\n",
      "         2.8026e-45,  5.6052e-45, -2.8026e-45, -4.2039e-45,  2.8026e-45,\n",
      "        -4.2039e-45,  7.0065e-45,  4.2039e-45, -4.2039e-45,  5.6052e-45,\n",
      "         1.4013e-45, -4.2039e-45,  2.8026e-45,  4.2039e-45, -2.8026e-45,\n",
      "         1.4013e-45, -2.8026e-45, -5.6052e-45, -1.4013e-45, -5.6052e-45,\n",
      "        -2.8026e-45,  0.0000e+00,  2.8026e-45, -2.8026e-45,  4.2039e-45,\n",
      "        -4.2039e-45,  5.6052e-45,  1.4013e-45, -1.4013e-45,  2.8026e-45,\n",
      "         2.8026e-45, -4.2039e-45,  1.4013e-45, -4.2039e-45,  4.2039e-45,\n",
      "         5.6052e-45, -4.2039e-45, -4.2039e-45, -0.0000e+00,  2.8026e-45,\n",
      "        -4.2039e-45, -0.0000e+00, -0.0000e+00, -4.2039e-45,  4.2039e-45,\n",
      "        -7.0065e-45,  2.8026e-45, -2.8026e-45,  4.2039e-45,  1.4013e-45,\n",
      "         2.8026e-45, -1.4013e-45, -2.8026e-45,  4.2039e-45, -2.8026e-45,\n",
      "        -1.4013e-45,  2.8026e-45,  2.8026e-45, -2.8026e-45, -4.2039e-45,\n",
      "        -5.6052e-45, -4.2039e-45,  1.4013e-45,  4.2039e-45, -0.0000e+00,\n",
      "        -2.8026e-45, -4.2039e-45, -1.4013e-45, -4.2039e-45,  0.0000e+00,\n",
      "        -4.2039e-45,  2.8026e-45,  4.2039e-45, -4.2039e-45, -5.6052e-45,\n",
      "        -0.0000e+00,  1.4013e-45, -5.6052e-45,  5.6052e-45,  1.4013e-45,\n",
      "         2.8026e-45,  0.0000e+00, -0.0000e+00,  2.8026e-45, -1.4013e-45,\n",
      "        -1.4013e-45, -1.4013e-45, -2.8026e-45,  4.2039e-45,  2.8026e-45,\n",
      "         1.4013e-45, -5.6052e-45, -1.4013e-45, -5.6052e-45, -2.8026e-45,\n",
      "        -1.4013e-45, -1.4013e-45, -0.0000e+00,  1.4013e-45,  0.0000e+00,\n",
      "         4.2039e-45, -1.4013e-45,  4.2039e-45,  4.2039e-45, -1.4013e-45,\n",
      "        -1.4013e-45, -1.4013e-45,  4.2039e-45, -7.0065e-45,  2.8026e-45,\n",
      "         2.8026e-45, -2.8026e-45,  4.2039e-45,  4.2039e-45, -5.6052e-45,\n",
      "         2.8026e-45,  4.2039e-45, -4.2039e-45, -2.8026e-45, -0.0000e+00,\n",
      "        -4.2039e-45,  1.4013e-45, -4.2039e-45, -2.8026e-45, -1.4013e-45,\n",
      "         2.8026e-45, -1.4013e-45, -1.4013e-45, -4.2039e-45, -0.0000e+00,\n",
      "         2.8026e-45,  1.4013e-45,  1.4013e-45,  4.2039e-45, -1.4013e-45,\n",
      "         1.4013e-45, -4.2039e-45, -1.4013e-45, -2.8026e-45,  4.2039e-45,\n",
      "        -1.4013e-45, -4.2039e-45, -5.6052e-45,  1.4013e-45,  4.2039e-45,\n",
      "         4.2039e-45,  4.2039e-45, -2.8026e-45, -0.0000e+00, -1.4013e-45,\n",
      "        -2.8026e-45, -1.4013e-45, -2.8026e-45,  2.8026e-45, -1.4013e-45,\n",
      "         7.0065e-45, -2.8026e-45,  2.8026e-45,  1.4013e-45, -7.0065e-45,\n",
      "        -4.2039e-45, -2.8026e-45, -1.4013e-45, -4.2039e-45,  2.8026e-45,\n",
      "        -7.0065e-45,  2.8026e-45, -2.8026e-45, -2.8026e-45,  1.4013e-45,\n",
      "        -2.8026e-45, -5.6052e-45, -2.8026e-45,  0.0000e+00, -2.8026e-45,\n",
      "         1.4013e-45,  2.8026e-45,  2.8026e-45,  5.6052e-45, -2.8026e-45,\n",
      "        -2.8026e-45, -4.2039e-45, -2.8026e-45,  0.0000e+00, -2.8026e-45,\n",
      "        -4.2039e-45,  5.6052e-45, -1.4013e-45,  0.0000e+00, -4.2039e-45,\n",
      "        -4.2039e-45,  2.8026e-45,  2.8026e-45, -1.4013e-45,  1.4013e-45,\n",
      "        -4.2039e-45], device='cuda:0'), 'exp_avg_sq': tensor([7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43], device='cuda:0')}, 12: {'step': 257520, 'exp_avg': tensor([-2.8026e-45, -2.8026e-45, -0.0000e+00,  1.4013e-45, -4.2039e-45,\n",
      "         7.0065e-45, -0.0000e+00, -2.8026e-45,  2.8026e-45, -1.4013e-45,\n",
      "        -4.2039e-45,  2.8026e-45, -2.8026e-45,  1.4013e-45, -4.2039e-45,\n",
      "        -2.8026e-45,  2.8026e-45, -1.4013e-45,  2.8026e-45,  2.8026e-45,\n",
      "        -5.6052e-45,  2.8026e-45, -1.4013e-45, -1.4013e-45, -1.4013e-45,\n",
      "        -4.2039e-45, -5.6052e-45,  5.6052e-45, -0.0000e+00,  7.0065e-45,\n",
      "        -1.4013e-45, -5.6052e-45,  2.8026e-45, -4.2039e-45, -2.8026e-45,\n",
      "         5.6052e-45, -4.2039e-45,  5.6052e-45, -0.0000e+00, -2.8026e-45,\n",
      "         4.2039e-45,  4.2039e-45, -4.2039e-45, -2.8026e-45,  4.2039e-45,\n",
      "         5.6052e-45, -4.2039e-45,  4.2039e-45,  5.6052e-45, -1.4013e-45,\n",
      "        -1.4013e-45, -2.8026e-45, -1.4013e-45, -2.8026e-45, -1.4013e-45,\n",
      "         2.8026e-45,  4.2039e-45,  2.8026e-45, -2.8026e-45,  4.2039e-45,\n",
      "         4.2039e-45, -2.8026e-45, -1.4013e-45,  7.0065e-45,  1.4013e-45,\n",
      "        -2.8026e-45, -7.0065e-45, -0.0000e+00, -0.0000e+00,  2.8026e-45,\n",
      "        -1.4013e-45, -4.2039e-45, -5.6052e-45, -1.4013e-45,  0.0000e+00,\n",
      "         2.8026e-45,  1.4013e-45,  1.4013e-45, -1.4013e-45, -2.8026e-45,\n",
      "         1.4013e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -7.0065e-45,\n",
      "        -1.4013e-45,  2.8026e-45,  1.4013e-45,  0.0000e+00, -1.4013e-45,\n",
      "        -4.2039e-45, -2.8026e-45, -4.2039e-45, -0.0000e+00, -2.8026e-45,\n",
      "         1.4013e-45,  1.4013e-45,  1.4013e-45, -4.2039e-45, -2.8026e-45,\n",
      "         0.0000e+00,  2.8026e-45,  2.8026e-45, -7.0065e-45, -4.2039e-45,\n",
      "         5.6052e-45,  5.6052e-45, -1.4013e-45,  1.4013e-45, -2.8026e-45,\n",
      "        -4.2039e-45,  4.2039e-45, -0.0000e+00, -1.4013e-45, -2.8026e-45,\n",
      "        -5.6052e-45, -7.0065e-45, -0.0000e+00,  2.8026e-45,  2.8026e-45,\n",
      "         2.8026e-45, -2.8026e-45,  0.0000e+00,  4.2039e-45,  2.8026e-45,\n",
      "         2.8026e-45, -4.2039e-45,  4.2039e-45, -4.2039e-45,  1.4013e-45,\n",
      "         7.0065e-45, -5.6052e-45,  2.8026e-45,  2.8026e-45,  1.4013e-45,\n",
      "        -1.4013e-45, -1.4013e-45,  4.2039e-45,  2.8026e-45, -0.0000e+00,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -0.0000e+00,  7.0065e-45,\n",
      "         4.2039e-45,  0.0000e+00,  0.0000e+00,  5.6052e-45, -5.6052e-45,\n",
      "         0.0000e+00, -4.2039e-45, -4.2039e-45, -4.2039e-45,  1.4013e-45,\n",
      "        -1.4013e-45,  0.0000e+00, -4.2039e-45,  2.8026e-45, -0.0000e+00,\n",
      "         4.2039e-45,  1.4013e-45, -0.0000e+00, -1.4013e-45,  4.2039e-45,\n",
      "         2.8026e-45, -1.4013e-45, -2.8026e-45,  2.8026e-45,  5.6052e-45,\n",
      "         4.2039e-45, -1.4013e-45,  4.2039e-45,  2.8026e-45, -2.8026e-45,\n",
      "        -2.8026e-45,  4.2039e-45, -1.4013e-45, -1.4013e-45, -4.2039e-45,\n",
      "        -2.8026e-45,  0.0000e+00,  2.8026e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -2.8026e-45, -4.2039e-45, -2.8026e-45, -4.2039e-45,  7.0065e-45,\n",
      "        -1.4013e-45,  4.2039e-45,  4.2039e-45, -2.8026e-45, -1.4013e-45,\n",
      "        -4.2039e-45,  4.2039e-45, -1.4013e-45,  2.8026e-45,  2.8026e-45,\n",
      "        -2.8026e-45, -0.0000e+00, -2.8026e-45, -0.0000e+00, -0.0000e+00,\n",
      "         4.2039e-45,  2.8026e-45,  4.2039e-45, -5.6052e-45, -5.6052e-45,\n",
      "         0.0000e+00, -4.2039e-45, -2.8026e-45, -2.8026e-45,  1.4013e-45,\n",
      "        -2.8026e-45, -0.0000e+00, -1.4013e-45, -5.6052e-45, -2.8026e-45,\n",
      "         5.6052e-45, -2.8026e-45,  0.0000e+00, -1.4013e-45, -4.2039e-45,\n",
      "         2.8026e-45,  1.4013e-45, -1.4013e-45,  4.2039e-45, -2.8026e-45,\n",
      "         1.4013e-45,  1.4013e-45, -2.8026e-45,  0.0000e+00, -4.2039e-45,\n",
      "         1.4013e-45, -2.8026e-45, -4.2039e-45,  1.4013e-45, -4.2039e-45,\n",
      "        -4.2039e-45,  2.8026e-45,  2.8026e-45,  5.6052e-45,  2.8026e-45,\n",
      "         7.0065e-45, -4.2039e-45, -0.0000e+00, -4.2039e-45,  1.4013e-45,\n",
      "        -4.2039e-45, -4.2039e-45, -4.2039e-45,  1.4013e-45, -1.4013e-45,\n",
      "        -1.4013e-45], device='cuda:0'), 'exp_avg_sq': tensor([7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43,\n",
      "        7.0065e-43, 7.0065e-43, 7.0065e-43, 7.0065e-43], device='cuda:0')}, 13: {'step': 257520, 'exp_avg': tensor([[-4.0117e-04,  9.0331e-05,  1.2780e-03,  ..., -5.7227e-04,\n",
      "          7.6539e-05,  7.0067e-04],\n",
      "        [-1.4431e-07, -4.2157e-08,  6.4932e-07,  ...,  4.2759e-06,\n",
      "          1.2453e-06,  1.2565e-06],\n",
      "        [ 2.4259e-06,  9.7869e-08, -8.6828e-08,  ..., -4.8893e-06,\n",
      "         -2.6560e-06,  3.7622e-07],\n",
      "        ...,\n",
      "        [ 1.4783e-06,  1.3751e-07, -1.6248e-07,  ...,  1.2425e-06,\n",
      "         -1.1214e-05,  2.8351e-07],\n",
      "        [-1.1909e-06,  4.0945e-08, -1.1632e-06,  ..., -5.1823e-06,\n",
      "          5.2800e-07,  2.2043e-06],\n",
      "        [-4.0242e-06, -4.5626e-06, -1.1293e-04,  ...,  6.6329e-05,\n",
      "          8.0706e-05,  1.1152e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.3963e-05, 5.2297e-08, 6.3963e-06,  ..., 2.0997e-05, 2.0637e-05,\n",
      "         7.5393e-06],\n",
      "        [3.8204e-10, 1.4772e-12, 1.1270e-10,  ..., 7.3241e-10, 6.7216e-10,\n",
      "         3.8739e-10],\n",
      "        [4.3458e-10, 1.5704e-12, 1.1088e-10,  ..., 1.3237e-09, 4.3368e-10,\n",
      "         5.1644e-10],\n",
      "        ...,\n",
      "        [3.6995e-10, 1.1222e-12, 1.2814e-10,  ..., 8.6325e-10, 1.3860e-09,\n",
      "         1.3197e-09],\n",
      "        [3.0182e-09, 3.7791e-12, 1.6964e-09,  ..., 1.2236e-09, 2.9578e-09,\n",
      "         1.0299e-09],\n",
      "        [8.8994e-07, 1.5712e-09, 2.7616e-07,  ..., 1.6371e-06, 1.9330e-06,\n",
      "         1.2385e-06]], device='cuda:0')}, 14: {'step': 257520, 'exp_avg': tensor([[-3.4308e-04, -6.8393e-06, -3.5005e-06,  ..., -4.7384e-06,\n",
      "         -9.5669e-07,  8.0953e-05],\n",
      "        [-2.5139e-06, -7.6359e-08,  5.6546e-08,  ...,  5.3336e-08,\n",
      "          1.6700e-08, -3.0081e-07],\n",
      "        [ 7.1920e-07,  2.0949e-08,  1.7550e-08,  ..., -2.3879e-08,\n",
      "          5.4084e-09,  1.4362e-06],\n",
      "        ...,\n",
      "        [-5.7794e-06, -6.2882e-08,  4.3820e-08,  ..., -2.7033e-08,\n",
      "         -7.3722e-08,  2.2566e-06],\n",
      "        [-3.3030e-06, -6.8455e-08, -1.6642e-08,  ...,  6.2583e-09,\n",
      "          3.5832e-09,  2.4292e-06],\n",
      "        [ 3.3816e-04,  9.3756e-07,  2.4148e-06,  ..., -2.4301e-06,\n",
      "         -1.6406e-06, -3.6436e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[8.3803e-06, 1.9919e-09, 1.2120e-09,  ..., 1.2034e-09, 6.5404e-09,\n",
      "         2.5104e-06],\n",
      "        [5.7082e-10, 2.1689e-12, 1.2464e-13,  ..., 2.0515e-13, 6.3860e-13,\n",
      "         5.1677e-10],\n",
      "        [4.8765e-10, 2.6868e-13, 1.9940e-12,  ..., 2.2421e-13, 4.2746e-13,\n",
      "         3.8739e-10],\n",
      "        ...,\n",
      "        [4.6833e-10, 3.4277e-13, 2.1199e-13,  ..., 2.2805e-12, 2.2747e-12,\n",
      "         5.8352e-10],\n",
      "        [1.3224e-09, 1.4671e-12, 4.2692e-13,  ..., 5.3605e-13, 7.1336e-11,\n",
      "         4.7486e-10],\n",
      "        [4.4560e-07, 3.0252e-10, 1.9999e-10,  ..., 2.5473e-10, 1.8780e-10,\n",
      "         1.7251e-06]], device='cuda:0')}, 15: {'step': 257520, 'exp_avg': tensor([-2.7717e-03, -4.3335e-06,  2.7719e-07,  1.4444e-05,  2.0160e-06,\n",
      "         1.4886e-05, -1.6745e-06, -1.8154e-03, -8.1236e-06,  5.3840e-05,\n",
      "         3.9274e-04,  1.0038e-05,  6.5864e-04,  1.7272e-05,  8.0168e-06,\n",
      "        -2.6127e-06,  3.9248e-03,  9.1066e-06,  1.3686e-05, -1.1332e-04,\n",
      "         1.0234e-05,  2.1452e-05,  6.9837e-06, -8.4741e-06,  6.6502e-06,\n",
      "         1.0406e-05, -8.0526e-07, -2.4769e-03, -5.8337e-04, -3.2942e-05,\n",
      "         3.9375e-06,  9.8236e-04, -2.3880e-04, -3.6028e-06,  1.4109e-05,\n",
      "        -1.5869e-05,  5.4852e-05,  1.2057e-03,  1.2956e-05, -5.5005e-04,\n",
      "         3.4042e-03, -6.4134e-06, -2.6223e-06,  8.6684e-06, -9.8786e-08,\n",
      "         1.6944e-05,  1.3930e-05, -9.9893e-06,  1.4433e-04, -5.0426e-04,\n",
      "        -5.0916e-05, -2.9585e-06,  2.1937e-03, -1.1228e-06,  4.0262e-03,\n",
      "        -5.6619e-07, -7.3671e-04,  5.4983e-06, -1.8967e-05, -7.7495e-06,\n",
      "         1.7368e-03, -9.5417e-06, -6.3992e-06, -4.1346e-03, -2.9150e-03,\n",
      "        -1.9676e-06,  1.5622e-06, -1.5390e-06, -7.6536e-07,  8.7594e-06,\n",
      "         4.7477e-07, -1.0820e-03, -2.8284e-06,  3.9063e-05,  2.4128e-04,\n",
      "         4.4537e-06,  4.5328e-04, -7.3431e-08,  2.3427e-06, -2.5143e-06,\n",
      "         1.6090e-03,  7.0011e-08,  8.6420e-06, -2.5648e-05, -4.9357e-07,\n",
      "         1.8045e-05, -1.7806e-06, -4.6707e-06,  5.4335e-07,  3.5462e-06,\n",
      "         9.4241e-07, -2.4285e-04,  5.5433e-05, -1.0175e-05,  5.2670e-06,\n",
      "         1.1646e-03, -5.5527e-04, -1.4188e-07,  4.5292e-06, -4.2892e-06,\n",
      "         1.7851e-05,  2.4068e-03,  2.6074e-05,  8.6750e-05,  2.4343e-03,\n",
      "         3.4058e-06, -3.1943e-08,  2.7090e-06, -2.8340e-07,  9.7321e-06,\n",
      "         5.2392e-06,  6.6332e-08,  2.6693e-04, -3.7615e-04, -9.5006e-06,\n",
      "        -3.2183e-06,  1.6198e-03, -1.2641e-06,  1.0899e-04,  1.3384e-06,\n",
      "        -1.2042e-03,  2.7737e-05, -3.4059e-06, -9.7818e-07,  3.8855e-04,\n",
      "        -2.9250e-07, -1.0323e-06, -4.5349e-06, -8.7808e-05, -7.5186e-07,\n",
      "         8.1528e-05,  2.5649e-05,  2.4092e-05,  1.7589e-05, -3.2410e-05,\n",
      "        -4.2456e-04, -3.9585e-05,  1.7041e-04, -2.5622e-03,  5.1928e-05,\n",
      "        -5.0659e-04, -2.2791e-06, -4.4198e-07, -3.4747e-05,  9.0612e-04,\n",
      "         3.0991e-05,  9.8013e-05,  1.9090e-04,  3.9069e-05,  1.0278e-05,\n",
      "        -9.9994e-05, -6.1808e-06,  2.4527e-05,  4.4455e-05, -7.0363e-05,\n",
      "        -2.0968e-04,  8.7854e-04,  3.3984e-05, -9.4179e-05,  1.0138e-04,\n",
      "         7.2848e-04,  2.5691e-05,  1.7931e-05, -4.0224e-05, -1.2062e-04,\n",
      "         5.4625e-04, -3.1690e-04, -6.3750e-06,  8.6687e-04,  1.1497e-05,\n",
      "         8.2680e-06, -9.0555e-05, -6.2340e-05, -2.0670e-05,  1.0097e-04,\n",
      "         6.0694e-05,  3.3652e-04, -2.3983e-05,  1.9906e-04, -7.2606e-05,\n",
      "         5.6947e-04,  9.0928e-07, -1.3932e-04,  2.6921e-05,  4.2756e-04,\n",
      "        -7.6758e-05, -6.3803e-05, -1.3962e-05,  1.9621e-03, -7.3790e-05,\n",
      "        -3.7509e-05,  2.2012e-03,  8.3406e-04, -4.7940e-06,  2.9809e-07,\n",
      "         1.6304e-05,  1.4816e-06,  1.5031e-05, -2.3917e-06, -1.0928e-03,\n",
      "        -8.5315e-06,  5.7252e-05, -7.7727e-05,  1.0223e-05, -8.6932e-05,\n",
      "         1.7307e-05,  7.5176e-06, -3.6384e-06,  5.9143e-04,  8.9373e-06,\n",
      "         1.4082e-05, -1.2648e-04,  1.0468e-05,  2.3649e-05,  6.5673e-06,\n",
      "        -9.3092e-06,  6.7947e-06,  1.0678e-05, -9.0159e-07, -1.4298e-03,\n",
      "         8.5994e-06, -3.7416e-05,  4.5443e-06,  7.6377e-04, -8.5860e-05,\n",
      "        -4.0172e-06,  1.4235e-05, -1.6145e-05,  5.7093e-05,  3.2968e-04,\n",
      "         1.4139e-05, -5.6155e-04, -5.7546e-05, -5.6358e-06, -2.9675e-06,\n",
      "         8.1028e-06, -5.9103e-07,  1.9185e-05,  1.4209e-05, -1.0324e-05,\n",
      "         8.1022e-04,  1.8578e-04, -4.1131e-05, -3.0760e-06,  7.0690e-04,\n",
      "        -2.5898e-06,  1.1548e-04, -1.0242e-06, -1.1290e-03,  4.9552e-05,\n",
      "        -2.0223e-05, -8.2624e-06,  2.8508e-04, -9.8782e-06, -7.1653e-06,\n",
      "         4.6641e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.1587e-04, 4.7138e-09, 4.2245e-09, 5.8941e-08, 1.3996e-08, 5.8290e-09,\n",
      "        8.9677e-09, 1.0673e-04, 5.9391e-09, 4.5712e-09, 8.2790e-05, 5.3716e-09,\n",
      "        1.8954e-04, 1.1682e-08, 2.0108e-08, 5.2860e-09, 1.0565e-04, 3.7675e-09,\n",
      "        3.5240e-09, 8.7319e-07, 8.0243e-09, 2.2903e-08, 1.6779e-08, 9.7246e-09,\n",
      "        1.0966e-07, 4.1826e-09, 4.4306e-09, 4.1027e-05, 1.2079e-04, 9.0603e-09,\n",
      "        3.3940e-09, 7.2922e-05, 1.4682e-05, 1.1562e-08, 5.5647e-09, 1.6356e-08,\n",
      "        1.0222e-08, 2.6235e-04, 7.5119e-08, 2.0239e-05, 2.6755e-04, 5.0895e-09,\n",
      "        4.6917e-09, 3.6589e-09, 5.4645e-09, 7.7624e-09, 4.1363e-09, 6.5010e-09,\n",
      "        3.0438e-05, 1.1757e-04, 1.6197e-07, 7.1956e-09, 3.6431e-04, 4.1567e-09,\n",
      "        8.6069e-05, 2.0115e-08, 3.6232e-05, 4.3603e-08, 1.3276e-07, 8.1382e-09,\n",
      "        1.2387e-05, 4.7422e-09, 8.0295e-09, 1.2672e-04, 1.0805e-03, 7.0309e-10,\n",
      "        5.3535e-10, 9.5483e-09, 2.2977e-09, 8.3524e-10, 1.4923e-09, 3.8099e-05,\n",
      "        8.8998e-10, 8.5227e-10, 1.0158e-05, 8.6732e-10, 1.5695e-05, 1.6544e-09,\n",
      "        7.9455e-09, 8.0651e-10, 6.2981e-05, 8.9422e-10, 5.6876e-10, 1.9760e-07,\n",
      "        1.1209e-09, 4.0372e-09, 2.7480e-09, 2.1589e-09, 1.3618e-07, 7.4013e-10,\n",
      "        8.2376e-10, 2.3254e-05, 5.4087e-06, 1.7348e-09, 5.3762e-10, 4.5739e-05,\n",
      "        1.2895e-05, 1.3538e-09, 1.0075e-09, 3.3259e-09, 1.9310e-09, 3.3107e-05,\n",
      "        1.0681e-08, 6.2686e-06, 3.6416e-05, 7.8014e-10, 9.1425e-10, 5.6805e-10,\n",
      "        8.1697e-10, 9.3570e-10, 6.2953e-10, 7.7482e-10, 2.9571e-06, 3.0768e-05,\n",
      "        1.3132e-07, 9.3950e-10, 2.4555e-05, 8.0570e-10, 2.0044e-05, 6.3655e-09,\n",
      "        4.4528e-05, 7.5209e-09, 2.9022e-08, 1.4486e-09, 1.1365e-05, 5.6180e-10,\n",
      "        1.0300e-09, 2.3023e-05, 2.3035e-07, 6.7347e-08, 4.9112e-08, 2.7741e-07,\n",
      "        8.7333e-08, 6.4711e-08, 7.1516e-08, 9.6832e-06, 7.4324e-08, 5.5418e-08,\n",
      "        3.2423e-05, 5.4592e-08, 4.2310e-05, 9.3094e-08, 7.1036e-08, 7.4204e-08,\n",
      "        4.9147e-05, 6.7158e-08, 4.7555e-08, 1.3682e-06, 7.2195e-08, 9.5607e-08,\n",
      "        8.3331e-08, 8.7335e-08, 2.0654e-07, 5.5659e-08, 4.3759e-08, 1.2551e-05,\n",
      "        3.1159e-05, 7.2309e-08, 4.6388e-08, 1.3188e-06, 9.9168e-06, 7.8545e-08,\n",
      "        5.3205e-08, 8.7532e-08, 7.3086e-08, 1.9344e-04, 4.0724e-07, 3.8049e-06,\n",
      "        7.0614e-05, 6.3944e-08, 4.3807e-08, 5.5810e-08, 6.0907e-08, 7.0577e-08,\n",
      "        6.2447e-08, 6.5290e-08, 1.7592e-05, 2.2584e-05, 3.9875e-07, 5.6523e-08,\n",
      "        4.4175e-05, 4.9657e-08, 1.1646e-05, 6.7289e-08, 2.1962e-05, 3.1358e-07,\n",
      "        2.7365e-07, 6.0129e-08, 2.7704e-06, 6.4024e-08, 5.3964e-08, 1.1817e-05,\n",
      "        7.7210e-06, 5.3069e-09, 4.7272e-09, 7.5165e-08, 2.3385e-08, 6.3433e-09,\n",
      "        1.0080e-08, 2.4300e-05, 6.6212e-09, 5.1106e-09, 7.0679e-07, 6.4230e-09,\n",
      "        8.0845e-06, 1.2497e-08, 4.7121e-08, 5.9241e-09, 9.0676e-06, 4.4559e-09,\n",
      "        4.1232e-09, 8.9053e-07, 9.9513e-09, 2.6935e-08, 2.6439e-08, 1.2241e-08,\n",
      "        1.3673e-07, 4.6260e-09, 5.4912e-09, 3.5336e-05, 1.3947e-06, 1.0021e-08,\n",
      "        3.7024e-09, 7.1484e-06, 4.3724e-07, 1.3843e-08, 6.2430e-09, 2.0476e-08,\n",
      "        1.4181e-08, 3.9083e-05, 9.9612e-08, 4.9558e-05, 8.5550e-06, 5.3285e-09,\n",
      "        6.6273e-09, 4.0235e-09, 6.3989e-09, 8.5752e-09, 4.3232e-09, 7.4101e-09,\n",
      "        5.4256e-06, 5.3196e-06, 3.5117e-07, 8.1027e-09, 3.4537e-06, 1.3117e-08,\n",
      "        8.6936e-06, 3.7075e-08, 1.2264e-05, 5.8473e-08, 2.5781e-07, 9.9453e-09,\n",
      "        1.6177e-06, 5.0173e-09, 1.0755e-08, 3.2223e-06], device='cuda:0')}, 16: {'step': 257520, 'exp_avg': tensor([-2.7718e-03, -4.3335e-06,  2.7719e-07,  1.4444e-05,  2.0160e-06,\n",
      "         1.4886e-05, -1.6745e-06, -1.8159e-03, -8.1236e-06,  5.3840e-05,\n",
      "         3.9244e-04,  1.0038e-05,  6.5837e-04,  1.7272e-05,  8.0168e-06,\n",
      "        -2.6127e-06,  3.9252e-03,  9.1066e-06,  1.3686e-05, -1.1332e-04,\n",
      "         1.0234e-05,  2.1452e-05,  6.9837e-06, -8.4741e-06,  6.6502e-06,\n",
      "         1.0406e-05, -8.0526e-07, -2.4769e-03, -5.8379e-04, -3.2942e-05,\n",
      "         3.9375e-06,  9.8217e-04, -2.3880e-04, -3.6028e-06,  1.4109e-05,\n",
      "        -1.5869e-05,  5.4852e-05,  1.2053e-03,  1.2956e-05, -5.5010e-04,\n",
      "         3.4039e-03, -6.4134e-06, -2.6223e-06,  8.6684e-06, -9.8786e-08,\n",
      "         1.6944e-05,  1.3930e-05, -9.9893e-06,  1.4452e-04, -5.0396e-04,\n",
      "        -5.0916e-05, -2.9585e-06,  2.1935e-03, -1.1228e-06,  4.0265e-03,\n",
      "        -5.6619e-07, -7.3670e-04,  5.4983e-06, -1.8967e-05, -7.7495e-06,\n",
      "         1.7368e-03, -9.5417e-06, -6.3992e-06, -4.1347e-03, -2.9149e-03,\n",
      "        -1.9676e-06,  1.5622e-06, -1.5390e-06, -7.6536e-07,  8.7594e-06,\n",
      "         4.7477e-07, -1.0820e-03, -2.8284e-06,  3.9063e-05,  2.4129e-04,\n",
      "         4.4537e-06,  4.5324e-04, -7.3431e-08,  2.3427e-06, -2.5143e-06,\n",
      "         1.6091e-03,  7.0011e-08,  8.6420e-06, -2.5648e-05, -4.9357e-07,\n",
      "         1.8045e-05, -1.7806e-06, -4.6707e-06,  5.4335e-07,  3.5462e-06,\n",
      "         9.4241e-07, -2.4285e-04,  5.5417e-05, -1.0175e-05,  5.2670e-06,\n",
      "         1.1645e-03, -5.5527e-04, -1.4188e-07,  4.5292e-06, -4.2892e-06,\n",
      "         1.7851e-05,  2.4068e-03,  2.6074e-05,  8.6735e-05,  2.4343e-03,\n",
      "         3.4058e-06, -3.1943e-08,  2.7090e-06, -2.8340e-07,  9.7321e-06,\n",
      "         5.2392e-06,  6.6332e-08,  2.6693e-04, -3.7614e-04, -9.5006e-06,\n",
      "        -3.2183e-06,  1.6197e-03, -1.2641e-06,  1.0899e-04,  1.3384e-06,\n",
      "        -1.2042e-03,  2.7737e-05, -3.4059e-06, -9.7818e-07,  3.8855e-04,\n",
      "        -2.9250e-07, -1.0323e-06, -4.4754e-06, -8.7808e-05, -7.5186e-07,\n",
      "         8.1528e-05,  2.5649e-05,  2.4092e-05,  1.7589e-05, -3.2410e-05,\n",
      "        -4.2462e-04, -3.9585e-05,  1.7041e-04, -2.5619e-03,  5.1928e-05,\n",
      "        -5.0661e-04, -2.2791e-06, -4.4198e-07, -3.4747e-05,  9.0617e-04,\n",
      "         3.0991e-05,  9.8013e-05,  1.9090e-04,  3.9069e-05,  1.0278e-05,\n",
      "        -9.9994e-05, -6.1808e-06,  2.4527e-05,  4.4455e-05, -7.0363e-05,\n",
      "        -2.0968e-04,  8.7845e-04,  3.3984e-05, -9.4179e-05,  1.0138e-04,\n",
      "         7.2848e-04,  2.5691e-05,  1.7931e-05, -4.0224e-05, -1.2062e-04,\n",
      "         5.4597e-04, -3.1690e-04, -6.2897e-06,  8.6687e-04,  1.1497e-05,\n",
      "         8.2680e-06, -9.0555e-05, -6.2340e-05, -2.0670e-05,  1.0097e-04,\n",
      "         6.0694e-05,  3.3651e-04, -2.4106e-05,  1.9906e-04, -7.2606e-05,\n",
      "         5.6931e-04,  9.0928e-07, -1.3931e-04,  2.6921e-05,  4.2756e-04,\n",
      "        -7.6758e-05, -6.3803e-05, -1.3962e-05,  1.9621e-03, -7.3790e-05,\n",
      "        -3.7509e-05,  2.2013e-03,  8.3406e-04, -4.7940e-06,  2.9809e-07,\n",
      "         1.6304e-05,  1.4816e-06,  1.5031e-05, -2.3917e-06, -1.0928e-03,\n",
      "        -8.5315e-06,  5.7252e-05, -7.7727e-05,  1.0223e-05, -8.6933e-05,\n",
      "         1.7307e-05,  7.5176e-06, -3.6384e-06,  5.9142e-04,  8.9373e-06,\n",
      "         1.4082e-05, -1.2648e-04,  1.0468e-05,  2.3649e-05,  6.5673e-06,\n",
      "        -9.3092e-06,  6.7947e-06,  1.0678e-05, -9.0159e-07, -1.4298e-03,\n",
      "         8.5989e-06, -3.7416e-05,  4.5443e-06,  7.6376e-04, -8.5860e-05,\n",
      "        -4.0172e-06,  1.4235e-05, -1.6145e-05,  5.7093e-05,  3.2960e-04,\n",
      "         1.4139e-05, -5.6151e-04, -5.7546e-05, -5.6358e-06, -2.9675e-06,\n",
      "         8.1028e-06, -5.9103e-07,  1.9185e-05,  1.4209e-05, -1.0324e-05,\n",
      "         8.1022e-04,  1.8578e-04, -4.1131e-05, -3.0760e-06,  7.0690e-04,\n",
      "        -2.5898e-06,  1.1548e-04, -1.0242e-06, -1.1290e-03,  4.9552e-05,\n",
      "        -2.0223e-05, -8.2624e-06,  2.8508e-04, -9.8782e-06, -7.1653e-06,\n",
      "         4.6641e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.1587e-04, 4.7138e-09, 4.2245e-09, 5.8941e-08, 1.3996e-08, 5.8290e-09,\n",
      "        8.9677e-09, 1.0673e-04, 5.9391e-09, 4.5712e-09, 8.2790e-05, 5.3716e-09,\n",
      "        1.8954e-04, 1.1682e-08, 2.0108e-08, 5.2860e-09, 1.0565e-04, 3.7675e-09,\n",
      "        3.5240e-09, 8.7319e-07, 8.0243e-09, 2.2903e-08, 1.6779e-08, 9.7246e-09,\n",
      "        1.0966e-07, 4.1826e-09, 4.4306e-09, 4.1027e-05, 1.2079e-04, 9.0603e-09,\n",
      "        3.3940e-09, 7.2922e-05, 1.4682e-05, 1.1562e-08, 5.5647e-09, 1.6356e-08,\n",
      "        1.0222e-08, 2.6235e-04, 7.5119e-08, 2.0239e-05, 2.6755e-04, 5.0895e-09,\n",
      "        4.6917e-09, 3.6589e-09, 5.4645e-09, 7.7624e-09, 4.1363e-09, 6.5010e-09,\n",
      "        3.0438e-05, 1.1757e-04, 1.6197e-07, 7.1956e-09, 3.6431e-04, 4.1567e-09,\n",
      "        8.6069e-05, 2.0115e-08, 3.6232e-05, 4.3603e-08, 1.3276e-07, 8.1382e-09,\n",
      "        1.2387e-05, 4.7422e-09, 8.0295e-09, 1.2672e-04, 1.0805e-03, 7.0309e-10,\n",
      "        5.3535e-10, 9.5483e-09, 2.2977e-09, 8.3524e-10, 1.4923e-09, 3.8099e-05,\n",
      "        8.8998e-10, 8.5227e-10, 1.0158e-05, 8.6732e-10, 1.5695e-05, 1.6544e-09,\n",
      "        7.9455e-09, 8.0651e-10, 6.2981e-05, 8.9422e-10, 5.6876e-10, 1.9760e-07,\n",
      "        1.1209e-09, 4.0372e-09, 2.7480e-09, 2.1589e-09, 1.3618e-07, 7.4013e-10,\n",
      "        8.2376e-10, 2.3254e-05, 5.4087e-06, 1.7348e-09, 5.3762e-10, 4.5739e-05,\n",
      "        1.2895e-05, 1.3538e-09, 1.0075e-09, 3.3259e-09, 1.9310e-09, 3.3107e-05,\n",
      "        1.0681e-08, 6.2686e-06, 3.6416e-05, 7.8014e-10, 9.1425e-10, 5.6805e-10,\n",
      "        8.1697e-10, 9.3570e-10, 6.2953e-10, 7.7482e-10, 2.9571e-06, 3.0768e-05,\n",
      "        1.3132e-07, 9.3950e-10, 2.4555e-05, 8.0570e-10, 2.0044e-05, 6.3655e-09,\n",
      "        4.4528e-05, 7.5209e-09, 2.9022e-08, 1.4486e-09, 1.1365e-05, 5.6180e-10,\n",
      "        1.0300e-09, 2.3023e-05, 2.3035e-07, 6.7347e-08, 4.9112e-08, 2.7741e-07,\n",
      "        8.7333e-08, 6.4711e-08, 7.1516e-08, 9.6832e-06, 7.4324e-08, 5.5418e-08,\n",
      "        3.2423e-05, 5.4592e-08, 4.2310e-05, 9.3094e-08, 7.1036e-08, 7.4204e-08,\n",
      "        4.9147e-05, 6.7158e-08, 4.7555e-08, 1.3682e-06, 7.2195e-08, 9.5607e-08,\n",
      "        8.3331e-08, 8.7335e-08, 2.0654e-07, 5.5659e-08, 4.3759e-08, 1.2551e-05,\n",
      "        3.1159e-05, 7.2309e-08, 4.6388e-08, 1.3188e-06, 9.9168e-06, 7.8545e-08,\n",
      "        5.3205e-08, 8.7532e-08, 7.3086e-08, 1.9344e-04, 4.0724e-07, 3.8049e-06,\n",
      "        7.0614e-05, 6.3944e-08, 4.3807e-08, 5.5810e-08, 6.0907e-08, 7.0577e-08,\n",
      "        6.2447e-08, 6.5290e-08, 1.7592e-05, 2.2584e-05, 3.9875e-07, 5.6523e-08,\n",
      "        4.4175e-05, 4.9657e-08, 1.1646e-05, 6.7289e-08, 2.1962e-05, 3.1358e-07,\n",
      "        2.7365e-07, 6.0129e-08, 2.7704e-06, 6.4024e-08, 5.3964e-08, 1.1817e-05,\n",
      "        7.7210e-06, 5.3069e-09, 4.7272e-09, 7.5165e-08, 2.3385e-08, 6.3433e-09,\n",
      "        1.0080e-08, 2.4300e-05, 6.6212e-09, 5.1106e-09, 7.0679e-07, 6.4230e-09,\n",
      "        8.0845e-06, 1.2497e-08, 4.7121e-08, 5.9241e-09, 9.0676e-06, 4.4559e-09,\n",
      "        4.1232e-09, 8.9053e-07, 9.9513e-09, 2.6935e-08, 2.6439e-08, 1.2241e-08,\n",
      "        1.3673e-07, 4.6260e-09, 5.4912e-09, 3.5336e-05, 1.3947e-06, 1.0021e-08,\n",
      "        3.7024e-09, 7.1484e-06, 4.3724e-07, 1.3843e-08, 6.2430e-09, 2.0476e-08,\n",
      "        1.4181e-08, 3.9083e-05, 9.9612e-08, 4.9558e-05, 8.5550e-06, 5.3285e-09,\n",
      "        6.6273e-09, 4.0235e-09, 6.3989e-09, 8.5752e-09, 4.3232e-09, 7.4101e-09,\n",
      "        5.4256e-06, 5.3196e-06, 3.5117e-07, 8.1027e-09, 3.4537e-06, 1.3117e-08,\n",
      "        8.6936e-06, 3.7075e-08, 1.2264e-05, 5.8473e-08, 2.5781e-07, 9.9453e-09,\n",
      "        1.6177e-06, 5.0173e-09, 1.0755e-08, 3.2223e-06], device='cuda:0')}, 17: {'step': 257520, 'exp_avg': tensor([[ 5.6052e-45, -2.8026e-45,  4.2039e-45,  ...,  1.4013e-45,\n",
      "         -7.0065e-45, -5.9996e-36],\n",
      "        [ 5.6052e-45, -4.2039e-45, -4.2039e-45,  ..., -4.2039e-45,\n",
      "          1.4013e-45,  5.6052e-45],\n",
      "        [ 3.0555e-41, -2.8026e-45, -4.2039e-45,  ...,  2.8026e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        ...,\n",
      "        [-3.5818e-06, -9.7205e-07, -1.8392e-06,  ..., -1.3801e-08,\n",
      "         -6.0155e-09, -1.0922e-04],\n",
      "        [ 5.6052e-45, -4.2039e-45, -2.8026e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 1.1545e-03, -8.3693e-07,  1.2943e-05,  ...,  1.3182e-08,\n",
      "          2.6219e-08, -5.2581e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[3.7339e-13, 1.6828e-16, 1.2399e-16,  ..., 1.5198e-20, 2.0862e-22,\n",
      "         3.0387e-12],\n",
      "        [1.7145e-13, 1.3906e-17, 3.0688e-17,  ..., 1.3090e-20, 5.5085e-21,\n",
      "         7.3967e-13],\n",
      "        [2.6055e-12, 2.5696e-16, 2.9601e-16,  ..., 2.4153e-18, 2.9831e-20,\n",
      "         2.1298e-13],\n",
      "        ...,\n",
      "        [2.7324e-06, 2.0132e-09, 1.8277e-09,  ..., 1.5967e-13, 5.1153e-13,\n",
      "         4.5473e-06],\n",
      "        [8.9130e-13, 3.1344e-16, 7.2651e-16,  ..., 3.2536e-20, 2.8725e-20,\n",
      "         5.2616e-13],\n",
      "        [9.0742e-06, 2.0444e-09, 2.2217e-09,  ..., 3.7454e-13, 1.0141e-12,\n",
      "         9.5429e-06]], device='cuda:0')}, 18: {'step': 257520, 'exp_avg': tensor([-1.5145e-14, -4.3136e-25, -4.3498e-13,  1.0026e-03, -1.5413e-03,\n",
      "        -2.0901e-07, -1.8823e-06, -2.0314e-10, -3.5775e-19, -4.0562e-31,\n",
      "        -2.7955e-04, -1.5630e-08, -2.8393e-06, -2.2322e-08, -1.7147e-03,\n",
      "        -6.2221e-04, -2.4482e-05,  2.0080e-04, -2.1407e-05, -3.3014e-03,\n",
      "        -1.0866e-06, -1.4419e-06,  3.9100e-03, -1.1460e-06, -1.0594e-06,\n",
      "        -3.3876e-32, -9.0120e-08, -3.2282e-07, -2.2644e-08, -9.7775e-06,\n",
      "        -3.6347e-06, -2.5411e-13, -1.5905e-06, -1.2987e-15, -2.4880e-06,\n",
      "        -1.9627e-17, -9.0740e-04, -3.6567e-04, -8.1099e-08,  6.8284e-05,\n",
      "        -8.9317e-16, -2.7369e-06, -1.1845e-17, -3.3016e-07, -1.7872e-06,\n",
      "        -1.4644e-16, -8.7357e-04, -6.3862e-05, -1.1009e-13,  1.4901e-03,\n",
      "        -2.1023e-11, -5.6100e-16, -3.0059e-08, -6.6983e-08, -3.3110e-07,\n",
      "        -4.9025e-04, -3.7965e-04, -1.4964e-06, -2.0091e-06, -4.7909e-03,\n",
      "        -1.7261e-06, -2.0980e-06, -1.1300e-06,  5.7000e-03,  1.0087e-03,\n",
      "        -5.1090e-08, -2.3145e-06, -6.8448e-07,  9.2718e-04,  3.8366e-03,\n",
      "        -3.1753e-07, -9.6712e-07, -1.2363e-03,  1.5326e-03, -1.4414e-06,\n",
      "         8.7266e-04, -6.8119e-35,  3.3435e-03, -5.2886e-04,  1.8243e-03,\n",
      "        -2.9316e-03, -1.2127e-03, -2.0267e-04, -2.2536e-06, -1.3319e-07,\n",
      "        -8.5332e-09, -1.9712e-06, -1.7685e-06, -5.1930e-22, -1.3112e-07,\n",
      "        -3.6452e-03,  1.1743e-03, -1.0168e-04, -7.1674e-05, -2.7705e-09,\n",
      "        -1.4926e-03, -1.4102e-15,  1.3146e-03, -1.0927e-03, -5.5117e-04,\n",
      "        -4.6340e-12, -1.1064e-06, -3.2110e-26, -7.1483e-12, -7.6181e-12,\n",
      "        -2.8907e-06,  6.7965e-04, -6.9980e-04, -2.4861e-04, -3.6621e-12,\n",
      "        -8.9801e-04, -1.9704e-07, -1.3211e-18,  1.0270e-03,  5.1843e-03,\n",
      "        -1.7330e-06, -9.4088e-06, -8.0094e-07, -1.4994e-43, -7.7180e-07,\n",
      "        -2.7307e-11, -2.8485e-07, -5.4982e-07,  2.0164e-22, -3.7561e-13,\n",
      "        -9.1585e-04, -1.2878e-15,  1.7336e-03], device='cuda:0'), 'exp_avg_sq': tensor([2.7071e-11, 5.8071e-12, 4.4904e-11, 1.1112e-04, 2.3296e-05, 7.0722e-12,\n",
      "        2.0023e-06, 8.9119e-11, 1.3073e-11, 4.0678e-12, 6.6562e-05, 3.9276e-10,\n",
      "        2.8527e-07, 2.8614e-12, 6.9558e-06, 1.5072e-04, 4.0110e-06, 1.6200e-05,\n",
      "        1.6568e-06, 1.9292e-04, 2.3050e-08, 8.9949e-09, 4.5652e-05, 6.4925e-09,\n",
      "        5.8469e-09, 3.8844e-12, 6.8462e-10, 2.0327e-09, 3.5608e-10, 6.9085e-06,\n",
      "        3.5623e-07, 3.9377e-11, 2.6096e-07, 2.4535e-11, 6.0124e-08, 1.5563e-11,\n",
      "        1.3109e-05, 5.1481e-06, 6.3803e-10, 6.9125e-07, 2.3196e-11, 6.4637e-08,\n",
      "        1.5616e-11, 1.8455e-09, 8.5979e-09, 1.0270e-11, 9.9137e-05, 6.7371e-05,\n",
      "        3.8921e-11, 7.9849e-05, 6.5412e-11, 2.1763e-11, 3.2216e-10, 7.5460e-10,\n",
      "        1.9431e-09, 1.9228e-04, 1.0233e-04, 2.1109e-07, 1.7914e-08, 1.8477e-04,\n",
      "        2.4280e-06, 7.5667e-08, 9.1704e-10, 2.8335e-04, 7.2018e-05, 6.6890e-10,\n",
      "        2.5759e-08, 3.2361e-09, 1.7401e-04, 1.6410e-04, 1.7319e-10, 5.5218e-09,\n",
      "        5.1326e-05, 2.7472e-04, 2.8163e-08, 6.4771e-05, 3.3613e-12, 4.2506e-05,\n",
      "        5.1688e-06, 1.2399e-04, 1.1786e-04, 1.8282e-04, 1.2570e-04, 2.1838e-06,\n",
      "        8.6389e-10, 2.7533e-10, 2.7586e-06, 1.3528e-08, 9.1298e-12, 1.3005e-09,\n",
      "        1.4560e-04, 2.4010e-05, 1.2196e-04, 8.1097e-06, 1.1640e-10, 1.5368e-04,\n",
      "        2.4586e-11, 1.7048e-04, 2.1671e-04, 1.2813e-04, 5.2630e-11, 1.4197e-07,\n",
      "        5.8640e-12, 9.6854e-12, 3.4678e-11, 9.7453e-06, 2.1722e-05, 8.5216e-06,\n",
      "        3.4193e-06, 4.2356e-11, 8.5623e-05, 1.2630e-09, 1.0750e-11, 1.5842e-05,\n",
      "        3.1144e-04, 1.2977e-08, 5.7204e-07, 5.9588e-09, 2.2352e-12, 1.9284e-08,\n",
      "        8.2008e-11, 1.7803e-09, 4.1006e-09, 2.9047e-12, 3.7009e-11, 9.9847e-05,\n",
      "        2.3765e-11, 1.3672e-04], device='cuda:0')}, 19: {'step': 257520, 'exp_avg': tensor([[ 2.8026e-45, -5.6052e-45,  2.8026e-45,  ..., -1.0134e-06,\n",
      "         -2.8026e-45,  9.5324e-08],\n",
      "        [ 1.4013e-45,  1.4013e-45, -1.4013e-45,  ..., -1.3224e-17,\n",
      "          0.0000e+00, -4.9844e-14],\n",
      "        [ 0.0000e+00, -4.2039e-45,  5.6052e-45,  ..., -1.2268e-07,\n",
      "          1.4013e-45,  9.8433e-07],\n",
      "        ...,\n",
      "        [-4.2039e-45,  5.6052e-45,  1.4013e-45,  ..., -2.7634e-07,\n",
      "         -4.2039e-45,  7.4636e-06],\n",
      "        [-0.0000e+00,  5.6052e-45, -1.4013e-45,  ..., -6.8073e-08,\n",
      "         -0.0000e+00, -1.7535e-08],\n",
      "        [-5.6052e-45, -1.4013e-45,  0.0000e+00,  ...,  7.3850e-07,\n",
      "         -5.6052e-45, -5.6021e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[3.7333e-20, 2.6429e-16, 7.3321e-27,  ..., 2.0319e-08, 1.0502e-15,\n",
      "         2.0895e-08],\n",
      "        [2.2529e-36, 7.0943e-24, 3.7518e-15,  ..., 1.7710e-11, 7.2866e-18,\n",
      "         4.8696e-11],\n",
      "        [4.6931e-34, 4.0621e-15, 9.2677e-15,  ..., 7.8522e-09, 2.5054e-18,\n",
      "         2.4163e-08],\n",
      "        ...,\n",
      "        [3.2161e-26, 3.8194e-15, 6.4110e-16,  ..., 1.5061e-08, 3.6686e-15,\n",
      "         2.9808e-06],\n",
      "        [6.4534e-18, 1.6422e-19, 5.9533e-28,  ..., 9.0741e-10, 6.9980e-18,\n",
      "         6.8612e-10],\n",
      "        [1.0828e-34, 7.1308e-18, 5.5334e-17,  ..., 5.6414e-07, 3.1215e-14,\n",
      "         5.7860e-09]], device='cuda:0')}, 20: {'step': 257520, 'exp_avg': tensor([ 5.9944e-05, -1.0179e-07, -2.4212e-06, -1.0122e-06, -2.3305e-06,\n",
      "        -2.0087e-06, -4.3708e-04, -6.4101e-06,  1.7324e-04, -4.6083e-06,\n",
      "         1.2417e-04, -5.0559e-06,  3.4397e-04, -8.4524e-06, -4.5518e-06,\n",
      "        -2.7700e-06,  5.5054e-05,  2.1911e-03, -5.1822e-24, -2.3230e-06,\n",
      "        -2.3332e-04,  3.5187e-03, -2.2601e-04, -9.0356e-09, -2.0724e-03,\n",
      "        -7.3098e-06, -1.1610e-07, -1.0488e-03, -5.7056e-06, -1.7976e-06,\n",
      "        -9.3653e-06,  4.4244e-03, -2.6981e-05, -2.7273e-06,  5.4853e-05,\n",
      "        -7.9118e-06, -5.2157e-06, -7.5958e-07, -3.7808e-06, -5.2886e-06,\n",
      "        -2.5764e-07, -3.2007e-08, -5.8523e-07, -1.2041e-13, -8.8539e-06,\n",
      "        -1.8942e-20, -1.3079e-05, -1.9249e-05,  1.8393e-05, -6.8623e-05,\n",
      "        -1.6965e-09, -2.6195e-06,  2.8310e-04, -2.8303e-03,  2.0348e-04,\n",
      "        -3.4847e-07, -7.8675e-06, -1.1768e-03, -6.1057e-06, -4.7543e-14,\n",
      "        -2.0375e-06, -9.6626e-06, -2.8870e-06,  1.0866e-04], device='cuda:0'), 'exp_avg_sq': tensor([7.9167e-08, 7.2063e-10, 5.0556e-08, 8.7832e-10, 1.0103e-08, 1.4281e-07,\n",
      "        4.0350e-06, 1.1162e-07, 2.3075e-06, 2.9276e-06, 1.4886e-06, 3.4272e-07,\n",
      "        9.3261e-06, 6.1951e-07, 9.0785e-08, 1.6530e-07, 2.0931e-06, 1.6639e-05,\n",
      "        6.8283e-12, 1.0649e-08, 8.0959e-06, 5.1041e-04, 5.6353e-06, 2.0278e-10,\n",
      "        5.0430e-05, 1.2904e-07, 7.6453e-10, 6.4485e-04, 3.4952e-07, 2.5892e-06,\n",
      "        2.7492e-06, 7.4511e-04, 6.7172e-07, 7.7944e-07, 3.2831e-06, 6.4167e-07,\n",
      "        8.7952e-07, 1.5320e-09, 1.4517e-08, 3.0099e-08, 1.0561e-09, 5.2322e-10,\n",
      "        1.4293e-09, 7.9348e-12, 2.3293e-07, 1.0388e-11, 7.6088e-06, 2.4177e-06,\n",
      "        1.7171e-06, 2.3989e-06, 1.5635e-10, 9.2950e-08, 1.0894e-06, 7.5677e-04,\n",
      "        4.6080e-05, 7.5511e-10, 6.8937e-08, 2.7983e-05, 4.3344e-08, 3.1412e-11,\n",
      "        1.2856e-06, 8.1772e-07, 5.1559e-08, 9.7712e-07], device='cuda:0')}, 21: {'step': 257520, 'exp_avg': tensor([[-8.9945e-07, -1.7507e-08,  2.5447e-08,  ..., -8.1081e-07,\n",
      "         -1.7225e-06, -1.1612e-05],\n",
      "        [-2.6911e-06, -1.3758e-08,  1.5652e-07,  ..., -7.6399e-07,\n",
      "         -4.4779e-07, -1.7102e-04],\n",
      "        [ 5.2395e-07, -2.3550e-15,  9.6180e-07,  ...,  4.2780e-06,\n",
      "          2.8251e-08,  2.6966e-07],\n",
      "        ...,\n",
      "        [ 7.5458e-07,  9.1355e-11,  6.1217e-07,  ...,  2.8363e-06,\n",
      "          2.3180e-08,  2.7137e-07],\n",
      "        [-4.2960e-07,  1.8335e-18,  1.2551e-07,  ..., -1.3247e-06,\n",
      "          7.6498e-07, -2.3180e-08],\n",
      "        [ 1.6374e-07, -8.5633e-10, -3.8139e-07,  ...,  1.7312e-06,\n",
      "         -3.5536e-07, -4.2526e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[3.0717e-08, 6.4267e-10, 3.2675e-09,  ..., 1.2954e-07, 1.8590e-08,\n",
      "         2.3620e-06],\n",
      "        [2.8814e-08, 5.6401e-10, 3.6667e-09,  ..., 1.0659e-07, 9.7639e-09,\n",
      "         2.8387e-06],\n",
      "        [2.5020e-08, 2.7949e-11, 8.0513e-08,  ..., 3.7090e-07, 4.6835e-10,\n",
      "         9.5482e-10],\n",
      "        ...,\n",
      "        [1.2885e-08, 1.0499e-10, 2.8311e-09,  ..., 5.7241e-07, 9.6114e-10,\n",
      "         1.6308e-09],\n",
      "        [2.3100e-08, 1.8737e-11, 5.6195e-08,  ..., 1.2742e-08, 4.7238e-09,\n",
      "         4.8565e-10],\n",
      "        [1.5308e-08, 1.7898e-10, 4.4427e-08,  ..., 2.4688e-08, 2.9196e-09,\n",
      "         2.3924e-08]], device='cuda:0')}, 22: {'step': 257520, 'exp_avg': tensor([ 0.0021,  0.0016, -0.0017, -0.0010,  0.0016, -0.0016, -0.0007,  0.0008,\n",
      "        -0.0033,  0.0002, -0.0004,  0.0038, -0.0031,  0.0031,  0.0018, -0.0022,\n",
      "         0.0018,  0.0008, -0.0030,  0.0007,  0.0010,  0.0003,  0.0020, -0.0005,\n",
      "         0.0033,  0.0029, -0.0011,  0.0019, -0.0018,  0.0023, -0.0017, -0.0005],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([1.1374e-04, 1.3015e-04, 1.8141e-04, 1.1952e-04, 1.2476e-04, 2.5210e-04,\n",
      "        9.6961e-05, 1.8727e-04, 1.6317e-04, 1.5609e-04, 1.7188e-04, 1.6593e-04,\n",
      "        1.9931e-04, 6.1847e-05, 9.0891e-05, 1.3462e-04, 1.4474e-04, 1.4554e-04,\n",
      "        1.3846e-04, 1.3334e-04, 2.0197e-04, 9.4550e-05, 1.9884e-04, 2.0585e-04,\n",
      "        1.1127e-04, 9.7254e-05, 1.9348e-04, 1.2854e-04, 9.3978e-05, 1.2409e-04,\n",
      "        1.0595e-04, 1.5738e-04], device='cuda:0')}, 23: {'step': 257520, 'exp_avg': tensor([[-3.5637e-03, -1.1364e-03, -2.4387e-03, -3.9916e-03,  1.2022e-03,\n",
      "          9.0513e-05, -4.4227e-03, -1.9305e-03, -8.9323e-03, -2.4096e-03,\n",
      "          1.0846e-03, -2.9216e-03,  4.7698e-03,  2.0151e-04, -1.6636e-03,\n",
      "         -9.0991e-03, -1.8613e-03,  1.8657e-03, -5.7347e-03, -2.6410e-03,\n",
      "         -3.0689e-03, -7.2830e-03, -5.0579e-05, -3.2371e-05, -2.9572e-05,\n",
      "          4.6758e-03,  2.2640e-03,  3.5447e-03, -1.4241e-02,  6.5105e-03,\n",
      "         -1.4412e-02, -1.0926e-03],\n",
      "        [-1.6303e-02, -9.0458e-03,  4.7633e-03,  4.7606e-03, -9.2983e-03,\n",
      "         -3.7633e-03,  9.9606e-04,  1.6177e-03,  5.5208e-03,  5.2365e-03,\n",
      "          6.1107e-03,  1.7145e-02, -7.7442e-03, -1.1470e-02, -1.3061e-02,\n",
      "          3.7251e-03, -1.3826e-02,  3.6993e-03,  1.9292e-04,  1.5154e-02,\n",
      "          1.6589e-02, -5.8597e-03,  1.2524e-02, -6.9708e-04, -1.5306e-02,\n",
      "         -1.1437e-02, -5.8210e-04,  7.0188e-03,  1.1887e-02,  8.4719e-03,\n",
      "          1.1195e-02,  7.3623e-03],\n",
      "        [ 1.9867e-02,  1.0185e-02, -2.3251e-03, -7.6704e-04,  8.0963e-03,\n",
      "          3.6731e-03,  3.4277e-03,  3.1140e-04,  3.4111e-03, -2.8284e-03,\n",
      "         -7.1953e-03, -1.4222e-02,  2.9739e-03,  1.1272e-02,  1.4724e-02,\n",
      "          5.3737e-03,  1.5687e-02, -5.5664e-03,  5.5443e-03, -1.2512e-02,\n",
      "         -1.3520e-02,  1.3143e-02, -1.2475e-02,  7.2814e-04,  1.5334e-02,\n",
      "          6.7608e-03, -1.6811e-03, -1.0563e-02,  2.3546e-03, -1.4982e-02,\n",
      "          3.2170e-03, -6.2694e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[0.0005, 0.0004, 0.0014, 0.0020, 0.0006, 0.0005, 0.0011, 0.0013, 0.0016,\n",
      "         0.0005, 0.0003, 0.0006, 0.0007, 0.0004, 0.0006, 0.0013, 0.0003, 0.0004,\n",
      "         0.0010, 0.0006, 0.0005, 0.0018, 0.0006, 0.0004, 0.0004, 0.0016, 0.0005,\n",
      "         0.0005, 0.0012, 0.0005, 0.0013, 0.0013],\n",
      "        [0.0016, 0.0014, 0.0013, 0.0020, 0.0011, 0.0022, 0.0008, 0.0010, 0.0011,\n",
      "         0.0018, 0.0011, 0.0011, 0.0024, 0.0008, 0.0017, 0.0009, 0.0015, 0.0007,\n",
      "         0.0007, 0.0010, 0.0027, 0.0019, 0.0014, 0.0020, 0.0015, 0.0017, 0.0012,\n",
      "         0.0011, 0.0008, 0.0008, 0.0009, 0.0013],\n",
      "        [0.0021, 0.0017, 0.0006, 0.0022, 0.0016, 0.0024, 0.0004, 0.0004, 0.0005,\n",
      "         0.0019, 0.0009, 0.0007, 0.0026, 0.0012, 0.0022, 0.0004, 0.0017, 0.0004,\n",
      "         0.0003, 0.0006, 0.0026, 0.0022, 0.0010, 0.0020, 0.0019, 0.0019, 0.0009,\n",
      "         0.0007, 0.0004, 0.0004, 0.0004, 0.0005]], device='cuda:0')}, 24: {'step': 257520, 'exp_avg': tensor([-0.0060,  0.0043,  0.0017], device='cuda:0'), 'exp_avg_sq': tensor([0.0025, 0.0026, 0.0025], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 0.005, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 1e-05, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model, 'sm_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsH495dMz4Xu",
    "outputId": "0632ab0c-b244-4bab-bd1d-e24426d6b445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(33589, 200)\n",
       "  (lstm): LSTM(200, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (FC_concat1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (FC_concat2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (FC_concat3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (output): Linear(in_features=32, out_features=3, bias=True)\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=32, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = torch.load('sm_1')\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkfY79IF0Eav",
    "outputId": "d0797bd8-350e-4e8d-a8cd-bb39afe9d168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=32, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vufrSKr90mt0",
    "outputId": "ba80614c-2cb8-4d80-c941-c770f779b7c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people like to listen to rock music', 'rock and roll people love'),\n",
       " ('a girl is dancing on the stage', 'girl dance')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_o = [''] * len(rw)\n",
    "sentence_p = [''] * len(rw)\n",
    "# sentence_o = [''] * 2\n",
    "# sentence_p = [''] * 2\n",
    "\n",
    "# sentence_o[0] = \"rock music is very good for public\"\n",
    "# sentence_p[0] = \"people dont like rock and roll\"\n",
    "sentence_o[0] = \"people like to listen to rock music\"\n",
    "sentence_p[0] = \"rock and roll people love\"\n",
    "sentence_o[1] = \"a girl is dancing on the stage\"\n",
    "sentence_p[1] = \"girl dance\"\n",
    "\n",
    "sentence_o[0] = clean_text(sentence_o[0])\n",
    "sentence_p[0] = clean_text(sentence_p[0])\n",
    "sentence_o[1] = clean_text(sentence_o[1])\n",
    "sentence_p[1] = clean_text(sentence_p[1])\n",
    "\n",
    "sen_p = []\n",
    "for i in range(2):\n",
    "  sen1 = sentence_o[i]\n",
    "  sen2 = sentence_p[i]\n",
    "  sen_p.append((sen1, sen2))\n",
    "\n",
    "sen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5QABAtRQynp",
    "outputId": "d2b0fd48-e128-482f-fff4-005d59b99896"
   },
   "outputs": [],
   "source": [
    "# rw_sentence_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKnftM-cSWiC",
    "outputId": "9d57aebc-60f6-4348-cef1-bd37278456ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 9, 10, 11, 12, 13, 14, 15, 16, 6, 7])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_pairs = get_pair_indices(vocab, rw_sentence_pairs)\n",
    "# id_pairs = get_pair_indices(vocab, sen_p)\n",
    "id_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzurbdbC0pe9",
    "outputId": "e65643f5-9519-47e0-87b7-bd03ce07a9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "premise_seq    = [torch.tensor(seq[0]).long().to(device) for seq in id_pairs]\n",
    "hypothesis_seq = [torch.tensor(seq[1]).long().to(device) for seq in id_pairs]\n",
    "\n",
    "premise_len    = list(map(len, premise_seq))\n",
    "hypothesis_len = list(map(len, hypothesis_seq))\n",
    "\n",
    "batch = len(premise_seq)\n",
    "temp = pad_sequence(premise_seq + hypothesis_seq, batch_first=True)\n",
    "premise_seq    = temp[:batch, :]\n",
    "hypothesis_seq = temp[batch:, :]\n",
    "\n",
    "prediction = lstm_model([premise_seq, hypothesis_seq], premise_len, hypothesis_len)\n",
    "# prediction = prediction[prediction!=prediction[0,3]]\n",
    "\n",
    "prediction_list = prediction.to('cpu')\n",
    "prediction_list = prediction_list.tolist()\n",
    "print(len(prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8696,  0.6217, -0.0253],\n",
       "        [-1.9065,  1.6477, -0.1347],\n",
       "        [-0.0615,  0.3212, -0.4463],\n",
       "        [-0.6877,  0.3944,  0.0492],\n",
       "        [-0.6813,  0.5628, -0.1376],\n",
       "        [-1.2927,  0.5959,  0.3359],\n",
       "        [ 0.3494,  0.7090, -1.1463],\n",
       "        [-1.0383,  0.5665,  0.1767],\n",
       "        [-0.9075,  0.4701,  0.1568],\n",
       "        [-0.9460,  1.6476, -0.9519],\n",
       "        [-1.0585,  1.6333, -0.8350],\n",
       "        [-1.2694,  1.6645, -0.6846],\n",
       "        [-0.3276, -0.0769,  0.2976],\n",
       "        [-1.0597,  0.5145,  0.2316],\n",
       "        [-0.9506,  0.2287,  0.4170],\n",
       "        [-1.0315, -0.0863,  0.9526],\n",
       "        [ 0.1711,  0.9141, -1.1975],\n",
       "        [-0.5653,  0.3290,  0.0131],\n",
       "        [-1.0102, -0.5361,  1.8214],\n",
       "        [-1.3167,  0.6405,  0.3191],\n",
       "        [-0.7040,  0.2054,  0.3038],\n",
       "        [-0.6242,  0.8319, -0.4530],\n",
       "        [-0.8098,  0.8204, -0.2944],\n",
       "        [-1.6101,  1.0189,  0.2162],\n",
       "        [-0.6674,  0.6089, -0.2219],\n",
       "        [ 0.6761,  0.8817, -1.5859],\n",
       "        [ 0.4457,  0.5524, -1.0853],\n",
       "        [ 0.1176,  0.7096, -0.9664],\n",
       "        [-1.7029,  1.5770, -0.2346],\n",
       "        [-1.7594,  1.0970,  0.2674],\n",
       "        [-1.4723,  0.9473,  0.1679],\n",
       "        [-0.9697,  0.3501,  0.3008],\n",
       "        [-1.1769,  1.4380, -0.5463],\n",
       "        [-0.0890,  1.7699, -1.8231],\n",
       "        [-2.1252,  1.3375,  0.3314],\n",
       "        [-0.7898,  0.2006,  0.3165],\n",
       "        [-0.1421,  0.2412, -0.2219],\n",
       "        [-2.0616,  1.2558,  0.3689],\n",
       "        [ 0.1747, -0.1994,  0.0394],\n",
       "        [ 0.2505,  1.1646, -1.4920],\n",
       "        [-1.3266,  0.5752,  0.3759],\n",
       "        [-1.7935,  1.1181,  0.2709],\n",
       "        [-1.2244,  0.8145,  0.0877],\n",
       "        [-0.9256,  0.6515, -0.0055],\n",
       "        [-1.9735,  1.2089,  0.3408],\n",
       "        [-3.2048,  1.8687,  0.7205],\n",
       "        [-1.7549,  0.8443,  0.4778],\n",
       "        [-1.0901,  0.5948,  0.1921],\n",
       "        [-1.2401,  1.0558, -0.1547],\n",
       "        [-1.2715,  0.3256,  0.5724],\n",
       "        [-1.9803,  1.2125,  0.3432],\n",
       "        [-1.2172,  0.8106,  0.0854],\n",
       "        [ 0.2439,  0.2222, -0.6172],\n",
       "        [-0.2804,  0.3320, -0.2402],\n",
       "        [-1.3160,  0.8635,  0.1162],\n",
       "        [-0.9191,  0.8925, -0.2683],\n",
       "        [-1.2731, -0.1113,  1.2301],\n",
       "        [-1.2877,  1.1883, -0.2302],\n",
       "        [-0.0705, -0.0466,  0.0642],\n",
       "        [-0.7325,  0.7078, -0.2578],\n",
       "        [-0.4504,  0.5428, -0.3355],\n",
       "        [-0.0043,  1.0102, -1.1745],\n",
       "        [ 0.0897,  0.2172, -0.4632],\n",
       "        [-1.4498,  0.9351,  0.1613],\n",
       "        [-0.0859,  0.2914, -0.3878],\n",
       "        [ 0.3514, -0.1398, -0.3252],\n",
       "        [-1.0907,  0.4736,  0.2848],\n",
       "        [-1.9303,  1.6630, -0.1290],\n",
       "        [-1.0929, -0.0678,  0.9769],\n",
       "        [-0.0628,  0.1989, -0.2459],\n",
       "        [ 0.1375,  0.8035, -1.0690],\n",
       "        [-1.5344, -0.1183,  1.4930],\n",
       "        [-0.8757,  0.6242, -0.0211],\n",
       "        [-0.8515,  0.8226, -0.2619],\n",
       "        [ 0.0501,  0.5200, -0.7299],\n",
       "        [-0.0992,  0.2806, -0.3528],\n",
       "        [-1.8466,  0.6728,  0.6747],\n",
       "        [-1.8029,  1.1198,  0.2824],\n",
       "        [-0.6324, -0.5711,  1.5246],\n",
       "        [-0.9100,  0.6429, -0.0104],\n",
       "        [ 0.1543,  0.8610, -1.1351],\n",
       "        [-1.3229, -0.7166,  2.4898],\n",
       "        [-0.0190,  0.3870, -0.5454],\n",
       "        [ 0.8695, -0.1653, -0.8028],\n",
       "        [-1.1462,  0.4593,  0.3353],\n",
       "        [ 0.0959,  0.6419, -0.8846],\n",
       "        [-1.1920,  0.9661, -0.1161],\n",
       "        [-0.0857, -0.0415,  0.0819],\n",
       "        [-1.4810,  0.9560,  0.1664],\n",
       "        [-1.4605,  0.9407,  0.1649],\n",
       "        [ 0.1175,  0.7092, -0.9660],\n",
       "        [-1.7205,  1.0766,  0.2541],\n",
       "        [-2.0769,  1.2640,  0.3735],\n",
       "        [-0.1421,  0.2412, -0.2219],\n",
       "        [ 0.0195,  0.9519, -1.1407],\n",
       "        [-1.3397,  0.8774,  0.1237],\n",
       "        [-0.6175, -0.1080,  0.6047],\n",
       "        [ 0.4586, -0.2133, -0.3429],\n",
       "        [ 0.1695,  0.9089, -1.1914],\n",
       "        [-0.9651,  1.0232, -0.3434]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "soft.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saudi stock exchange appoints its first female head',\n",
       " 'saudi stock exchange appointed sarah al ceo investment bank ncb capital first female')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_sentence_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8696,  0.6217, -0.0253], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('what makes fireworks explode',\n",
       " 'hollywood actor morgan freeman said would like make movie india morgan')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rw_sentence_pairs[1]\n",
    "# 0: entailment\n",
    "# 1: neutral\n",
    "# 2: contradiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.8695, 1.8687, 2.4898], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([83, 45, 81], device='cuda:0')) torch.return_types.min(\n",
      "values=tensor([-3.2048, -0.7166, -1.8231], device='cuda:0', grad_fn=<MinBackward0>),\n",
      "indices=tensor([45, 81, 33], device='cuda:0'))\n",
      "3.657499452431997\n"
     ]
    }
   ],
   "source": [
    "maxi = torch.max(prediction, dim=0)\n",
    "mini = torch.min(prediction, dim=0)\n",
    "# print(maxi[0][0])\n",
    "denom1 = float(maxi[0][0].to('cpu')) - float(mini[0][0].to('cpu'))\n",
    "denom2 = float(maxi[0][1].to('cpu')) - float(mini[0][1].to('cpu'))\n",
    "denom3 = float(maxi[0][2].to('cpu')) - float(mini[0][2].to('cpu'))\n",
    "denom = ( denom1 + denom2 + denom3 ) / 3\n",
    "print(maxi, mini)\n",
    "print(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23776825183719902, 0.16997312833714423, -0.006914738727502434], [-0.5212526456440189, 0.450503266169341, -0.03681542751502372], [-0.01681006866418081, 0.08781571963079066, -0.12202273668337109], [-0.1880111832399699, 0.1078229851786897, 0.01344966177176972], [-0.18626213906693254, 0.15387304358147239, -0.03760914720258072], [-0.35344127176150425, 0.1629380354691826, 0.09184596386591791], [0.0955209920691452, 0.1938372183191216, -0.31340734776402424], [-0.2838898521209764, 0.15488923162960536, 0.04830902996244051], [-0.2481276465776757, 0.1285250218000388, 0.042869467709664356], [-0.258649224643815, 0.4504627203379254, -0.26025042646050073], [-0.28941500388604957, 0.4465719175845136, -0.22829095708179742], [-0.3470685687101507, 0.4550870962647071, -0.18717882034391436], [-0.08957249651966674, -0.02101188304124699, 0.08135706039462925], [-0.2897435098626078, 0.1406793681119041, 0.06332127071309247], [-0.2599103499291575, 0.06252003831320324, 0.11401962838691664], [-0.28201509631468324, -0.023588478552170503, 0.2604611409300363], [0.04679154355410776, 0.2499197625483142, -0.3274197133191345], [-0.15457169323525885, 0.0899386719855004, 0.003581274116356595], [-0.2762062541021487, -0.1465746961473176, 0.49798292365375846], [-0.360002786711082, 0.17512958681847632, 0.08725825519021543], [-0.19246780241892497, 0.05615335683930468, 0.08306461353600092], [-0.17067422247433597, 0.22745965346188418, -0.12385822593789735], [-0.2214033154528426, 0.2243093336216013, -0.08048547983647492], [-0.440207982080307, 0.2785832697654477, 0.05911797334942709], [-0.18247139716757707, 0.16648872909813908, -0.060662243147603746], [0.1848534973563591, 0.24106610439926887, -0.4335974144970631], [0.12185857332615017, 0.15104317921906632, -0.2967255737372308], [0.03215437211474568, 0.1940018787213016, -0.2642284809749252], [-0.46560378536403585, 0.431165772777934, -0.06414160675079401], [-0.48104297958625486, 0.2999332574547577, 0.0731196728086123], [-0.40255068262878113, 0.25901128522924977, 0.04591516366020105], [-0.265120195928061, 0.09571135214019275, 0.0822484494166444], [-0.3217818219794096, 0.39317537172104805, -0.14937351557047657], [-0.02433297449222308, 0.48390035253524843, -0.49846504096750477], [-0.5810639396734089, 0.36568748175974014, 0.09061239605683098], [-0.21593366975762537, 0.05483506323539058, 0.08652675167946194], [-0.03886199791159634, 0.06595937757477097, -0.060663550946225574], [-0.5636626075114357, 0.34335458358972115, 0.10084860513023731], [0.04777074249417975, -0.05452228750954537, 0.010768731634969638], [0.06848010034332769, 0.31842473143615163, -0.40791811632454533], [-0.36270299567367176, 0.15725790345621435, 0.10277282098409742], [-0.490360959209856, 0.30571169029373046, 0.07405344917287508], [-0.3347659400349208, 0.22269773460216508, 0.023978809588187384], [-0.2530794855014294, 0.17811350252508346, -0.0015136281986914137], [-0.5395673019924305, 0.3305318014389587, 0.09318679560682874], [-0.8762365493998182, 0.5109124482465517, 0.1969992879763059], [-0.47980026940923215, 0.23084633855090209, 0.13064012736301758], [-0.2980340568144117, 0.16261503772856428, 0.05252281415991457], [-0.33906575375170483, 0.2886596259207045, -0.04230225792858007], [-0.3476310932313748, 0.08903546796035972, 0.1564956646407784], [-0.5414451867374824, 0.33151357116074526, 0.09383068883233682], [-0.33278512624195034, 0.22161662107478775, 0.023360648624658944], [0.06668908439022157, 0.06074976787592997, -0.16875227184176478], [-0.07667703172898718, 0.09076433699702546, -0.06566092652168073], [-0.3598064783970816, 0.23610139119624732, 0.031758940256689766], [-0.2513029979280287, 0.24403279464614674, -0.0733533980152696], [-0.3480780751703092, -0.030422459696240342, 0.33633425540152745], [-0.3520597801132855, 0.3248913678364923, -0.06294996183210771], [-0.01926610632769468, -0.012742321979477476, 0.017562904366784413], [-0.2002683119307494, 0.19352157032527517, -0.0704791173893895], [-0.12315128948536698, 0.14841185579883748, -0.09172877533146855], [-0.0011824536610824253, 0.2762030273840537, -0.3211226262877844], [0.02452292714936975, 0.05939709668705954, -0.12664826966563134], [-0.39638628215666993, 0.25567176237339784, 0.044092157567597774], [-0.023476044537944423, 0.07965895110747999, -0.10603090180116327], [0.09606707336532981, -0.0382219140060615, -0.0889177905292293], [-0.2982036713696264, 0.12949144016604017, 0.07786382842225299], [-0.5277666398361979, 0.4546946751953787, -0.03526001087251897], [-0.2988210826915772, -0.01853427688582049, 0.2671007489761349], [-0.017180253082799135, 0.05439073763508996, -0.06724323655578264], [0.03758522793246001, 0.21969656084271663, -0.29227077977255167], [-0.41952778284404507, -0.03234113472104845, 0.40819290885241144], [-0.23942489453751664, 0.17066084300183104, -0.005774912782869169], [-0.23280503791733273, 0.22489516221795583, -0.07160469606990896], [0.013690899690759269, 0.14216484808418367, -0.19957531718190719], [-0.027119082601674553, 0.07672786883553909, -0.09646154780071865], [-0.5048906426397487, 0.18396192907222755, 0.18447173423467772], [-0.4929442892725611, 0.3061556410732423, 0.07720046081228282], [-0.1729108596039475, -0.15613301737932636, 0.41684960682521494], [-0.24880907077173292, 0.17578270389470033, -0.0028463238840016575], [0.042194354356931786, 0.23539920518980123, -0.3103569584053494], [-0.3616944344137633, -0.19591753888324318, 0.6807365445787537], [-0.005194893908741187, 0.10580521079663134, -0.14911433514329223], [0.2377318779241284, -0.04520796646277411, -0.2195075044961519], [-0.3133880526416785, 0.12558865944394249, 0.09166518616981907], [0.026206980656938616, 0.17550870989807998, -0.2418514191380507], [-0.32591775752870333, 0.26413586764697694, -0.03175421018130054], [-0.02344310919819722, -0.011343572278417424, 0.02240591488933484], [-0.40491426992990714, 0.26136737611459954, 0.045485537553444214], [-0.3993090368884768, 0.2571998904328216, 0.04509432242926242], [0.03213221287267677, 0.19389704297632693, -0.2641140791515578], [-0.4703932454034545, 0.2943651805610877, 0.06946803831157358], [-0.5678356992084899, 0.3455916444297896, 0.10213230114568862], [-0.03886199791159634, 0.06595937757477097, -0.060663550946225574], [0.005327238240303311, 0.26025249612311724, -0.3118850538716611], [-0.3662807741787588, 0.2398984235662324, 0.033813846341674406], [-0.1688409902928206, -0.029525491140852626, 0.16533944707686637], [0.12537842572280997, -0.05830691005210959, -0.09375225350813925], [0.04633979487253309, 0.24849293388120544, -0.3257430584480056], [-0.26387944133776253, 0.27975420990969124, -0.09389758619486145]]\n"
     ]
    }
   ],
   "source": [
    "aa = []\n",
    "for i in prediction:\n",
    "    a = []\n",
    "    for j in i:\n",
    "        a.append(float(j.to('cpu'))/denom)\n",
    "    aa.append(a)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15347316154137713, -0.29968255531085075, 0.01489551748287741, -0.13275472447344808, -0.11308653199645441, -0.26278765764032114, 0.1610988664523036, -0.20161433330992967, -0.17957818890668983, -0.05944290712090239, -0.08895814080197252, -0.13824290261218855, -0.09194273200082731, -0.21307169873534648, -0.21724836793386423, -0.2677632214977649, 0.1390094534963514, -0.109244229830873, -0.29969530981043163, -0.26371216778282225, -0.15608466264567256, -0.06933021833718361, -0.11729719662568942, -0.29500454986264035, -0.10529325693326791, 0.2620268081062872, 0.16770760556196024, 0.10273246337790395, -0.25643505965014823, -0.32376438357801474, -0.2684535236481361, -0.20903967491630018, -0.1401314876759332, 0.16777069767865066, -0.38915895918785565, -0.1798634629719839, -0.011948664218833418, -0.3819004552035514, 0.021586471902904032, 0.18690065442894896, -0.27379676184715485, -0.33009976914570327, -0.2210191917750195, -0.1641740970587568, -0.3649827217122683, -0.6010803964789118, -0.35131308739747935, -0.2114742565341381, -0.1989661665842106, -0.28746379278711715, -0.36630533227387607, -0.21964075084209056, 0.08018874114401009, -0.03786095588264252, -0.23857988877328895, -0.13662194040648226, -0.3296558794782766, -0.1959090923782501, -0.023880976880754978, -0.11055543850705077, -0.0581182391190951, 0.10480679740216597, 0.041556648526336386, -0.2641411852132112, 0.005750340835679244, 0.06806433730937612, -0.225671568444381, -0.3039453033257604, -0.2813781462368739, 0.003290792079167581, 0.11820643037656316, -0.39487905931932815, -0.15467196431488803, -0.1275179264153457, 0.06481579201466038, 0.001598697036023125, -0.3944625046801672, -0.33214642265471167, -0.20929240761108917, -0.16120235121278292, 0.12885826111129745, -0.3915795493975095, 0.03279627797524526, 0.19317714424312615, -0.24142720430272538, 0.08977619369217354, -0.19702524472334493, -0.026874303848472447, -0.269682028117263, -0.2661996594291398, 0.10266932644568444, -0.31626385129175333, -0.3848266468790262, -0.011948664218833418, 0.10426498091469583, -0.2429501777614752, -0.16706979115556028, 0.08684974534594125, 0.13801195596833524, -0.13339209500240307]\n"
     ]
    }
   ],
   "source": [
    "e_scores = []\n",
    "for i in aa:\n",
    "    e_scores.append(i[0] + i[1]*0.5 + i[2]*0.1)\n",
    "print(e_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_labels = []\n",
    "for i in e_scores:\n",
    "    if i < 0:\n",
    "        E_labels.append('NEGATIVE ENTAILMENT')\n",
    "    elif i > 0.2:\n",
    "        E_labels.append('PERFECT ENTAILMENT')\n",
    "    else:\n",
    "        E_labels.append('NEUTRAL ENTAILMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence pairs</th>\n",
       "      <th>entailment scores (raw: e, n, c)</th>\n",
       "      <th>entailment_metric [-1:1]</th>\n",
       "      <th>entailment_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(saudi stock exchange appoints its first femal...</td>\n",
       "      <td>[-0.23776825183719902, 0.16997312833714423, -0...</td>\n",
       "      <td>-0.153473</td>\n",
       "      <td>NEGATIVE ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(what makes fireworks explode, hollywood actor...</td>\n",
       "      <td>[-0.5212526456440189, 0.450503266169341, -0.03...</td>\n",
       "      <td>-0.299683</td>\n",
       "      <td>NEGATIVE ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(british firms to increase investment in india...</td>\n",
       "      <td>[-0.01681006866418081, 0.08781571963079066, -0...</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>NEUTRAL ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(railways increase senior citizen women quota,...</td>\n",
       "      <td>[-0.1880111832399699, 0.1078229851786897, 0.01...</td>\n",
       "      <td>-0.132755</td>\n",
       "      <td>NEGATIVE ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(pilots arrested in scotland for drinking befo...</td>\n",
       "      <td>[-0.18626213906693254, 0.15387304358147239, -0...</td>\n",
       "      <td>-0.113087</td>\n",
       "      <td>NEGATIVE ENTAILMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sentence pairs  \\\n",
       "0  (saudi stock exchange appoints its first femal...   \n",
       "1  (what makes fireworks explode, hollywood actor...   \n",
       "2  (british firms to increase investment in india...   \n",
       "3  (railways increase senior citizen women quota,...   \n",
       "4  (pilots arrested in scotland for drinking befo...   \n",
       "\n",
       "                    entailment scores (raw: e, n, c)  \\\n",
       "0  [-0.23776825183719902, 0.16997312833714423, -0...   \n",
       "1  [-0.5212526456440189, 0.450503266169341, -0.03...   \n",
       "2  [-0.01681006866418081, 0.08781571963079066, -0...   \n",
       "3  [-0.1880111832399699, 0.1078229851786897, 0.01...   \n",
       "4  [-0.18626213906693254, 0.15387304358147239, -0...   \n",
       "\n",
       "   entailment_metric [-1:1]    entailment_labels  \n",
       "0                 -0.153473  NEGATIVE ENTAILMENT  \n",
       "1                 -0.299683  NEGATIVE ENTAILMENT  \n",
       "2                  0.014896   NEUTRAL ENTAILMENT  \n",
       "3                 -0.132755  NEGATIVE ENTAILMENT  \n",
       "4                 -0.113087  NEGATIVE ENTAILMENT  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_E = pd.DataFrame(list(zip(rw_sentence_pairs, aa, e_scores, E_labels)), columns =['sentence pairs', 'entailment scores (raw: e, n, c)', 'entailment_metric [-1:1]', 'entailment_labels'])\n",
    "# df_final_E.to_csv('entailment_scores_of_test_pairs.csv')\n",
    "df_final_E.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testcases_df = pd.read_csv('ins.csv')\n",
    "# testcases_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arsenal beat sunderland to go top of premier league', 'arsenal alexis sanchez substitute olivier giroud scored brace secure')\n",
      "('over killed in blast at shrine in balochistan', 'victims reportedly attending sufi dance called shrine blast occurred in balochistan')\n",
      "('mercedes self driving car to save passengers not', 'executive von hugo said know save least one person least save one save one car')\n",
      "('raveena govinda dance to mein at zee cine awards', 'video shows performing performing kisi disco mein film bade')\n",
      "('nda slams nitish govt over law and order issue', 'opposition also brought alleged rape minor girl rjd mla raised anti government slogans following')\n",
      "('would choose ranbir ranveer for ram remake jackie', 'actor jackie shroff said would choose actors ranbir kapoor ran')\n",
      "('poor affects rd humans report', 'according global nutrition report poor nutrition affects third human population report states five billion adults')\n",
      "('uefa chief to resign after losing appeal', 'european football president michel said resigning european football president michael michel')\n",
      "('affordable housing sector to hit bn in study', 'affordable housing market estimated touch billion lakh crore per annum next')\n",
      "('cross border in search for food', 'colombia reportedly cost times subsidised prices venezuela comes amid economic crisis')\n",
      "('bayern munich celebrate beer festival', 'german football club bayern players staff celebrated beginning oktoberfest festival wed wednesday')\n",
      "('fire destroys durga puja in ranchi', 'fire destroyed durga puja pandal rr sporting club ranchi friday morning')\n",
      "('radio show helps ease man elephant conflict in chhattisgarh', 'elephant bulletin tells elephants spotted spotted advises vigilant incidents radio jockey mishra')\n",
      "('pics from the big bang theory season out', 'television network released pictures upcoming th season american sitcom big bang theory season')\n",
      "('jio telcos to due to competition fitch', 'fitch ratings agency fitch ratings said ongoing consolidation likely leave four larger operators f')\n",
      "('dravid appointed to icc committee', 'icc cricket committee represents players umpires and media making recommendations committee represents players')\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for i in range(len(soft)):\n",
    "    if soft[i] == 2:\n",
    "        print(rw_sentence_pairs[i])\n",
    "        ctr = ctr + 1\n",
    "print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testcases_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-b67a6aca8d33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnew_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'sentence1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sentence2'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestcases_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'original_summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mnew_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestcases_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predicted_summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnew_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'testcases_df' is not defined"
     ]
    }
   ],
   "source": [
    "new_scores = {'sentence1': [], 'sentence2': []}\n",
    "for i in testcases_df['original_summary']:\n",
    "    new_scores['sentence2'].append(i)\n",
    "for i in testcases_df['Predicted_summary']:\n",
    "    new_scores['sentence1'].append(i)\n",
    "for i in testcases_df['Predicted_summary']:\n",
    "    new_scores['sentence1'].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores['sentence1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_o = [''] * len(testcases_df)\n",
    "sentence_p = [''] * len(testcases_df)\n",
    "# sentence_o = [''] * 2\n",
    "# sentence_p = [''] * 2\n",
    "\n",
    "# sentence_o[0] = \"rock music is very good for public\"\n",
    "# sentence_p[0] = \"people like rock and roll\"\n",
    "# sentence_o[1] = \"a girl is dancing on the stage\"\n",
    "# sentence_p[1] = \"hello world\"\n",
    "\n",
    "# sentence_o[0] = clean_text(sentence_o[0])\n",
    "# sentence_p[0] = clean_text(sentence_p[0])\n",
    "# sentence_o[1] = clean_text(sentence_o[1])\n",
    "# sentence_p[1] = clean_text(sentence_p[1])\n",
    "\n",
    "new_sen_p = []\n",
    "for i in range(len(testcases_df)):\n",
    "  sen1 = new_scores['sentence1'][i]\n",
    "  sen2 = new_scores['sentence2'][i]\n",
    "  new_sen_p.append((sen1, sen2))\n",
    "\n",
    "new_sen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [new_sen_p]:\n",
    "  for sentence_pair in data:\n",
    "    premise    = sentence_pair[0]\n",
    "    hypothesis = sentence_pair[1]\n",
    "    vocab.addSentence(premise)\n",
    "    vocab.addSentence(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_pairs = get_pair_indices(vocab, new_sen_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_seq    = [torch.tensor(seq[0]).long().to(device) for seq in new_id_pairs]\n",
    "hypothesis_seq = [torch.tensor(seq[1]).long().to(device) for seq in new_id_pairs]\n",
    "\n",
    "premise_len    = list(map(len, premise_seq))\n",
    "hypothesis_len = list(map(len, hypothesis_seq))\n",
    "\n",
    "batch = len(premise_seq)\n",
    "temp = pad_sequence(premise_seq + hypothesis_seq, batch_first=True)\n",
    "premise_seq    = temp[:batch, :]\n",
    "hypothesis_seq = temp[batch:, :]\n",
    "\n",
    "prediction = lstm_model([premise_seq, hypothesis_seq], premise_len, hypothesis_len)\n",
    "# prediction = prediction[prediction!=prediction[0,3]]\n",
    "\n",
    "prediction_list = prediction.to('cpu')\n",
    "prediction_list = prediction_list.tolist()\n",
    "print(len(prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soft = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "# soft.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctr = 0\n",
    "# for i in range(len(soft)):\n",
    "#     if soft[i] == 1:\n",
    "#         print(rw_sentence_pairs[i])\n",
    "#         ctr = ctr + 1\n",
    "# print(ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "entail_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
